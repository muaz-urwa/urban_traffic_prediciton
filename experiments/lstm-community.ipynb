{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/home/urwa/Documents/side_projects/urban/data/featureData/jfk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 1049)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>...</th>\n",
       "      <th>91_lag_3</th>\n",
       "      <th>92_lag_3</th>\n",
       "      <th>93_lag_3</th>\n",
       "      <th>94_lag_3</th>\n",
       "      <th>95_lag_3</th>\n",
       "      <th>96_lag_3</th>\n",
       "      <th>97_lag_3</th>\n",
       "      <th>98_lag_3</th>\n",
       "      <th>99_lag_3</th>\n",
       "      <th>arrival_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour  1  10  100  101  102  106  107  108  ...  91_lag_3  \\\n",
       "0  2018-01-01     3  0   0    0    0    0    0    0    0  ...       1.0   \n",
       "1  2018-01-01     4  0   3    0    0    1    0    0    1  ...       4.0   \n",
       "2  2018-01-01     5  0   4    0    0    1    2    3    1  ...       0.0   \n",
       "\n",
       "   92_lag_3  93_lag_3  94_lag_3  95_lag_3  96_lag_3  97_lag_3  98_lag_3  \\\n",
       "0       1.0       0.0       1.0       6.0       0.0       1.0       0.0   \n",
       "1       1.0       0.0       0.0       2.0       0.0       0.0       0.0   \n",
       "2       0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "\n",
       "   99_lag_3  arrival_lag_3  \n",
       "0       0.0            6.0  \n",
       "1       0.0            6.0  \n",
       "2       0.0            2.0  \n",
       "\n",
       "[3 rows x 1049 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "777"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_columns = [c for c in dataset.columns if 'lag' in c]\n",
    "len(lag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 272)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[[c for c in dataset.columns if c not in lag_columns]]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DateColumns = ['Date']\n",
    "\n",
    "ext_columns = ['Dow', 'arrival','maxtemp', 'mintemp', 'avgtemp', 'departure', 'hdd',\n",
    "       'cdd', 'participation', 'newsnow', 'snowdepth', 'ifSnow']\n",
    "\n",
    "targetColumns = [c for c in dataset.columns if c not in ext_columns and \\\n",
    "                c not in DateColumns and c not in lag_columns and c != 'Hour']\n",
    "len(targetColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cols = [c for c in dataset.columns if c not in targetColumns and c not in DateColumns]\n",
    "len(features_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6567\n",
      "(6567, 272)\n",
      "(2190, 272)\n"
     ]
    }
   ],
   "source": [
    "sep = int(0.75*len(dataset))\n",
    "print(sep)\n",
    "\n",
    "\n",
    "trainData = dataset[:sep]\n",
    "testData = dataset[sep:]\n",
    "\n",
    "print(trainData.shape)\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6567, 13])\n",
      "torch.Size([6567, 258])\n",
      "torch.Size([2190, 13])\n",
      "torch.Size([2190, 258])\n"
     ]
    }
   ],
   "source": [
    "X_train = trainData[features_cols].values\n",
    "X_train = torch.tensor(X_train).float().to(device)\n",
    "print(X_train.shape)\n",
    "\n",
    "y_train = trainData[targetColumns].values\n",
    "y_train = torch.tensor(y_train).float().to(device)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test = testData[features_cols].values\n",
    "X_test = torch.tensor(X_test).float().to(device)\n",
    "print(X_test.shape)\n",
    "\n",
    "y_test = testData[targetColumns].values\n",
    "y_test = torch.tensor(y_test).float().to(device)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(x,y, tw):\n",
    "    inout_seq = []\n",
    "    L = len(x)\n",
    "    for i in range(L-tw):\n",
    "        train_seq_x = x[i:i+tw]\n",
    "        train_seq_y = y[i:i+tw]\n",
    "#         train_seq = torch.cat((train_seq_x,train_seq_y),axis=1)\n",
    "        \n",
    "#         train_label = y[i+tw:i+tw+1]\n",
    "        train_label = y[i+1:i+tw+1]\n",
    "        inout_seq.append((train_seq_x, train_seq_y ,train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inout_seq = create_inout_sequences(X_train,y_train, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([24, 13]), torch.Size([24, 258]), torch.Size([24, 258]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inout_seq[0][0].shape,train_inout_seq[0][1].shape, train_inout_seq[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inout_seq = create_inout_sequences(X_test,y_test, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, feat_size=1, hidden_layer_size=100, network_size=1, layers=1, communities=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # aggregation\n",
    "        self.attachment_matrix = torch.nn.Parameter(torch.randn(network_size,communities))\n",
    "        self.attachment_matrix.requires_grad = True\n",
    "        \n",
    "        \n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        self.hidden_cell = (torch.zeros(layers,1,self.hidden_layer_size),\n",
    "                    torch.zeros(layers,1,self.hidden_layer_size))\n",
    "        \n",
    "        lstm_input = communities + feat_size\n",
    "        self.lstm = nn.LSTM(input_size=lstm_input, hidden_size=hidden_layer_size, num_layers=layers)\n",
    "\n",
    "        #disaggregation\n",
    "#         self.linear_1 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.linear_2 = nn.Linear(hidden_layer_size, network_size)\n",
    "\n",
    "\n",
    "    def forward(self, input_seq, feat):\n",
    "        \n",
    "        w = F.softmax(self.attachment_matrix, dim=1)\n",
    "        x = torch.matmul(input_seq, self.attachment_matrix)\n",
    "        x = torch.cat((x,feat),axis=1)\n",
    "\n",
    "        \n",
    "        lstm_out, self.hidden_cell = self.lstm(x.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        \n",
    "        predictions = self.linear_2(lstm_out.view(len(input_seq), -1))\n",
    "#         predictions = F.relu(predictions)\n",
    "#         predictions = self.linear_2(predictions)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    with torch.no_grad():\n",
    "        for feat,seq, labels in test_inout_seq:\n",
    "            model.hidden = (torch.zeros(layers, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(layers, 1, model.hidden_layer_size))\n",
    "            prediction.append(model(seq,feat)[-1])\n",
    "\n",
    "    y_test_ = torch.stack([labels[-1] for feat,seq, labels in test_inout_seq], axis=0).detach().cpu().numpy()\n",
    "    y_pred_ = torch.stack(prediction).detach().cpu().numpy()\n",
    "\n",
    "    r2 = r2_score(y_test_, y_pred_, multioutput='variance_weighted')\n",
    "    rmse = mean_squared_error(y_test_, y_pred_)\n",
    "    mae = mean_absolute_error(y_test_, y_pred_)\n",
    "#     print(\"r2: \",r2)\n",
    "    return (r2, rmse, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 1\n",
    "communities = 20\n",
    "network_size = len(targetColumns)\n",
    "feat_size = len(features_cols)\n",
    "\n",
    "model = LSTM(feat_size = feat_size, hidden_layer_size=100,\n",
    "             network_size=network_size, layers=layers,\n",
    "            communities=communities).to(device)\n",
    "\n",
    "loss_function = nn.L1Loss()   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 1.23411751 r2: 0.416 rmse: 4.983 mae: 1.251\n",
      "epoch:  11 loss: 1.25594020 r2: 0.484 rmse: 4.397 mae: 1.155\n",
      "epoch:  21 loss: 1.26784170 r2: 0.469 rmse: 4.533 mae: 1.176\n",
      "epoch:  31 loss: 1.17462993 r2: 0.506 rmse: 4.211 mae: 1.127\n",
      "epoch:  41 loss: 1.18800199 r2: 0.513 rmse: 4.152 mae: 1.122\n",
      "epoch:  51 loss: 1.18325198 r2: 0.505 rmse: 4.225 mae: 1.126\n",
      "epoch:  61 loss: 1.15604198 r2: 0.518 rmse: 4.110 mae: 1.109\n",
      "epoch:  71 loss: 1.18215728 r2: 0.514 rmse: 4.145 mae: 1.108\n",
      "epoch:  81 loss: 1.16961443 r2: 0.514 rmse: 4.146 mae: 1.112\n",
      "epoch:  91 loss: 1.15114784 r2: 0.510 rmse: 4.179 mae: 1.111\n",
      "epoch: 101 loss: 1.14751267 r2: 0.511 rmse: 4.173 mae: 1.111\n",
      "epoch: 111 loss: 1.14076138 r2: 0.510 rmse: 4.179 mae: 1.111\n",
      "epoch: 121 loss: 1.14463723 r2: 0.510 rmse: 4.182 mae: 1.110\n",
      "epoch: 131 loss: 1.13794863 r2: 0.508 rmse: 4.200 mae: 1.111\n",
      "epoch: 141 loss: 1.13818395 r2: 0.508 rmse: 4.200 mae: 1.110\n",
      "epoch: 151 loss: 1.13970613 r2: 0.508 rmse: 4.195 mae: 1.109\n",
      "epoch: 161 loss: 1.13945794 r2: 0.509 rmse: 4.191 mae: 1.108\n",
      "epoch: 171 loss: 1.13902915 r2: 0.508 rmse: 4.199 mae: 1.109\n",
      "epoch: 181 loss: 1.14034772 r2: 0.507 rmse: 4.202 mae: 1.107\n",
      "epoch: 191 loss: 1.14138377 r2: 0.507 rmse: 4.203 mae: 1.107\n",
      "epoch: 201 loss: 1.13997340 r2: 0.507 rmse: 4.207 mae: 1.106\n",
      "epoch: 211 loss: 1.15430617 r2: 0.503 rmse: 4.242 mae: 1.107\n",
      "epoch: 221 loss: 1.15463603 r2: 0.503 rmse: 4.239 mae: 1.106\n",
      "epoch: 231 loss: 1.15481198 r2: 0.504 rmse: 4.232 mae: 1.106\n",
      "epoch: 241 loss: 1.15426660 r2: 0.503 rmse: 4.243 mae: 1.105\n",
      "epoch: 249 loss: 1.1552233696\n"
     ]
    }
   ],
   "source": [
    "epochs = 250\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    for feat,seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(layers, 1, model.hidden_layer_size).to(device),\n",
    "                        torch.zeros(layers, 1, model.hidden_layer_size).to(device))\n",
    "\n",
    "        y_pred = model(seq, feat)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()\n",
    "    if i%10 == 1:\n",
    "        r2, rmse, mae = evaluate(model)\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f} r2: {r2:5.3f} rmse: {rmse:5.3f} mae: {mae:5.3f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5026385642873215, 4.2423506, 1.1048625)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 8,\n",
       " '10': 6,\n",
       " '100': 10,\n",
       " '101': 3,\n",
       " '102': 15,\n",
       " '106': 7,\n",
       " '107': 3,\n",
       " '108': 7,\n",
       " '109': 7,\n",
       " '11': 19,\n",
       " '110': 11,\n",
       " '111': 19,\n",
       " '112': 4,\n",
       " '113': 19,\n",
       " '114': 5,\n",
       " '115': 18,\n",
       " '116': 2,\n",
       " '117': 13,\n",
       " '118': 13,\n",
       " '119': 7,\n",
       " '12': 9,\n",
       " '120': 6,\n",
       " '121': 11,\n",
       " '122': 6,\n",
       " '123': 15,\n",
       " '124': 2,\n",
       " '125': 2,\n",
       " '126': 10,\n",
       " '127': 0,\n",
       " '128': 18,\n",
       " '129': 0,\n",
       " '13': 12,\n",
       " '130': 18,\n",
       " '131': 15,\n",
       " '133': 15,\n",
       " '134': 7,\n",
       " '135': 11,\n",
       " '136': 14,\n",
       " '137': 0,\n",
       " '138': 8,\n",
       " '139': 16,\n",
       " '14': 2,\n",
       " '140': 12,\n",
       " '141': 16,\n",
       " '142': 18,\n",
       " '143': 2,\n",
       " '144': 18,\n",
       " '145': 3,\n",
       " '146': 2,\n",
       " '147': 11,\n",
       " '148': 15,\n",
       " '149': 10,\n",
       " '15': 19,\n",
       " '150': 7,\n",
       " '151': 14,\n",
       " '152': 1,\n",
       " '153': 2,\n",
       " '154': 6,\n",
       " '155': 5,\n",
       " '156': 7,\n",
       " '157': 7,\n",
       " '158': 13,\n",
       " '159': 7,\n",
       " '16': 11,\n",
       " '160': 19,\n",
       " '161': 16,\n",
       " '162': 16,\n",
       " '163': 3,\n",
       " '164': 0,\n",
       " '165': 3,\n",
       " '166': 19,\n",
       " '167': 1,\n",
       " '168': 10,\n",
       " '169': 14,\n",
       " '17': 2,\n",
       " '170': 4,\n",
       " '171': 7,\n",
       " '172': 8,\n",
       " '173': 3,\n",
       " '174': 10,\n",
       " '175': 19,\n",
       " '176': 7,\n",
       " '177': 2,\n",
       " '178': 3,\n",
       " '179': 18,\n",
       " '18': 11,\n",
       " '180': 2,\n",
       " '181': 18,\n",
       " '182': 18,\n",
       " '183': 9,\n",
       " '184': 17,\n",
       " '185': 12,\n",
       " '186': 15,\n",
       " '187': 12,\n",
       " '188': 9,\n",
       " '189': 10,\n",
       " '19': 9,\n",
       " '190': 16,\n",
       " '191': 18,\n",
       " '192': 3,\n",
       " '193': 16,\n",
       " '194': 17,\n",
       " '195': 11,\n",
       " '196': 15,\n",
       " '197': 16,\n",
       " '198': 6,\n",
       " '199': 11,\n",
       " '2': 3,\n",
       " '20': 12,\n",
       " '200': 6,\n",
       " '201': 2,\n",
       " '202': 0,\n",
       " '203': 7,\n",
       " '204': 13,\n",
       " '205': 2,\n",
       " '206': 2,\n",
       " '207': 1,\n",
       " '208': 15,\n",
       " '209': 12,\n",
       " '21': 14,\n",
       " '210': 1,\n",
       " '211': 4,\n",
       " '212': 0,\n",
       " '213': 15,\n",
       " '214': 2,\n",
       " '215': 5,\n",
       " '216': 18,\n",
       " '217': 0,\n",
       " '218': 2,\n",
       " '219': 2,\n",
       " '22': 11,\n",
       " '220': 16,\n",
       " '221': 16,\n",
       " '222': 14,\n",
       " '223': 1,\n",
       " '224': 8,\n",
       " '225': 6,\n",
       " '226': 15,\n",
       " '227': 6,\n",
       " '228': 18,\n",
       " '229': 11,\n",
       " '23': 15,\n",
       " '230': 3,\n",
       " '231': 2,\n",
       " '232': 18,\n",
       " '233': 9,\n",
       " '234': 13,\n",
       " '235': 6,\n",
       " '236': 2,\n",
       " '237': 19,\n",
       " '238': 2,\n",
       " '239': 2,\n",
       " '24': 18,\n",
       " '240': 19,\n",
       " '241': 11,\n",
       " '242': 5,\n",
       " '243': 5,\n",
       " '244': 2,\n",
       " '245': 9,\n",
       " '246': 1,\n",
       " '247': 11,\n",
       " '248': 11,\n",
       " '249': 15,\n",
       " '25': 2,\n",
       " '250': 9,\n",
       " '251': 0,\n",
       " '252': 17,\n",
       " '253': 12,\n",
       " '254': 10,\n",
       " '255': 6,\n",
       " '256': 19,\n",
       " '257': 11,\n",
       " '258': 18,\n",
       " '259': 17,\n",
       " '26': 5,\n",
       " '260': 14,\n",
       " '261': 0,\n",
       " '262': 17,\n",
       " '263': 6,\n",
       " '27': 13,\n",
       " '28': 0,\n",
       " '29': 2,\n",
       " '3': 16,\n",
       " '30': 1,\n",
       " '31': 16,\n",
       " '32': 2,\n",
       " '33': 1,\n",
       " '34': 16,\n",
       " '35': 18,\n",
       " '36': 14,\n",
       " '37': 7,\n",
       " '38': 7,\n",
       " '39': 11,\n",
       " '4': 2,\n",
       " '40': 13,\n",
       " '41': 7,\n",
       " '42': 14,\n",
       " '43': 13,\n",
       " '44': 3,\n",
       " '45': 11,\n",
       " '46': 6,\n",
       " '47': 9,\n",
       " '48': 10,\n",
       " '49': 6,\n",
       " '5': 14,\n",
       " '50': 18,\n",
       " '51': 18,\n",
       " '52': 3,\n",
       " '53': 0,\n",
       " '54': 0,\n",
       " '55': 19,\n",
       " '56': 16,\n",
       " '58': 8,\n",
       " '59': 0,\n",
       " '6': 8,\n",
       " '60': 12,\n",
       " '61': 3,\n",
       " '62': 9,\n",
       " '63': 6,\n",
       " '64': 18,\n",
       " '65': 18,\n",
       " '66': 4,\n",
       " '67': 1,\n",
       " '68': 1,\n",
       " '69': 0,\n",
       " '7': 17,\n",
       " '70': 5,\n",
       " '71': 8,\n",
       " '72': 0,\n",
       " '73': 2,\n",
       " '74': 12,\n",
       " '75': 11,\n",
       " '76': 17,\n",
       " '77': 19,\n",
       " '78': 18,\n",
       " '79': 12,\n",
       " '8': 17,\n",
       " '80': 6,\n",
       " '81': 9,\n",
       " '82': 7,\n",
       " '83': 9,\n",
       " '84': 1,\n",
       " '85': 8,\n",
       " '86': 14,\n",
       " '87': 0,\n",
       " '88': 10,\n",
       " '89': 11,\n",
       " '9': 0,\n",
       " '90': 0,\n",
       " '91': 19,\n",
       " '92': 9,\n",
       " '93': 19,\n",
       " '94': 14,\n",
       " '95': 16,\n",
       " '96': 1,\n",
       " '97': 0,\n",
       " '98': 9,\n",
       " '99': 6}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attachment = torch.argmax(F.softmax(model.attachment_matrix, dim=1), dim=1).detach().cpu().numpy()\n",
    "community_assignment = dict(zip(targetColumns, attachment))\n",
    "community_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 linear\n",
    "# 0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 linear\n",
    "# 0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 linear + RELU\n",
    "# 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 linear bptt = 24\n",
    "# 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO\n",
    "# other hubs\n",
    "# ensemble model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
