{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2020)\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0012098123619624396,\n",
       " 'layers': 2,\n",
       " 'step_size': 21,\n",
       " 'gamma': 0.5302067528042456,\n",
       " 'bptt': 12,\n",
       " 'dropout': 0.35583243487203325}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'lr': 0.0012098123619624396,\n",
    " 'layers': 2,\n",
    " 'step_size': 21,\n",
    " 'gamma': 0.5302067528042456,\n",
    " 'bptt': 12,\n",
    " 'dropout': 0.35583243487203325}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/home/urwa/Documents/side_projects/urban/data/featureData/lga.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 1045)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>...</th>\n",
       "      <th>91_lag_3</th>\n",
       "      <th>92_lag_3</th>\n",
       "      <th>93_lag_3</th>\n",
       "      <th>94_lag_3</th>\n",
       "      <th>95_lag_3</th>\n",
       "      <th>96_lag_3</th>\n",
       "      <th>97_lag_3</th>\n",
       "      <th>98_lag_3</th>\n",
       "      <th>99_lag_3</th>\n",
       "      <th>arrival_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1045 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour  1  10  100  101  102  106  107  108  ...  91_lag_3  \\\n",
       "0  2018-01-01     3  0   0    0    0    0    0    0    0  ...       0.0   \n",
       "1  2018-01-01     4  1   0    0    0    0    0    0    0  ...       0.0   \n",
       "2  2018-01-01     5  1   0    0    0    0    0    0    0  ...       0.0   \n",
       "\n",
       "   92_lag_3  93_lag_3  94_lag_3  95_lag_3  96_lag_3  97_lag_3  98_lag_3  \\\n",
       "0       1.0       0.0       1.0       0.0       0.0       1.0       0.0   \n",
       "1       1.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   99_lag_3  arrival_lag_3  \n",
       "0       0.0            3.0  \n",
       "1       0.0            0.0  \n",
       "2       0.0            1.0  \n",
       "\n",
       "[3 rows x 1045 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_columns = [c for c in dataset.columns if 'lag' in c]\n",
    "len(lag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 271)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[[c for c in dataset.columns if c not in lag_columns]]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DateColumns = ['Date']\n",
    "\n",
    "ext_columns = ['Dow', 'arrival','maxtemp', 'mintemp', 'avgtemp', 'departure', 'hdd',\n",
    "       'cdd', 'participation', 'newsnow', 'snowdepth', 'ifSnow']\n",
    "\n",
    "targetColumns = [c for c in dataset.columns if c not in ext_columns and \\\n",
    "                c not in DateColumns and c not in lag_columns and c != 'Hour']\n",
    "len(targetColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cols = [c for c in dataset.columns if c not in targetColumns and c not in DateColumns]\n",
    "len(features_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6567\n",
      "(6567, 271)\n",
      "(2190, 271)\n"
     ]
    }
   ],
   "source": [
    "sep = int(0.75*len(dataset))\n",
    "print(sep)\n",
    "\n",
    "\n",
    "trainData = dataset[:sep]\n",
    "testData = dataset[sep:]\n",
    "\n",
    "print(trainData.shape)\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6567, 13])\n",
      "torch.Size([6567, 257])\n",
      "torch.Size([2190, 13])\n",
      "torch.Size([2190, 257])\n"
     ]
    }
   ],
   "source": [
    "X_train = trainData[features_cols].values\n",
    "X_train = torch.tensor(X_train).float().to(device)\n",
    "print(X_train.shape)\n",
    "\n",
    "y_train = trainData[targetColumns].values\n",
    "y_train = torch.tensor(y_train).float().to(device)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test = testData[features_cols].values\n",
    "X_test = torch.tensor(X_test).float().to(device)\n",
    "print(X_test.shape)\n",
    "\n",
    "y_test = testData[targetColumns].values\n",
    "y_test = torch.tensor(y_test).float().to(device)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(x,y, tw):\n",
    "    inout_seq = []\n",
    "    L = len(x)\n",
    "    for i in range(L-tw):\n",
    "        train_seq_x = x[i:i+tw]\n",
    "        train_seq_y = y[i:i+tw]\n",
    "#         train_seq = torch.cat((train_seq_x,train_seq_y),axis=1)\n",
    "        \n",
    "#         train_label = y[i+tw:i+tw+1]\n",
    "        train_label = y[i+1:i+tw+1]\n",
    "        inout_seq.append((train_seq_x, train_seq_y ,train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inout_seq = create_inout_sequences(X_train,y_train, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 13]), torch.Size([12, 257]), torch.Size([12, 257]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inout_seq[0][0].shape,train_inout_seq[0][1].shape, train_inout_seq[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inout_seq = create_inout_sequences(X_test,y_test, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, feat_size=1, hidden_layer_size=100, network_size=1, layers=1, communities=10, dropout=0, at_mat=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # aggregation\n",
    "        if at_mat != None:\n",
    "            self.attachment_matrix = torch.nn.Parameter(at_mat)\n",
    "            self.attachment_matrix.requires_grad = False\n",
    "        else:\n",
    "            self.attachment_matrix = torch.nn.Parameter(torch.randn(network_size,communities))\n",
    "            self.attachment_matrix.requires_grad = True\n",
    "        \n",
    "        \n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        self.hidden_cell = (torch.zeros(layers,1,self.hidden_layer_size),\n",
    "                    torch.zeros(layers,1,self.hidden_layer_size))\n",
    "        \n",
    "        lstm_input = communities + feat_size\n",
    "        self.lstm = nn.LSTM(input_size=lstm_input, hidden_size=hidden_layer_size, num_layers=layers, dropout=dropout)\n",
    "\n",
    "        #disaggregation\n",
    "#         self.linear_1 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.linear_2 = nn.Linear(hidden_layer_size, network_size)\n",
    "\n",
    "\n",
    "    def forward(self, input_seq, feat):\n",
    "        \n",
    "        w = F.softmax(self.attachment_matrix, dim=1)\n",
    "        x = torch.matmul(input_seq, self.attachment_matrix)\n",
    "        x = torch.cat((x,feat),axis=1)\n",
    "\n",
    "        \n",
    "        lstm_out, self.hidden_cell = self.lstm(x.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        \n",
    "        predictions = self.linear_2(lstm_out.view(len(input_seq), -1))\n",
    "#         predictions = F.relu(predictions)\n",
    "#         predictions = self.linear_2(predictions)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    with torch.no_grad():\n",
    "        for feat,seq, labels in test_inout_seq:\n",
    "            model.hidden = (torch.zeros(layers, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(layers, 1, model.hidden_layer_size))\n",
    "            prediction.append(model(seq,feat)[-1])\n",
    "\n",
    "    y_test_ = torch.stack([labels[-1] for feat,seq, labels in test_inout_seq], axis=0).detach().cpu().numpy()\n",
    "    y_pred_ = torch.stack(prediction).detach().cpu().numpy()\n",
    "\n",
    "    r2 = r2_score(y_test_, y_pred_, multioutput='variance_weighted')\n",
    "    rmse = mean_squared_error(y_test_, y_pred_)\n",
    "    mae = mean_absolute_error(y_test_, y_pred_)\n",
    "#     print(\"r2: \",r2)\n",
    "    return (r2, rmse, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_at_mat(targetColumns):\n",
    "    comms = pd.read_csv('/home/urwa/Documents/side_projects/urban/UrbanTemporalNetworks/Data/ZonetoComm.csv')  \n",
    "    communities = list(set(comms.start_community))\n",
    "\n",
    "    mapping = dict(zip(comms.start_id, comms.start_community))\n",
    "    comm_to_index = dict(zip(communities,range(len(communities))))\n",
    "    col_to_index = dict(zip(targetColumns,range(len(targetColumns))))\n",
    "\n",
    "    attach = torch.zeros(len(targetColumns), len(communities))\n",
    "\n",
    "    for t_c in targetColumns:\n",
    "        com = mapping[int(t_c)]\n",
    "        x_i = col_to_index[t_c]\n",
    "        y_i = comm_to_index[com]\n",
    "\n",
    "        attach[x_i,y_i] = 1\n",
    "\n",
    "    return attach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([257, 24])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_mat = get_at_mat(targetColumns)\n",
    "at_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 2\n",
    "communities = 24\n",
    "network_size = len(targetColumns)\n",
    "feat_size = len(features_cols)\n",
    "dropout=0.35583243487203325\n",
    "\n",
    "model = LSTM(feat_size = feat_size, hidden_layer_size=communities,\n",
    "             network_size=network_size, layers=layers,\n",
    "            communities=communities, dropout=dropout, at_mat=at_mat).to(device)\n",
    "\n",
    "loss_function = nn.L1Loss()   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0012098123619624396)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=21, gamma=0.530)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 1.61770117 r2: 0.570 rmse: 10.013 mae: 1.224\n",
      "epoch:   1 loss: 1.48797011 r2: 0.646 rmse: 8.258 mae: 1.157\n",
      "epoch:   2 loss: 1.39927602 r2: 0.681 rmse: 7.435 mae: 1.117\n",
      "epoch:   3 loss: 1.36847055 r2: 0.680 rmse: 7.470 mae: 1.122\n",
      "epoch:   4 loss: 1.29878771 r2: 0.693 rmse: 7.162 mae: 1.115\n",
      "epoch:   5 loss: 1.28894806 r2: 0.712 rmse: 6.715 mae: 1.076\n",
      "epoch:   6 loss: 1.32515252 r2: 0.711 rmse: 6.732 mae: 1.087\n",
      "epoch:   7 loss: 1.28571153 r2: 0.702 rmse: 6.945 mae: 1.087\n",
      "epoch:   8 loss: 1.31155205 r2: 0.726 rmse: 6.384 mae: 1.057\n",
      "epoch:   9 loss: 1.23294592 r2: 0.725 rmse: 6.417 mae: 1.057\n",
      "epoch:  10 loss: 1.23393464 r2: 0.722 rmse: 6.479 mae: 1.070\n",
      "epoch:  11 loss: 1.21626782 r2: 0.731 rmse: 6.261 mae: 1.057\n",
      "epoch:  12 loss: 1.19701838 r2: 0.740 rmse: 6.054 mae: 1.040\n",
      "epoch:  13 loss: 1.46755695 r2: 0.732 rmse: 6.237 mae: 1.038\n",
      "epoch:  14 loss: 1.24417651 r2: 0.719 rmse: 6.545 mae: 1.061\n",
      "epoch:  15 loss: 1.26248682 r2: 0.733 rmse: 6.224 mae: 1.046\n",
      "epoch:  16 loss: 1.23099720 r2: 0.743 rmse: 5.996 mae: 1.030\n",
      "epoch:  17 loss: 1.22898352 r2: 0.723 rmse: 6.463 mae: 1.055\n",
      "epoch:  18 loss: 1.16566408 r2: 0.734 rmse: 6.194 mae: 1.055\n",
      "epoch:  19 loss: 1.27948785 r2: 0.720 rmse: 6.516 mae: 1.064\n",
      "epoch:  20 loss: 1.21294177 r2: 0.749 rmse: 5.859 mae: 1.027\n",
      "epoch:  21 loss: 1.15585446 r2: 0.742 rmse: 6.012 mae: 1.030\n",
      "epoch:  22 loss: 1.31159663 r2: 0.746 rmse: 5.921 mae: 1.030\n",
      "epoch:  23 loss: 1.27106118 r2: 0.746 rmse: 5.931 mae: 1.025\n",
      "epoch:  24 loss: 1.12454534 r2: 0.754 rmse: 5.728 mae: 1.017\n",
      "epoch:  25 loss: 1.23169041 r2: 0.745 rmse: 5.942 mae: 1.029\n",
      "epoch:  26 loss: 1.24566054 r2: 0.745 rmse: 5.935 mae: 1.023\n",
      "epoch:  27 loss: 1.15197515 r2: 0.746 rmse: 5.921 mae: 1.024\n",
      "epoch:  28 loss: 1.16185188 r2: 0.739 rmse: 6.085 mae: 1.027\n",
      "epoch:  29 loss: 1.20655990 r2: 0.744 rmse: 5.974 mae: 1.029\n",
      "epoch:  30 loss: 1.23688066 r2: 0.749 rmse: 5.850 mae: 1.019\n",
      "epoch:  31 loss: 1.20031297 r2: 0.738 rmse: 6.103 mae: 1.032\n",
      "epoch:  32 loss: 1.19978166 r2: 0.751 rmse: 5.806 mae: 1.015\n",
      "epoch:  33 loss: 1.18960834 r2: 0.750 rmse: 5.821 mae: 1.016\n",
      "epoch:  34 loss: 1.21346903 r2: 0.746 rmse: 5.919 mae: 1.021\n",
      "epoch:  35 loss: 1.13225102 r2: 0.750 rmse: 5.830 mae: 1.023\n",
      "epoch:  36 loss: 1.20513010 r2: 0.750 rmse: 5.834 mae: 1.017\n",
      "epoch:  37 loss: 1.15400290 r2: 0.747 rmse: 5.907 mae: 1.021\n",
      "epoch:  38 loss: 1.22429383 r2: 0.753 rmse: 5.759 mae: 1.015\n",
      "epoch:  39 loss: 1.14456534 r2: 0.750 rmse: 5.836 mae: 1.017\n",
      "epoch:  40 loss: 1.15420365 r2: 0.746 rmse: 5.930 mae: 1.019\n",
      "epoch:  41 loss: 1.18138576 r2: 0.749 rmse: 5.840 mae: 1.022\n",
      "epoch:  42 loss: 1.19997048 r2: 0.743 rmse: 5.997 mae: 1.023\n",
      "epoch:  43 loss: 1.19846833 r2: 0.745 rmse: 5.949 mae: 1.021\n",
      "epoch:  44 loss: 1.20294321 r2: 0.745 rmse: 5.952 mae: 1.022\n",
      "epoch:  45 loss: 1.14879513 r2: 0.751 rmse: 5.795 mae: 1.012\n",
      "epoch:  46 loss: 1.21331203 r2: 0.754 rmse: 5.733 mae: 1.008\n",
      "epoch:  47 loss: 1.21935356 r2: 0.750 rmse: 5.823 mae: 1.014\n",
      "epoch:  48 loss: 1.11751580 r2: 0.757 rmse: 5.674 mae: 1.011\n",
      "epoch:  49 loss: 1.19604766 r2: 0.753 rmse: 5.768 mae: 1.011\n",
      "epoch:  50 loss: 1.20363665 r2: 0.751 rmse: 5.797 mae: 1.018\n",
      "epoch:  51 loss: 1.18952024 r2: 0.747 rmse: 5.907 mae: 1.014\n",
      "epoch:  52 loss: 1.16155541 r2: 0.750 rmse: 5.817 mae: 1.013\n",
      "epoch:  53 loss: 1.11772227 r2: 0.749 rmse: 5.848 mae: 1.012\n",
      "epoch:  54 loss: 1.21189904 r2: 0.753 rmse: 5.756 mae: 1.010\n",
      "epoch:  55 loss: 1.16073489 r2: 0.754 rmse: 5.735 mae: 1.010\n",
      "epoch:  56 loss: 1.12449467 r2: 0.755 rmse: 5.706 mae: 1.008\n",
      "epoch:  57 loss: 1.12248147 r2: 0.756 rmse: 5.680 mae: 1.006\n",
      "epoch:  58 loss: 1.15832031 r2: 0.757 rmse: 5.673 mae: 1.006\n",
      "epoch:  59 loss: 1.18308437 r2: 0.753 rmse: 5.751 mae: 1.007\n",
      "epoch:  60 loss: 1.12429249 r2: 0.754 rmse: 5.732 mae: 1.009\n",
      "epoch:  61 loss: 1.13074780 r2: 0.751 rmse: 5.808 mae: 1.011\n",
      "epoch:  62 loss: 1.17221773 r2: 0.748 rmse: 5.864 mae: 1.013\n",
      "epoch:  63 loss: 1.17359281 r2: 0.752 rmse: 5.780 mae: 1.011\n",
      "epoch:  64 loss: 1.19701123 r2: 0.750 rmse: 5.830 mae: 1.015\n",
      "epoch:  65 loss: 1.23226106 r2: 0.751 rmse: 5.797 mae: 1.012\n",
      "epoch:  66 loss: 1.12959826 r2: 0.753 rmse: 5.768 mae: 1.009\n",
      "epoch:  67 loss: 1.18372405 r2: 0.748 rmse: 5.877 mae: 1.015\n",
      "epoch:  68 loss: 1.21877658 r2: 0.753 rmse: 5.760 mae: 1.007\n",
      "epoch:  69 loss: 1.13467109 r2: 0.753 rmse: 5.755 mae: 1.009\n",
      "epoch:  70 loss: 1.12731147 r2: 0.754 rmse: 5.723 mae: 1.008\n",
      "epoch:  71 loss: 1.18267477 r2: 0.754 rmse: 5.744 mae: 1.009\n",
      "epoch:  72 loss: 1.18417978 r2: 0.758 rmse: 5.629 mae: 1.003\n",
      "epoch:  73 loss: 1.18311858 r2: 0.758 rmse: 5.648 mae: 1.004\n",
      "epoch:  74 loss: 1.14454472 r2: 0.756 rmse: 5.688 mae: 1.006\n",
      "epoch:  75 loss: 1.11615705 r2: 0.756 rmse: 5.687 mae: 1.004\n",
      "epoch:  76 loss: 1.17788303 r2: 0.753 rmse: 5.762 mae: 1.008\n",
      "epoch:  77 loss: 1.11973059 r2: 0.758 rmse: 5.641 mae: 1.003\n",
      "epoch:  78 loss: 1.12770259 r2: 0.755 rmse: 5.716 mae: 1.004\n",
      "epoch:  79 loss: 1.12187564 r2: 0.755 rmse: 5.719 mae: 1.006\n",
      "epoch:  80 loss: 1.17569542 r2: 0.751 rmse: 5.793 mae: 1.010\n",
      "epoch:  81 loss: 1.16124976 r2: 0.755 rmse: 5.704 mae: 1.005\n",
      "epoch:  82 loss: 1.14034379 r2: 0.752 rmse: 5.785 mae: 1.007\n",
      "epoch:  83 loss: 1.21314251 r2: 0.755 rmse: 5.713 mae: 1.005\n",
      "epoch:  84 loss: 1.15406871 r2: 0.757 rmse: 5.669 mae: 1.002\n",
      "epoch:  85 loss: 1.19712329 r2: 0.754 rmse: 5.733 mae: 1.005\n",
      "epoch:  86 loss: 1.16243434 r2: 0.753 rmse: 5.768 mae: 1.006\n",
      "epoch:  87 loss: 1.20791006 r2: 0.755 rmse: 5.721 mae: 1.004\n",
      "epoch:  88 loss: 1.14169562 r2: 0.755 rmse: 5.703 mae: 1.003\n",
      "epoch:  89 loss: 1.13613462 r2: 0.752 rmse: 5.791 mae: 1.009\n",
      "epoch:  90 loss: 1.12584376 r2: 0.756 rmse: 5.690 mae: 1.003\n",
      "epoch:  91 loss: 1.15767872 r2: 0.755 rmse: 5.700 mae: 1.003\n",
      "epoch:  92 loss: 1.18777883 r2: 0.757 rmse: 5.654 mae: 1.002\n",
      "epoch:  93 loss: 1.21177328 r2: 0.756 rmse: 5.697 mae: 1.004\n",
      "epoch:  94 loss: 1.16265571 r2: 0.755 rmse: 5.719 mae: 1.004\n",
      "epoch:  95 loss: 1.15995944 r2: 0.753 rmse: 5.767 mae: 1.008\n",
      "epoch:  96 loss: 1.10806906 r2: 0.754 rmse: 5.724 mae: 1.004\n",
      "epoch:  97 loss: 1.16510093 r2: 0.754 rmse: 5.725 mae: 1.004\n",
      "epoch:  98 loss: 1.19314706 r2: 0.754 rmse: 5.735 mae: 1.006\n",
      "epoch:  99 loss: 1.16072237 r2: 0.751 rmse: 5.794 mae: 1.008\n",
      "epoch:  99 loss: 1.1607223749\n",
      "bet_r2:  0.7584986325716314\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "best_r2 = 0\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    for feat,seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(layers, 1, model.hidden_layer_size).to(device),\n",
    "                        torch.zeros(layers, 1, model.hidden_layer_size).to(device))\n",
    "\n",
    "        y_pred = model(seq, feat)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()\n",
    "#     if i%10 == 1:\n",
    "    r2, rmse, mae = evaluate(model)\n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.8f} r2: {r2:5.3f} rmse: {rmse:5.3f} mae: {mae:5.3f}')\n",
    "\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        torch.save(model.state_dict(), 'lga.pt')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "print(\"bet_r2: \", best_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7514492479226754, 5.7937226, 1.0082139)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attachment = torch.argmax(F.softmax(model.attachment_matrix, dim=1), dim=1).detach().cpu().numpy()\n",
    "# community_assignment = dict(zip(targetColumns, attachment))\n",
    "# community_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# community_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachment = model.attachment_matrix.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257, 24)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attachment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targetColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 2 ============\n",
      "0.9431580894298828\n",
      "========== 3 ============\n",
      "0.9409462285531621\n",
      "========== 4 ============\n",
      "0.938227413946092\n",
      "========== 5 ============\n",
      "0.9361745238003149\n",
      "========== 6 ============\n",
      "0.9336492828481276\n",
      "========== 7 ============\n",
      "0.9310861885154232\n",
      "========== 8 ============\n",
      "0.9277310771799258\n",
      "========== 9 ============\n",
      "0.9240067409725623\n",
      "========== 10 ============\n",
      "0.9210297483903906\n",
      "========== 11 ============\n",
      "0.9148244938307323\n",
      "========== 12 ============\n",
      "0.9106162890704091\n",
      "========== 13 ============\n",
      "0.9028384366793064\n",
      "========== 14 ============\n",
      "0.8928296466001854\n",
      "========== 15 ============\n",
      "0.8862701759183564\n",
      "========== 16 ============\n",
      "0.8754781390409807\n",
      "========== 17 ============\n",
      "0.8674057593158342\n",
      "========== 18 ============\n",
      "0.8517420124209563\n",
      "========== 19 ============\n",
      "0.8254840255935164\n",
      "========== 20 ============\n",
      "0.7926951398719686\n",
      "========== 21 ============\n",
      "0.7372305588529849\n",
      "========== 22 ============\n",
      "0.6382612661227811\n",
      "========== 23 ============\n",
      "0.3491485647920014\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,24):\n",
    "    print('========== '+str(i)+' ============')\n",
    "    kmeans = KMeans(n_clusters=i, random_state=1).fit(attachment)\n",
    "    labels = kmeans.labels_\n",
    "    print(davies_bouldin_score(attachment, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9,  2,  9,  2, 10,  7,  6,  1, 16,  1,  7, 14,  6,  6, 19, 13, 17,\n",
       "       16,  8,  6, 13,  3,  2,  1,  2,  6,  8, 13, 13, 10,  6,  2,  2,  2,\n",
       "        1,  2,  3, 11,  9,  2,  1, 18, 18, 15, 15,  6, 12, 12,  8,  6,  1,\n",
       "        3,  1, 15, 13, 11,  1,  1, 21, 10,  6,  8,  3, 10,  9,  9,  9,  9,\n",
       "        1, 15,  8,  8,  8, 14,  9,  3, 22, 10, 11,  3, 16,  4,  1, 12, 11,\n",
       "        2,  7,  5,  5,  5,  5,  9, 21,  4,  7,  2,  7,  2,  3, 12, 20,  7,\n",
       "       10,  2, 14,  3,  2, 11, 11, 17, 12,  2, 16,  2, 19,  0,  5,  6,  1,\n",
       "        1,  6,  5,  5, 22,  2,  2, 14,  2,  2,  1, 11, 19,  4, 12,  6, 14,\n",
       "       12,  1,  1,  9, 21,  9,  6,  6,  9,  0,  8, 18, 18, 15, 15, 15, 11,\n",
       "       11,  5, 13, 13, 19,  0,  8,  5,  6,  7,  5, 21,  3,  3,  5, 14, 14,\n",
       "        7,  2,  5,  1, 10,  6, 18, 18, 17,  2,  1,  5, 17,  5,  5,  7,  7,\n",
       "        4, 14, 14,  2,  4,  6,  7, 20, 13, 15, 16,  6,  5,  8,  9,  7, 16,\n",
       "        9,  5,  7,  3,  7,  1, 10,  5,  8, 22,  8,  4,  4,  4,  3,  7,  7,\n",
       "        1,  0,  8, 12, 10,  4,  4,  3, 20, 20,  4,  4,  8,  6, 12, 14,  5,\n",
       "       10, 10, 16,  4, 17,  6,  6,  4,  3,  0,  4,  3,  3, 11,  3, 10,  7,\n",
       "        3, 16], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_assignment = dict(zip(targetColumns, labels.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('lga_single.json', 'w') as fp:\n",
    "    json.dump(community_assignment, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 comm\n",
    "# 0.505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 comm\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
