{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2020)\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.000797977911440375,\n",
       " 'layers': 3,\n",
       " 'step_size': 15,\n",
       " 'gamma': 0.6484984709565126,\n",
       " 'bptt': 15,\n",
       " 'dropout': 0.0294619119320717}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'lr': 0.000797977911440375,\n",
    " 'layers': 3,\n",
    " 'step_size': 15,\n",
    " 'gamma': 0.6484984709565126,\n",
    " 'bptt': 15,\n",
    " 'dropout': 0.0294619119320717}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/home/urwa/Documents/side_projects/urban/data/featureData/penn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 1045)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>...</th>\n",
       "      <th>91_lag_3</th>\n",
       "      <th>92_lag_3</th>\n",
       "      <th>93_lag_3</th>\n",
       "      <th>94_lag_3</th>\n",
       "      <th>95_lag_3</th>\n",
       "      <th>96_lag_3</th>\n",
       "      <th>97_lag_3</th>\n",
       "      <th>98_lag_3</th>\n",
       "      <th>99_lag_3</th>\n",
       "      <th>arrival_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1045 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour  1  10  100  101  102  106  107  108  ...  91_lag_3  \\\n",
       "0  2018-01-01     3  5   0    3    0    0    0   26    0  ...       1.0   \n",
       "1  2018-01-01     4  3   0    7    0    0    0    8    0  ...       0.0   \n",
       "2  2018-01-01     5  6   0    1    1    0    2    1    0  ...       0.0   \n",
       "\n",
       "   92_lag_3  93_lag_3  94_lag_3  95_lag_3  96_lag_3  97_lag_3  98_lag_3  \\\n",
       "0       0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "1       0.0       1.0       0.0       3.0       0.0       2.0       0.0   \n",
       "2       0.0       0.0       0.0       1.0       0.0       1.0       1.0   \n",
       "\n",
       "   99_lag_3  arrival_lag_3  \n",
       "0       0.0            0.0  \n",
       "1       0.0            1.0  \n",
       "2       0.0            1.0  \n",
       "\n",
       "[3 rows x 1045 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_columns = [c for c in dataset.columns if 'lag' in c]\n",
    "len(lag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 271)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[[c for c in dataset.columns if c not in lag_columns]]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DateColumns = ['Date']\n",
    "\n",
    "ext_columns = ['Dow', 'arrival','maxtemp', 'mintemp', 'avgtemp', 'departure', 'hdd',\n",
    "       'cdd', 'participation', 'newsnow', 'snowdepth', 'ifSnow']\n",
    "\n",
    "targetColumns = [c for c in dataset.columns if c not in ext_columns and \\\n",
    "                c not in DateColumns and c not in lag_columns and c != 'Hour']\n",
    "len(targetColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cols = [c for c in dataset.columns if c not in targetColumns and c not in DateColumns]\n",
    "len(features_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6567\n",
      "(6567, 271)\n",
      "(2190, 271)\n"
     ]
    }
   ],
   "source": [
    "sep = int(0.75*len(dataset))\n",
    "print(sep)\n",
    "\n",
    "\n",
    "trainData = dataset[:sep]\n",
    "testData = dataset[sep:]\n",
    "\n",
    "print(trainData.shape)\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6567, 13])\n",
      "torch.Size([6567, 257])\n",
      "torch.Size([2190, 13])\n",
      "torch.Size([2190, 257])\n"
     ]
    }
   ],
   "source": [
    "X_train = trainData[features_cols].values\n",
    "X_train = torch.tensor(X_train).float().to(device)\n",
    "print(X_train.shape)\n",
    "\n",
    "y_train = trainData[targetColumns].values\n",
    "y_train = torch.tensor(y_train).float().to(device)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test = testData[features_cols].values\n",
    "X_test = torch.tensor(X_test).float().to(device)\n",
    "print(X_test.shape)\n",
    "\n",
    "y_test = testData[targetColumns].values\n",
    "y_test = torch.tensor(y_test).float().to(device)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(x,y, tw):\n",
    "    inout_seq = []\n",
    "    L = len(x)\n",
    "    for i in range(L-tw):\n",
    "        train_seq_x = x[i:i+tw]\n",
    "        train_seq_y = y[i:i+tw]\n",
    "#         train_seq = torch.cat((train_seq_x,train_seq_y),axis=1)\n",
    "        \n",
    "#         train_label = y[i+tw:i+tw+1]\n",
    "        train_label = y[i+1:i+tw+1]\n",
    "        inout_seq.append((train_seq_x, train_seq_y ,train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inout_seq = create_inout_sequences(X_train,y_train, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([15, 13]), torch.Size([15, 257]), torch.Size([15, 257]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inout_seq[0][0].shape,train_inout_seq[0][1].shape, train_inout_seq[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inout_seq = create_inout_sequences(X_test,y_test, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, feat_size=1, hidden_layer_size=100, network_size=1, layers=1, communities=10, dropout=0, at_mat=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # aggregation\n",
    "        if at_mat != None:\n",
    "            self.attachment_matrix = torch.nn.Parameter(at_mat)\n",
    "            self.attachment_matrix.requires_grad = False\n",
    "        else:\n",
    "            self.attachment_matrix = torch.nn.Parameter(torch.randn(network_size,communities))\n",
    "            self.attachment_matrix.requires_grad = True\n",
    "        \n",
    "        \n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        self.hidden_cell = (torch.zeros(layers,1,self.hidden_layer_size),\n",
    "                    torch.zeros(layers,1,self.hidden_layer_size))\n",
    "        \n",
    "        lstm_input = communities + feat_size\n",
    "        self.lstm = nn.LSTM(input_size=lstm_input, hidden_size=hidden_layer_size, num_layers=layers, dropout=dropout)\n",
    "\n",
    "        #disaggregation\n",
    "#         self.linear_1 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.linear_2 = nn.Linear(hidden_layer_size, network_size)\n",
    "\n",
    "\n",
    "    def forward(self, input_seq, feat):\n",
    "        \n",
    "        w = F.softmax(self.attachment_matrix, dim=1)\n",
    "        x = torch.matmul(input_seq, self.attachment_matrix)\n",
    "        x = torch.cat((x,feat),axis=1)\n",
    "\n",
    "        \n",
    "        lstm_out, self.hidden_cell = self.lstm(x.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        \n",
    "        predictions = self.linear_2(lstm_out.view(len(input_seq), -1))\n",
    "#         predictions = F.relu(predictions)\n",
    "#         predictions = self.linear_2(predictions)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    with torch.no_grad():\n",
    "        for feat,seq, labels in test_inout_seq:\n",
    "            model.hidden = (torch.zeros(layers, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(layers, 1, model.hidden_layer_size))\n",
    "            prediction.append(model(seq,feat)[-1])\n",
    "\n",
    "    y_test_ = torch.stack([labels[-1] for feat,seq, labels in test_inout_seq], axis=0).detach().cpu().numpy()\n",
    "    y_pred_ = torch.stack(prediction).detach().cpu().numpy()\n",
    "\n",
    "    r2 = r2_score(y_test_, y_pred_, multioutput='variance_weighted')\n",
    "    rmse = mean_squared_error(y_test_, y_pred_)\n",
    "    mae = mean_absolute_error(y_test_, y_pred_)\n",
    "#     print(\"r2: \",r2)\n",
    "    return (r2, rmse, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_at_mat(targetColumns):\n",
    "    comms = pd.read_csv('/home/urwa/Documents/side_projects/urban/UrbanTemporalNetworks/Data/ZonetoComm.csv')  \n",
    "    communities = list(set(comms.start_community))\n",
    "\n",
    "    mapping = dict(zip(comms.start_id, comms.start_community))\n",
    "    comm_to_index = dict(zip(communities,range(len(communities))))\n",
    "    col_to_index = dict(zip(targetColumns,range(len(targetColumns))))\n",
    "\n",
    "    attach = torch.zeros(len(targetColumns), len(communities))\n",
    "\n",
    "    for t_c in targetColumns:\n",
    "        com = mapping[int(t_c)]\n",
    "        x_i = col_to_index[t_c]\n",
    "        y_i = comm_to_index[com]\n",
    "\n",
    "        attach[x_i,y_i] = 1\n",
    "\n",
    "    return attach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([257, 24])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_mat = get_at_mat(targetColumns)\n",
    "at_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 3\n",
    "communities = 24\n",
    "network_size = len(targetColumns)\n",
    "feat_size = len(features_cols)\n",
    "dropout = 0.0294619119320717\n",
    "\n",
    "model = LSTM(feat_size = feat_size, hidden_layer_size=communities,\n",
    "             network_size=network_size, layers=layers,\n",
    "            communities=communities, dropout=dropout, at_mat=at_mat).to(device)\n",
    "\n",
    "loss_function = nn.L1Loss()   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000797977911440375)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.648)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 0.84347147 r2: 0.420 rmse: 9.387 mae: 0.971\n",
      "epoch:   1 loss: 0.72685772 r2: 0.533 rmse: 7.561 mae: 0.890\n",
      "epoch:   2 loss: 0.68050951 r2: 0.605 rmse: 6.403 mae: 0.862\n",
      "epoch:   3 loss: 0.66250342 r2: 0.617 rmse: 6.195 mae: 0.847\n",
      "epoch:   4 loss: 0.65180355 r2: 0.644 rmse: 5.760 mae: 0.830\n",
      "epoch:   5 loss: 0.64066255 r2: 0.643 rmse: 5.780 mae: 0.829\n",
      "epoch:   6 loss: 0.62875628 r2: 0.644 rmse: 5.767 mae: 0.837\n",
      "epoch:   7 loss: 0.63417852 r2: 0.648 rmse: 5.699 mae: 0.837\n",
      "epoch:   8 loss: 0.62599087 r2: 0.666 rmse: 5.410 mae: 0.806\n",
      "epoch:   9 loss: 0.61837393 r2: 0.671 rmse: 5.334 mae: 0.807\n",
      "epoch:  10 loss: 0.62578988 r2: 0.666 rmse: 5.405 mae: 0.814\n",
      "epoch:  11 loss: 0.61956882 r2: 0.670 rmse: 5.345 mae: 0.803\n",
      "epoch:  12 loss: 0.62543398 r2: 0.666 rmse: 5.409 mae: 0.813\n",
      "epoch:  13 loss: 0.62031138 r2: 0.663 rmse: 5.449 mae: 0.814\n",
      "epoch:  14 loss: 0.61905652 r2: 0.669 rmse: 5.354 mae: 0.806\n",
      "epoch:  15 loss: 0.61735809 r2: 0.678 rmse: 5.211 mae: 0.800\n",
      "epoch:  16 loss: 0.61590683 r2: 0.667 rmse: 5.392 mae: 0.804\n",
      "epoch:  17 loss: 0.61219609 r2: 0.674 rmse: 5.271 mae: 0.796\n",
      "epoch:  18 loss: 0.62017077 r2: 0.676 rmse: 5.252 mae: 0.795\n",
      "epoch:  19 loss: 0.60709131 r2: 0.676 rmse: 5.248 mae: 0.802\n",
      "epoch:  20 loss: 0.61173433 r2: 0.671 rmse: 5.325 mae: 0.799\n",
      "epoch:  21 loss: 0.61053002 r2: 0.684 rmse: 5.108 mae: 0.791\n",
      "epoch:  22 loss: 0.60868168 r2: 0.680 rmse: 5.180 mae: 0.795\n",
      "epoch:  23 loss: 0.60858017 r2: 0.675 rmse: 5.263 mae: 0.799\n",
      "epoch:  24 loss: 0.60703683 r2: 0.681 rmse: 5.165 mae: 0.794\n",
      "epoch:  25 loss: 0.61267334 r2: 0.677 rmse: 5.236 mae: 0.801\n",
      "epoch:  26 loss: 0.61102426 r2: 0.682 rmse: 5.145 mae: 0.792\n",
      "epoch:  27 loss: 0.61236298 r2: 0.677 rmse: 5.228 mae: 0.796\n",
      "epoch:  28 loss: 0.61700171 r2: 0.678 rmse: 5.211 mae: 0.800\n",
      "epoch:  29 loss: 0.61870086 r2: 0.686 rmse: 5.086 mae: 0.790\n",
      "epoch:  30 loss: 0.60832065 r2: 0.690 rmse: 5.024 mae: 0.782\n",
      "epoch:  31 loss: 0.61012691 r2: 0.686 rmse: 5.090 mae: 0.785\n",
      "epoch:  32 loss: 0.61502999 r2: 0.689 rmse: 5.036 mae: 0.781\n",
      "epoch:  33 loss: 0.60917771 r2: 0.679 rmse: 5.203 mae: 0.789\n",
      "epoch:  34 loss: 0.60874498 r2: 0.682 rmse: 5.148 mae: 0.788\n",
      "epoch:  35 loss: 0.60843223 r2: 0.683 rmse: 5.125 mae: 0.786\n",
      "epoch:  36 loss: 0.60929090 r2: 0.677 rmse: 5.222 mae: 0.794\n",
      "epoch:  37 loss: 0.61433959 r2: 0.686 rmse: 5.091 mae: 0.784\n",
      "epoch:  38 loss: 0.61005133 r2: 0.684 rmse: 5.112 mae: 0.785\n",
      "epoch:  39 loss: 0.60317922 r2: 0.681 rmse: 5.158 mae: 0.787\n",
      "epoch:  40 loss: 0.62267578 r2: 0.688 rmse: 5.051 mae: 0.786\n",
      "epoch:  41 loss: 0.61198157 r2: 0.675 rmse: 5.263 mae: 0.799\n",
      "epoch:  42 loss: 0.60867780 r2: 0.684 rmse: 5.122 mae: 0.785\n",
      "epoch:  43 loss: 0.60602391 r2: 0.690 rmse: 5.021 mae: 0.780\n",
      "epoch:  44 loss: 0.60104024 r2: 0.683 rmse: 5.135 mae: 0.787\n",
      "epoch:  45 loss: 0.60510194 r2: 0.695 rmse: 4.938 mae: 0.777\n",
      "epoch:  46 loss: 0.59599280 r2: 0.691 rmse: 5.000 mae: 0.779\n",
      "epoch:  47 loss: 0.62023646 r2: 0.689 rmse: 5.039 mae: 0.781\n",
      "epoch:  48 loss: 0.60893512 r2: 0.697 rmse: 4.912 mae: 0.777\n",
      "epoch:  49 loss: 0.61024010 r2: 0.697 rmse: 4.905 mae: 0.775\n",
      "epoch:  50 loss: 0.60321867 r2: 0.695 rmse: 4.940 mae: 0.778\n",
      "epoch:  51 loss: 0.60569167 r2: 0.692 rmse: 4.982 mae: 0.777\n",
      "epoch:  52 loss: 0.60558158 r2: 0.697 rmse: 4.913 mae: 0.774\n",
      "epoch:  53 loss: 0.60522139 r2: 0.692 rmse: 4.982 mae: 0.778\n",
      "epoch:  54 loss: 0.60909766 r2: 0.692 rmse: 4.989 mae: 0.778\n",
      "epoch:  55 loss: 0.60415995 r2: 0.693 rmse: 4.965 mae: 0.777\n",
      "epoch:  56 loss: 0.60805559 r2: 0.691 rmse: 4.995 mae: 0.776\n",
      "epoch:  57 loss: 0.60362256 r2: 0.696 rmse: 4.927 mae: 0.775\n",
      "epoch:  58 loss: 0.59874284 r2: 0.695 rmse: 4.934 mae: 0.776\n",
      "epoch:  59 loss: 0.60191005 r2: 0.697 rmse: 4.907 mae: 0.775\n",
      "epoch:  60 loss: 0.60386568 r2: 0.694 rmse: 4.954 mae: 0.775\n",
      "epoch:  61 loss: 0.60318345 r2: 0.697 rmse: 4.910 mae: 0.774\n",
      "epoch:  62 loss: 0.60462123 r2: 0.696 rmse: 4.929 mae: 0.774\n",
      "epoch:  63 loss: 0.60646468 r2: 0.694 rmse: 4.959 mae: 0.774\n",
      "epoch:  64 loss: 0.60187739 r2: 0.694 rmse: 4.962 mae: 0.774\n",
      "epoch:  65 loss: 0.60313499 r2: 0.696 rmse: 4.922 mae: 0.772\n",
      "epoch:  66 loss: 0.60478830 r2: 0.696 rmse: 4.925 mae: 0.773\n",
      "epoch:  67 loss: 0.60326535 r2: 0.697 rmse: 4.904 mae: 0.773\n",
      "epoch:  68 loss: 0.60179985 r2: 0.695 rmse: 4.940 mae: 0.774\n",
      "epoch:  69 loss: 0.60224813 r2: 0.693 rmse: 4.965 mae: 0.775\n",
      "epoch:  70 loss: 0.60485595 r2: 0.694 rmse: 4.952 mae: 0.775\n",
      "epoch:  71 loss: 0.59923863 r2: 0.695 rmse: 4.933 mae: 0.773\n",
      "epoch:  72 loss: 0.60204506 r2: 0.695 rmse: 4.931 mae: 0.773\n",
      "epoch:  73 loss: 0.60821438 r2: 0.696 rmse: 4.925 mae: 0.774\n",
      "epoch:  74 loss: 0.60481173 r2: 0.694 rmse: 4.957 mae: 0.775\n",
      "epoch:  75 loss: 0.60804510 r2: 0.695 rmse: 4.946 mae: 0.773\n",
      "epoch:  76 loss: 0.60371917 r2: 0.696 rmse: 4.929 mae: 0.772\n",
      "epoch:  77 loss: 0.60468608 r2: 0.694 rmse: 4.946 mae: 0.773\n",
      "epoch:  78 loss: 0.60446423 r2: 0.695 rmse: 4.935 mae: 0.773\n",
      "epoch:  79 loss: 0.60012579 r2: 0.694 rmse: 4.957 mae: 0.774\n",
      "epoch:  80 loss: 0.60045964 r2: 0.694 rmse: 4.950 mae: 0.774\n",
      "epoch:  81 loss: 0.60068762 r2: 0.694 rmse: 4.951 mae: 0.774\n",
      "epoch:  82 loss: 0.60379797 r2: 0.696 rmse: 4.930 mae: 0.772\n",
      "epoch:  83 loss: 0.60729456 r2: 0.696 rmse: 4.915 mae: 0.771\n",
      "epoch:  84 loss: 0.60220516 r2: 0.696 rmse: 4.926 mae: 0.772\n",
      "epoch:  85 loss: 0.60197288 r2: 0.695 rmse: 4.940 mae: 0.773\n",
      "epoch:  86 loss: 0.60625923 r2: 0.697 rmse: 4.900 mae: 0.771\n",
      "epoch:  87 loss: 0.60102534 r2: 0.695 rmse: 4.931 mae: 0.772\n",
      "epoch:  88 loss: 0.59824973 r2: 0.697 rmse: 4.908 mae: 0.771\n",
      "epoch:  89 loss: 0.60386419 r2: 0.697 rmse: 4.907 mae: 0.771\n",
      "epoch:  90 loss: 0.60199326 r2: 0.698 rmse: 4.893 mae: 0.771\n",
      "epoch:  91 loss: 0.60001504 r2: 0.697 rmse: 4.905 mae: 0.771\n",
      "epoch:  92 loss: 0.60283887 r2: 0.697 rmse: 4.902 mae: 0.772\n",
      "epoch:  93 loss: 0.60445666 r2: 0.698 rmse: 4.897 mae: 0.771\n",
      "epoch:  94 loss: 0.60205632 r2: 0.697 rmse: 4.904 mae: 0.772\n",
      "epoch:  95 loss: 0.60766906 r2: 0.698 rmse: 4.890 mae: 0.770\n",
      "epoch:  96 loss: 0.60444015 r2: 0.698 rmse: 4.895 mae: 0.771\n",
      "epoch:  97 loss: 0.59737742 r2: 0.698 rmse: 4.888 mae: 0.771\n",
      "epoch:  98 loss: 0.60539830 r2: 0.697 rmse: 4.912 mae: 0.772\n",
      "epoch:  99 loss: 0.60952193 r2: 0.697 rmse: 4.899 mae: 0.771\n",
      "epoch:  99 loss: 0.6095219254\n",
      "bet_r2:  0.698085852695221\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "best_r2 = 0\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    for feat,seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(layers, 1, model.hidden_layer_size).to(device),\n",
    "                        torch.zeros(layers, 1, model.hidden_layer_size).to(device))\n",
    "\n",
    "        y_pred = model(seq, feat)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()\n",
    "#     if i%10 == 1:\n",
    "    r2, rmse, mae = evaluate(model)\n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.8f} r2: {r2:5.3f} rmse: {rmse:5.3f} mae: {mae:5.3f}')\n",
    "\n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        torch.save(model.state_dict(), 'penn.pt')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "print(\"bet_r2: \", best_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6974371056178693, 4.8986483, 0.7709814)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0,\n",
       " '10': 4,\n",
       " '100': 0,\n",
       " '101': 4,\n",
       " '102': 23,\n",
       " '106': 19,\n",
       " '107': 1,\n",
       " '108': 3,\n",
       " '109': 5,\n",
       " '11': 3,\n",
       " '111': 19,\n",
       " '112': 9,\n",
       " '113': 1,\n",
       " '114': 1,\n",
       " '115': 18,\n",
       " '116': 22,\n",
       " '117': 16,\n",
       " '118': 5,\n",
       " '119': 14,\n",
       " '12': 1,\n",
       " '120': 22,\n",
       " '121': 8,\n",
       " '122': 4,\n",
       " '123': 3,\n",
       " '124': 4,\n",
       " '125': 1,\n",
       " '126': 14,\n",
       " '127': 22,\n",
       " '128': 22,\n",
       " '129': 23,\n",
       " '13': 1,\n",
       " '130': 4,\n",
       " '131': 4,\n",
       " '132': 4,\n",
       " '133': 3,\n",
       " '134': 4,\n",
       " '135': 8,\n",
       " '136': 10,\n",
       " '137': 0,\n",
       " '138': 0,\n",
       " '139': 4,\n",
       " '14': 3,\n",
       " '140': 15,\n",
       " '141': 15,\n",
       " '142': 12,\n",
       " '143': 12,\n",
       " '144': 1,\n",
       " '145': 7,\n",
       " '146': 7,\n",
       " '147': 14,\n",
       " '148': 1,\n",
       " '149': 3,\n",
       " '15': 8,\n",
       " '150': 3,\n",
       " '151': 12,\n",
       " '152': 22,\n",
       " '153': 10,\n",
       " '154': 3,\n",
       " '155': 3,\n",
       " '156': 11,\n",
       " '157': 23,\n",
       " '158': 1,\n",
       " '159': 14,\n",
       " '16': 8,\n",
       " '160': 23,\n",
       " '161': 0,\n",
       " '162': 0,\n",
       " '163': 0,\n",
       " '164': 0,\n",
       " '165': 3,\n",
       " '166': 12,\n",
       " '167': 14,\n",
       " '168': 14,\n",
       " '169': 14,\n",
       " '17': 9,\n",
       " '170': 0,\n",
       " '171': 8,\n",
       " '172': 6,\n",
       " '173': 23,\n",
       " '174': 10,\n",
       " '175': 8,\n",
       " '176': 5,\n",
       " '177': 13,\n",
       " '178': 3,\n",
       " '179': 7,\n",
       " '18': 10,\n",
       " '180': 4,\n",
       " '181': 19,\n",
       " '182': 2,\n",
       " '183': 2,\n",
       " '184': 2,\n",
       " '185': 2,\n",
       " '187': 11,\n",
       " '188': 13,\n",
       " '189': 19,\n",
       " '19': 4,\n",
       " '190': 19,\n",
       " '191': 4,\n",
       " '192': 8,\n",
       " '193': 7,\n",
       " '194': 20,\n",
       " '195': 19,\n",
       " '196': 23,\n",
       " '197': 4,\n",
       " '198': 9,\n",
       " '199': 8,\n",
       " '2': 4,\n",
       " '20': 10,\n",
       " '200': 10,\n",
       " '201': 16,\n",
       " '202': 7,\n",
       " '203': 4,\n",
       " '204': 5,\n",
       " '205': 4,\n",
       " '206': 18,\n",
       " '207': 17,\n",
       " '208': 2,\n",
       " '209': 1,\n",
       " '21': 3,\n",
       " '210': 3,\n",
       " '211': 1,\n",
       " '212': 2,\n",
       " '213': 2,\n",
       " '214': 6,\n",
       " '215': 4,\n",
       " '216': 4,\n",
       " '217': 9,\n",
       " '218': 4,\n",
       " '219': 4,\n",
       " '22': 3,\n",
       " '220': 10,\n",
       " '221': 18,\n",
       " '222': 13,\n",
       " '223': 7,\n",
       " '224': 1,\n",
       " '225': 9,\n",
       " '226': 7,\n",
       " '227': 3,\n",
       " '228': 3,\n",
       " '229': 0,\n",
       " '23': 11,\n",
       " '230': 0,\n",
       " '231': 1,\n",
       " '232': 1,\n",
       " '233': 0,\n",
       " '234': 21,\n",
       " '235': 14,\n",
       " '236': 15,\n",
       " '237': 15,\n",
       " '238': 12,\n",
       " '239': 12,\n",
       " '24': 12,\n",
       " '240': 10,\n",
       " '241': 10,\n",
       " '242': 2,\n",
       " '243': 22,\n",
       " '244': 22,\n",
       " '245': 18,\n",
       " '246': 21,\n",
       " '247': 14,\n",
       " '248': 2,\n",
       " '249': 1,\n",
       " '25': 19,\n",
       " '250': 2,\n",
       " '251': 11,\n",
       " '252': 8,\n",
       " '253': 8,\n",
       " '254': 2,\n",
       " '255': 9,\n",
       " '256': 9,\n",
       " '257': 19,\n",
       " '258': 4,\n",
       " '259': 2,\n",
       " '26': 3,\n",
       " '260': 23,\n",
       " '261': 1,\n",
       " '262': 15,\n",
       " '263': 15,\n",
       " '27': 16,\n",
       " '28': 4,\n",
       " '29': 3,\n",
       " '3': 2,\n",
       " '30': 16,\n",
       " '31': 2,\n",
       " '32': 2,\n",
       " '33': 19,\n",
       " '34': 19,\n",
       " '35': 13,\n",
       " '36': 9,\n",
       " '37': 9,\n",
       " '38': 4,\n",
       " '39': 13,\n",
       " '4': 1,\n",
       " '40': 19,\n",
       " '41': 20,\n",
       " '42': 22,\n",
       " '43': 12,\n",
       " '44': 5,\n",
       " '45': 1,\n",
       " '46': 2,\n",
       " '47': 14,\n",
       " '48': 0,\n",
       " '49': 19,\n",
       " '5': 5,\n",
       " '50': 0,\n",
       " '51': 2,\n",
       " '52': 19,\n",
       " '53': 8,\n",
       " '54': 19,\n",
       " '55': 3,\n",
       " '56': 23,\n",
       " '58': 2,\n",
       " '59': 14,\n",
       " '6': 6,\n",
       " '60': 14,\n",
       " '61': 13,\n",
       " '62': 13,\n",
       " '63': 13,\n",
       " '64': 8,\n",
       " '65': 19,\n",
       " '66': 19,\n",
       " '67': 3,\n",
       " '68': 21,\n",
       " '69': 14,\n",
       " '7': 7,\n",
       " '70': 23,\n",
       " '71': 13,\n",
       " '72': 13,\n",
       " '73': 8,\n",
       " '74': 20,\n",
       " '75': 20,\n",
       " '76': 13,\n",
       " '77': 13,\n",
       " '78': 14,\n",
       " '79': 1,\n",
       " '8': 7,\n",
       " '80': 9,\n",
       " '81': 2,\n",
       " '82': 23,\n",
       " '83': 23,\n",
       " '84': 5,\n",
       " '85': 13,\n",
       " '86': 16,\n",
       " '87': 1,\n",
       " '88': 1,\n",
       " '89': 13,\n",
       " '9': 8,\n",
       " '90': 21,\n",
       " '91': 13,\n",
       " '92': 8,\n",
       " '93': 8,\n",
       " '94': 10,\n",
       " '95': 8,\n",
       " '96': 23,\n",
       " '97': 19,\n",
       " '98': 8,\n",
       " '99': 5}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attachment = torch.argmax(F.softmax(model.attachment_matrix, dim=1), dim=1).detach().cpu().numpy()\n",
    "community_assignment = dict(zip(targetColumns, attachment))\n",
    "community_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 comm\n",
    "# 0.505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 comm\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
