{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'lr': 0.0012098123619624396,\n",
    " 'layers': 2,\n",
    " 'step_size': 21,\n",
    " 'gamma': 0.5302067528042456,\n",
    " 'bptt': 12,\n",
    " 'dropout': 0.35583243487203325}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001803241035696008"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['lr'] = config['lr'] * config['gamma'] **3\n",
    "config['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/home/urwa/Documents/side_projects/urban/data/featureData/lga.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 1045)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>...</th>\n",
       "      <th>91_lag_3</th>\n",
       "      <th>92_lag_3</th>\n",
       "      <th>93_lag_3</th>\n",
       "      <th>94_lag_3</th>\n",
       "      <th>95_lag_3</th>\n",
       "      <th>96_lag_3</th>\n",
       "      <th>97_lag_3</th>\n",
       "      <th>98_lag_3</th>\n",
       "      <th>99_lag_3</th>\n",
       "      <th>arrival_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1045 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour  1  10  100  101  102  106  107  108  ...  91_lag_3  \\\n",
       "0  2018-01-01     3  0   0    0    0    0    0    0    0  ...       0.0   \n",
       "1  2018-01-01     4  1   0    0    0    0    0    0    0  ...       0.0   \n",
       "2  2018-01-01     5  1   0    0    0    0    0    0    0  ...       0.0   \n",
       "\n",
       "   92_lag_3  93_lag_3  94_lag_3  95_lag_3  96_lag_3  97_lag_3  98_lag_3  \\\n",
       "0       1.0       0.0       1.0       0.0       0.0       1.0       0.0   \n",
       "1       1.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   99_lag_3  arrival_lag_3  \n",
       "0       0.0            3.0  \n",
       "1       0.0            0.0  \n",
       "2       0.0            1.0  \n",
       "\n",
       "[3 rows x 1045 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_columns = [c for c in dataset.columns if 'lag' in c]\n",
    "len(lag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 271)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[[c for c in dataset.columns if c not in lag_columns]]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DateColumns = ['Date']\n",
    "\n",
    "ext_columns = ['Dow', 'arrival','maxtemp', 'mintemp', 'avgtemp', 'departure', 'hdd',\n",
    "       'cdd', 'participation', 'newsnow', 'snowdepth', 'ifSnow']\n",
    "\n",
    "targetColumns = [c for c in dataset.columns if c not in ext_columns and \\\n",
    "                c not in DateColumns and c not in lag_columns and c != 'Hour']\n",
    "len(targetColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cols = [c for c in dataset.columns if c not in targetColumns and c not in DateColumns]\n",
    "len(features_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(x,y, tw):\n",
    "    inout_seq = []\n",
    "    L = len(x)\n",
    "    for i in range(L-tw):\n",
    "        train_seq_x = x[i:i+tw]\n",
    "        train_seq_y = y[i:i+tw]\n",
    "#         train_seq = torch.cat((train_seq_x,train_seq_y),axis=1)\n",
    "        \n",
    "#         train_label = y[i+tw:i+tw+1]\n",
    "        train_label = y[i+1:i+tw+1]\n",
    "        inout_seq.append((train_seq_x, train_seq_y ,train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=100, num_layers=1, dropout=0):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.hidden_cell = (torch.zeros(num_layers,1,self.hidden_size).to(device),\n",
    "                    torch.zeros(num_layers,1,self.hidden_size).to(device))\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.hidden_cell = (torch.zeros(self.num_layers,1,self.hidden_size).to(device),\n",
    "                    torch.zeros(self.num_layers,1,self.hidden_size).to(device))\n",
    "           \n",
    "        lstm_out, self.hidden_cell = self.lstm(x.view(len(x) ,1, -1), self.hidden_cell)\n",
    "        \n",
    "        return lstm_out, self.hidden_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphPrediction(nn.Module):\n",
    "    def __init__(self, feat_size=1, hidden_layer_size=100, network_size=1, layers=1, communities=10, ensembles=1, dropout=0, at_mat=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # aggregation\n",
    "        if at_mat != None:\n",
    "            self.attachment_matrix = torch.nn.Parameter(at_mat)\n",
    "            self.attachment_matrix.requires_grad = False\n",
    "        else:\n",
    "            self.attachment_matrix = torch.nn.Parameter(torch.randn(network_size,communities))\n",
    "            self.attachment_matrix.requires_grad = True\n",
    "        \n",
    "        lstm_input = communities + feat_size\n",
    "        \n",
    "        self.ensembles = ensembles\n",
    "        self.lstms = nn.ModuleList()\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(ensembles):\n",
    "             self.lstms.append(LSTM(input_size=lstm_input, hidden_size=hidden_layer_size, num_layers=layers))\n",
    "             self.linears.append(nn.Linear(hidden_layer_size, network_size))\n",
    "            \n",
    "\n",
    "    def forward(self, input_seq, feat):\n",
    "        \n",
    "        w = F.softmax(self.attachment_matrix, dim=1)\n",
    "        x = torch.matmul(input_seq, self.attachment_matrix)\n",
    "        x = torch.cat((x,feat),axis=1)\n",
    "        x = x.view(len(input_seq) ,1, -1)\n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(self.ensembles):\n",
    "            if torch.randn(1) < 0.7 or i==0 or not self.training:\n",
    "                lstm_out, self.hidden_cell = self.lstms[i](x)\n",
    "                y = self.linears[i](lstm_out.view(len(input_seq), -1))\n",
    "                predictions.append(y)\n",
    "        \n",
    "        predictions = torch.stack(predictions)\n",
    "#         print(predictions.shape)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    with torch.no_grad():\n",
    "        for feat,seq, labels in test_inout_seq:\n",
    "#             model.hidden = (torch.zeros(layers, 1, model.hidden_layer_size),\n",
    "#                             torch.zeros(layers, 1, model.hidden_layer_size))\n",
    "            y = model(seq,feat).mean(dim=0)[-1]\n",
    "    \n",
    "            prediction.append(y)\n",
    "\n",
    "    y_test_ = torch.stack([labels[-1] for feat,seq, labels in test_inout_seq], axis=0).detach().cpu().numpy()\n",
    "    y_pred_ = torch.stack(prediction).detach().cpu().numpy()\n",
    "\n",
    "    res = y_pred_ - y_test_\n",
    "    r2 = r2_score(y_test_, y_pred_, multioutput='variance_weighted')\n",
    "    rmse = mean_squared_error(y_test_, y_pred_)\n",
    "    mae = mean_absolute_error(y_test_, y_pred_)\n",
    "#     print(\"r2: \",r2)\n",
    "    return (res, r2, rmse, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_at_mat(targetColumns):\n",
    "    comms = pd.read_csv('/home/urwa/Documents/side_projects/urban/UrbanTemporalNetworks/Data/ZonetoComm.csv')  \n",
    "    communities = list(set(comms.start_community))\n",
    "\n",
    "    mapping = dict(zip(comms.start_id, comms.start_community))\n",
    "    comm_to_index = dict(zip(communities,range(len(communities))))\n",
    "    col_to_index = dict(zip(targetColumns,range(len(targetColumns))))\n",
    "\n",
    "    attach = torch.zeros(len(targetColumns), len(communities))\n",
    "\n",
    "    for t_c in targetColumns:\n",
    "        com = mapping[int(t_c)]\n",
    "        x_i = col_to_index[t_c]\n",
    "        y_i = comm_to_index[com]\n",
    "\n",
    "        attach[x_i,y_i] = 1\n",
    "\n",
    "    return attach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = '/home/urwa/Documents/side_projects/urban/urban_traffic_prediciton/ensemble/bayesian_opt/lga.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  1\n",
      "\n",
      " train test split\n",
      "(8016, 271)\n",
      "(741, 271)\n",
      "\n",
      " \n",
      "torch.Size([8016, 13])\n",
      "torch.Size([8016, 257])\n",
      "torch.Size([741, 13])\n",
      "torch.Size([741, 257])\n",
      "\n",
      " sequences\n",
      "torch.Size([12, 13]) torch.Size([12, 257]) torch.Size([12, 257])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([257, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.8431269396317222\n",
      "epoch:   0 loss: 1.28851068 r2: 0.800 rmse: 3.004 mae: 0.759\n",
      "epoch:   1 loss: 1.27635264 r2: 0.804 rmse: 2.932 mae: 0.754\n",
      "epoch:   2 loss: 1.27958429 r2: 0.804 rmse: 2.942 mae: 0.756\n",
      "epoch:   3 loss: 1.24049485 r2: 0.805 rmse: 2.918 mae: 0.755\n",
      "epoch:   4 loss: 1.22784507 r2: 0.806 rmse: 2.909 mae: 0.755\n",
      "epoch:   5 loss: 1.24204397 r2: 0.803 rmse: 2.948 mae: 0.758\n",
      "epoch:   6 loss: 1.21571994 r2: 0.806 rmse: 2.909 mae: 0.756\n",
      "epoch:   7 loss: 1.21204007 r2: 0.804 rmse: 2.933 mae: 0.757\n",
      "epoch:   8 loss: 1.20673060 r2: 0.804 rmse: 2.932 mae: 0.758\n",
      "epoch:   9 loss: 1.15778208 r2: 0.804 rmse: 2.941 mae: 0.759\n",
      "epoch:  10 loss: 1.19079804 r2: 0.804 rmse: 2.943 mae: 0.760\n",
      "epoch:  11 loss: 1.18896306 r2: 0.804 rmse: 2.937 mae: 0.759\n",
      "epoch:  12 loss: 1.16834593 r2: 0.805 rmse: 2.929 mae: 0.758\n",
      "epoch:  13 loss: 1.16468823 r2: 0.803 rmse: 2.948 mae: 0.760\n",
      "epoch:  14 loss: 1.14987159 r2: 0.803 rmse: 2.951 mae: 0.761\n",
      "epoch:  14 loss: 1.1498715878\n",
      "bet_r2:  0.8058951054744332\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  2\n",
      "\n",
      " train test split\n",
      "(8085, 271)\n",
      "(672, 271)\n",
      "\n",
      " \n",
      "torch.Size([8085, 13])\n",
      "torch.Size([8085, 257])\n",
      "torch.Size([672, 13])\n",
      "torch.Size([672, 257])\n",
      "\n",
      " sequences\n",
      "torch.Size([12, 13]) torch.Size([12, 257]) torch.Size([12, 257])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([257, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.8165370965800411\n",
      "epoch:   0 loss: 1.27105057 r2: 0.778 rmse: 3.468 mae: 0.823\n",
      "epoch:   1 loss: 1.27710414 r2: 0.781 rmse: 3.436 mae: 0.819\n",
      "epoch:   2 loss: 1.28061473 r2: 0.780 rmse: 3.437 mae: 0.819\n",
      "epoch:   3 loss: 1.26387465 r2: 0.783 rmse: 3.393 mae: 0.815\n",
      "epoch:   4 loss: 1.25425553 r2: 0.782 rmse: 3.417 mae: 0.817\n",
      "epoch:   5 loss: 1.24494421 r2: 0.785 rmse: 3.368 mae: 0.813\n",
      "epoch:   6 loss: 1.22160590 r2: 0.786 rmse: 3.349 mae: 0.813\n",
      "epoch:   7 loss: 1.20345736 r2: 0.788 rmse: 3.322 mae: 0.810\n",
      "epoch:   8 loss: 1.20671332 r2: 0.786 rmse: 3.353 mae: 0.812\n",
      "epoch:   9 loss: 1.20082736 r2: 0.789 rmse: 3.306 mae: 0.809\n",
      "epoch:  10 loss: 1.17369628 r2: 0.788 rmse: 3.322 mae: 0.810\n",
      "epoch:  11 loss: 1.18043339 r2: 0.790 rmse: 3.292 mae: 0.809\n",
      "epoch:  12 loss: 1.17529488 r2: 0.788 rmse: 3.317 mae: 0.810\n",
      "epoch:  13 loss: 1.18407416 r2: 0.789 rmse: 3.305 mae: 0.809\n",
      "epoch:  14 loss: 1.16674697 r2: 0.788 rmse: 3.314 mae: 0.810\n",
      "epoch:  14 loss: 1.1667469740\n",
      "bet_r2:  0.78973508119702\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  3\n",
      "\n",
      " train test split\n",
      "(8013, 271)\n",
      "(744, 271)\n",
      "\n",
      " \n",
      "torch.Size([8013, 13])\n",
      "torch.Size([8013, 257])\n",
      "torch.Size([744, 13])\n",
      "torch.Size([744, 257])\n",
      "\n",
      " sequences\n",
      "torch.Size([12, 13]) torch.Size([12, 257]) torch.Size([12, 257])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([257, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.8449388411569525\n",
      "epoch:   0 loss: 1.29839838 r2: 0.826 rmse: 3.015 mae: 0.782\n",
      "epoch:   1 loss: 1.26638424 r2: 0.827 rmse: 3.005 mae: 0.781\n",
      "epoch:   2 loss: 1.26623535 r2: 0.826 rmse: 3.022 mae: 0.781\n",
      "epoch:   3 loss: 1.26263964 r2: 0.826 rmse: 3.015 mae: 0.781\n",
      "epoch:   4 loss: 1.24935091 r2: 0.826 rmse: 3.012 mae: 0.780\n",
      "epoch:   5 loss: 1.24900651 r2: 0.826 rmse: 3.022 mae: 0.781\n",
      "epoch:   6 loss: 1.20748508 r2: 0.827 rmse: 3.003 mae: 0.781\n",
      "epoch:   7 loss: 1.19976664 r2: 0.826 rmse: 3.013 mae: 0.781\n",
      "epoch:   8 loss: 1.19691968 r2: 0.826 rmse: 3.017 mae: 0.782\n",
      "epoch:   9 loss: 1.18065941 r2: 0.827 rmse: 3.003 mae: 0.781\n",
      "epoch:  10 loss: 1.21056294 r2: 0.826 rmse: 3.015 mae: 0.782\n",
      "epoch:  11 loss: 1.19697762 r2: 0.825 rmse: 3.027 mae: 0.783\n",
      "epoch:  12 loss: 1.16330886 r2: 0.826 rmse: 3.015 mae: 0.782\n",
      "epoch:  13 loss: 1.18923926 r2: 0.826 rmse: 3.016 mae: 0.783\n",
      "epoch:  14 loss: 1.18440378 r2: 0.826 rmse: 3.017 mae: 0.783\n",
      "epoch:  14 loss: 1.1844037771\n",
      "bet_r2:  0.8268052298182693\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  4\n",
      "\n",
      " train test split\n",
      "(8037, 271)\n",
      "(720, 271)\n",
      "\n",
      " \n",
      "torch.Size([8037, 13])\n",
      "torch.Size([8037, 257])\n",
      "torch.Size([720, 13])\n",
      "torch.Size([720, 257])\n",
      "\n",
      " sequences\n",
      "torch.Size([12, 13]) torch.Size([12, 257]) torch.Size([12, 257])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([257, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.8529050952798969\n",
      "epoch:   0 loss: 1.30990803 r2: 0.833 rmse: 3.261 mae: 0.847\n",
      "epoch:   1 loss: 1.28705645 r2: 0.834 rmse: 3.252 mae: 0.846\n",
      "epoch:   2 loss: 1.27534425 r2: 0.833 rmse: 3.260 mae: 0.847\n",
      "epoch:   3 loss: 1.25602400 r2: 0.834 rmse: 3.244 mae: 0.846\n",
      "epoch:   4 loss: 1.25070798 r2: 0.833 rmse: 3.261 mae: 0.847\n",
      "epoch:   5 loss: 1.23255002 r2: 0.834 rmse: 3.243 mae: 0.846\n",
      "epoch:   6 loss: 1.21201134 r2: 0.834 rmse: 3.252 mae: 0.847\n",
      "epoch:   7 loss: 1.20511436 r2: 0.833 rmse: 3.269 mae: 0.848\n",
      "epoch:   8 loss: 1.21733618 r2: 0.833 rmse: 3.259 mae: 0.848\n",
      "epoch:   9 loss: 1.21033609 r2: 0.834 rmse: 3.253 mae: 0.847\n",
      "epoch:  10 loss: 1.20732784 r2: 0.833 rmse: 3.266 mae: 0.848\n",
      "epoch:  11 loss: 1.20686626 r2: 0.833 rmse: 3.264 mae: 0.848\n",
      "epoch:  12 loss: 1.18193769 r2: 0.833 rmse: 3.271 mae: 0.849\n",
      "epoch:  13 loss: 1.17324460 r2: 0.832 rmse: 3.293 mae: 0.851\n",
      "epoch:  14 loss: 1.16542602 r2: 0.832 rmse: 3.283 mae: 0.850\n",
      "epoch:  14 loss: 1.1654260159\n",
      "bet_r2:  0.8343322582009949\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  5\n",
      "\n",
      " train test split\n",
      "(8013, 271)\n",
      "(744, 271)\n",
      "\n",
      " \n",
      "torch.Size([8013, 13])\n",
      "torch.Size([8013, 257])\n",
      "torch.Size([744, 13])\n",
      "torch.Size([744, 257])\n",
      "\n",
      " sequences\n",
      "torch.Size([12, 13]) torch.Size([12, 257]) torch.Size([12, 257])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([257, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.858320858694963\n",
      "epoch:   0 loss: 1.30554628 r2: 0.840 rmse: 3.399 mae: 0.861\n",
      "epoch:   1 loss: 1.27434087 r2: 0.839 rmse: 3.410 mae: 0.861\n",
      "epoch:   2 loss: 1.28364372 r2: 0.839 rmse: 3.413 mae: 0.862\n",
      "epoch:   3 loss: 1.24885845 r2: 0.839 rmse: 3.415 mae: 0.862\n",
      "epoch:   4 loss: 1.24918568 r2: 0.838 rmse: 3.438 mae: 0.864\n",
      "epoch:   5 loss: 1.23750269 r2: 0.839 rmse: 3.425 mae: 0.863\n",
      "epoch:   6 loss: 1.21186149 r2: 0.839 rmse: 3.413 mae: 0.862\n",
      "epoch:   7 loss: 1.22715330 r2: 0.839 rmse: 3.410 mae: 0.862\n",
      "epoch:   8 loss: 1.21810234 r2: 0.839 rmse: 3.423 mae: 0.863\n",
      "epoch:   9 loss: 1.20152414 r2: 0.838 rmse: 3.434 mae: 0.864\n",
      "epoch:  10 loss: 1.20875525 r2: 0.839 rmse: 3.427 mae: 0.864\n",
      "epoch:  11 loss: 1.17869294 r2: 0.838 rmse: 3.433 mae: 0.864\n",
      "epoch:  12 loss: 1.17599607 r2: 0.838 rmse: 3.437 mae: 0.865\n",
      "epoch:  13 loss: 1.18396759 r2: 0.838 rmse: 3.430 mae: 0.865\n",
      "epoch:  14 loss: 1.16797709 r2: 0.838 rmse: 3.433 mae: 0.865\n",
      "epoch:  14 loss: 1.1679770947\n",
      "bet_r2:  0.8398195851008128\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  6\n",
      "\n",
      " train test split\n",
      "(8037, 271)\n",
      "(720, 271)\n",
      "\n",
      " \n",
      "torch.Size([8037, 13])\n",
      "torch.Size([8037, 257])\n",
      "torch.Size([720, 13])\n",
      "torch.Size([720, 257])\n",
      "\n",
      " sequences\n",
      "torch.Size([12, 13]) torch.Size([12, 257]) torch.Size([12, 257])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([257, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.848742728075451\n",
      "epoch:   0 loss: 1.30138016 r2: 0.835 rmse: 3.499 mae: 0.859\n",
      "epoch:   1 loss: 1.27366674 r2: 0.834 rmse: 3.518 mae: 0.861\n",
      "epoch:   2 loss: 1.26380169 r2: 0.834 rmse: 3.516 mae: 0.861\n",
      "epoch:   3 loss: 1.24461222 r2: 0.832 rmse: 3.554 mae: 0.864\n",
      "epoch:   4 loss: 1.24317479 r2: 0.832 rmse: 3.559 mae: 0.865\n",
      "epoch:   5 loss: 1.22764575 r2: 0.833 rmse: 3.547 mae: 0.863\n",
      "epoch:   6 loss: 1.22722268 r2: 0.832 rmse: 3.565 mae: 0.865\n",
      "epoch:   7 loss: 1.19548929 r2: 0.832 rmse: 3.566 mae: 0.866\n",
      "epoch:   8 loss: 1.19054842 r2: 0.832 rmse: 3.563 mae: 0.865\n",
      "epoch:   9 loss: 1.19845772 r2: 0.832 rmse: 3.571 mae: 0.867\n",
      "epoch:  10 loss: 1.19442511 r2: 0.832 rmse: 3.570 mae: 0.866\n",
      "epoch:  11 loss: 1.16956306 r2: 0.833 rmse: 3.541 mae: 0.864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  12 loss: 1.17277563 r2: 0.832 rmse: 3.561 mae: 0.866\n",
      "epoch:  13 loss: 1.17111087 r2: 0.832 rmse: 3.564 mae: 0.866\n",
      "epoch:  14 loss: 1.14025342 r2: 0.831 rmse: 3.579 mae: 0.868\n",
      "epoch:  14 loss: 1.1402534246\n",
      "bet_r2:  0.8348994957079321\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  7\n",
      "\n",
      " train test split\n",
      "(8013, 271)\n",
      "(744, 271)\n",
      "\n",
      " \n",
      "torch.Size([8013, 13])\n",
      "torch.Size([8013, 257])\n",
      "torch.Size([744, 13])\n",
      "torch.Size([744, 257])\n",
      "\n",
      " sequences\n",
      "torch.Size([12, 13]) torch.Size([12, 257]) torch.Size([12, 257])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([257, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.8382378031041606\n",
      "epoch:   0 loss: 1.30665851 r2: 0.817 rmse: 2.911 mae: 0.821\n",
      "epoch:   1 loss: 1.27128124 r2: 0.817 rmse: 2.906 mae: 0.822\n",
      "epoch:   2 loss: 1.27771342 r2: 0.817 rmse: 2.916 mae: 0.823\n",
      "epoch:   3 loss: 1.23989022 r2: 0.817 rmse: 2.913 mae: 0.824\n",
      "epoch:   4 loss: 1.26124358 r2: 0.816 rmse: 2.925 mae: 0.824\n"
     ]
    }
   ],
   "source": [
    "bptt = config['bptt']\n",
    "\n",
    "R2List = []\n",
    "residual_list = []\n",
    "\n",
    "for m in range(1,13):\n",
    "    month_index  = pd.to_datetime(dataset.Date).dt.month == m\n",
    "    \n",
    "    print('-------------------------------------------------')\n",
    "    print('-------------------------------------------------')\n",
    "    print(\"Month: \", m)\n",
    "\n",
    "\n",
    "    trainData = dataset[~month_index]\n",
    "    testData = dataset[month_index]\n",
    "\n",
    "    print(\"\\n train test split\")\n",
    "    print(trainData.shape)\n",
    "    print(testData.shape)\n",
    "\n",
    "\n",
    "    print(\"\\n \")\n",
    "    X_train = trainData[features_cols].values\n",
    "    X_train = torch.tensor(X_train).float().to(device)\n",
    "    print(X_train.shape)\n",
    "\n",
    "    y_train = trainData[targetColumns].values\n",
    "    y_train = torch.tensor(y_train).float().to(device)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    X_test = testData[features_cols].values\n",
    "    X_test = torch.tensor(X_test).float().to(device)\n",
    "    print(X_test.shape)\n",
    "\n",
    "    y_test = testData[targetColumns].values\n",
    "    y_test = torch.tensor(y_test).float().to(device)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    \n",
    "    train_inout_seq = create_inout_sequences(X_train,y_train, bptt)\n",
    "    \n",
    "    test_inout_seq = create_inout_sequences(X_test,y_test, bptt)\n",
    "    print(\"\\n sequences\")\n",
    "    print(train_inout_seq[0][0].shape,train_inout_seq[0][1].shape, train_inout_seq[0][2].shape)\n",
    "    \n",
    "    at_mat = get_at_mat(targetColumns)\n",
    "    print(\"\\nattachment matrix\")\n",
    "    print(at_mat.shape)\n",
    "    \n",
    "    \n",
    "    layers = config['layers']\n",
    "    communities = 24\n",
    "    network_size = len(targetColumns)\n",
    "    feat_size = len(features_cols)\n",
    "    ensembles=10\n",
    "    dropout = config['dropout']\n",
    "\n",
    "    model = GraphPrediction(feat_size = feat_size, hidden_layer_size=100,\n",
    "                 network_size=network_size, layers=layers,\n",
    "                communities=communities, ensembles=ensembles, dropout=dropout, at_mat=at_mat).to(device)\n",
    "\n",
    "    loss_function = nn.L1Loss()   \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config['step_size'], gamma=config['gamma'])\n",
    "    print(\"\\n model inititalized\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(pretrained_weights))\n",
    "    print(\"\\n model loaded\")\n",
    "    \n",
    "    residual, r2, rmse, mae = evaluate(model)\n",
    "    print(\"Pretraining R2: \",r2)\n",
    "    \n",
    "    \n",
    "    best_r2 = 0\n",
    "    best_residual = residual\n",
    "#     torch.save(model.state_dict(), 'data/'+'lga_'+str(m)+'.pt')\n",
    "#     np.save('data/'+'lga_'+str(m)+'.npy', best_residual)\n",
    "    \n",
    "    \n",
    "    epochs = 15\n",
    "\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        for feat,seq, labels in train_inout_seq:\n",
    "            optimizer.zero_grad()\n",
    "    #         model.hidden_cell = (torch.zeros(layers, 1, model.hidden_layer_size).to(device),\n",
    "    #                         torch.zeros(layers, 1, model.hidden_layer_size).to(device))\n",
    "\n",
    "            y_pred = model(seq, feat)\n",
    "            labels = labels.repeat(y_pred.shape[0],1,1)\n",
    "\n",
    "            single_loss = loss_function(y_pred, labels)\n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        residual, r2, rmse, mae = evaluate(model)\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f} r2: {r2:5.3f} rmse: {rmse:5.3f} mae: {mae:5.3f}')\n",
    "        \n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_residual = residual\n",
    "            torch.save(model.state_dict(), 'data/'+'lga_'+str(m)+'.pt')\n",
    "            np.save('data/'+'lga_'+str(m)+'.npy', best_residual)\n",
    "\n",
    "\n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "    print(\"bet_r2: \", best_r2)\n",
    "\n",
    "    R2List.append(best_r2)\n",
    "    residual_list.append(best_residual)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(attachment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 linear\n",
    "# 0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 linear\n",
    "# 0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 linear + RELU\n",
    "# 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 linear bptt = 24\n",
    "# 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble\n",
    "#0.53228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO\n",
    "# other hubs\n",
    "# ensemble model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
