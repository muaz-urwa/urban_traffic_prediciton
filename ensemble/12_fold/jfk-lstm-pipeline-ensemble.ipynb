{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'lr': 0.00034439316653688684,\n",
    " 'layers': 3,\n",
    " 'step_size': 11,\n",
    " 'gamma': 0.761795969995615,\n",
    " 'bptt': 19,\n",
    " 'dropout': 0.1227497445640586}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.835840748963752e-05"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['lr'] = config['lr'] * config['gamma'] **5\n",
    "config['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/home/urwa/Documents/side_projects/urban/data/featureData/jfk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 1049)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>...</th>\n",
       "      <th>91_lag_3</th>\n",
       "      <th>92_lag_3</th>\n",
       "      <th>93_lag_3</th>\n",
       "      <th>94_lag_3</th>\n",
       "      <th>95_lag_3</th>\n",
       "      <th>96_lag_3</th>\n",
       "      <th>97_lag_3</th>\n",
       "      <th>98_lag_3</th>\n",
       "      <th>99_lag_3</th>\n",
       "      <th>arrival_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour  1  10  100  101  102  106  107  108  ...  91_lag_3  \\\n",
       "0  2018-01-01     3  0   0    0    0    0    0    0    0  ...       1.0   \n",
       "1  2018-01-01     4  0   3    0    0    1    0    0    1  ...       4.0   \n",
       "2  2018-01-01     5  0   4    0    0    1    2    3    1  ...       0.0   \n",
       "\n",
       "   92_lag_3  93_lag_3  94_lag_3  95_lag_3  96_lag_3  97_lag_3  98_lag_3  \\\n",
       "0       1.0       0.0       1.0       6.0       0.0       1.0       0.0   \n",
       "1       1.0       0.0       0.0       2.0       0.0       0.0       0.0   \n",
       "2       0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "\n",
       "   99_lag_3  arrival_lag_3  \n",
       "0       0.0            6.0  \n",
       "1       0.0            6.0  \n",
       "2       0.0            2.0  \n",
       "\n",
       "[3 rows x 1049 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "777"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_columns = [c for c in dataset.columns if 'lag' in c]\n",
    "len(lag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 272)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[[c for c in dataset.columns if c not in lag_columns]]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DateColumns = ['Date']\n",
    "\n",
    "ext_columns = ['Dow', 'arrival','maxtemp', 'mintemp', 'avgtemp', 'departure', 'hdd',\n",
    "       'cdd', 'participation', 'newsnow', 'snowdepth', 'ifSnow']\n",
    "\n",
    "targetColumns = [c for c in dataset.columns if c not in ext_columns and \\\n",
    "                c not in DateColumns and c not in lag_columns and c != 'Hour']\n",
    "len(targetColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cols = [c for c in dataset.columns if c not in targetColumns and c not in DateColumns]\n",
    "len(features_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(x,y, tw):\n",
    "    inout_seq = []\n",
    "    L = len(x)\n",
    "    for i in range(L-tw):\n",
    "        train_seq_x = x[i:i+tw]\n",
    "        train_seq_y = y[i:i+tw]\n",
    "#         train_seq = torch.cat((train_seq_x,train_seq_y),axis=1)\n",
    "        \n",
    "#         train_label = y[i+tw:i+tw+1]\n",
    "        train_label = y[i+1:i+tw+1]\n",
    "        inout_seq.append((train_seq_x, train_seq_y ,train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=100, num_layers=1, dropout=0):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.hidden_cell = (torch.zeros(num_layers,1,self.hidden_size).to(device),\n",
    "                    torch.zeros(num_layers,1,self.hidden_size).to(device))\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.hidden_cell = (torch.zeros(self.num_layers,1,self.hidden_size).to(device),\n",
    "                    torch.zeros(self.num_layers,1,self.hidden_size).to(device))\n",
    "           \n",
    "        lstm_out, self.hidden_cell = self.lstm(x.view(len(x) ,1, -1), self.hidden_cell)\n",
    "        \n",
    "        return lstm_out, self.hidden_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphPrediction(nn.Module):\n",
    "    def __init__(self, feat_size=1, hidden_layer_size=100, network_size=1, layers=1, communities=10, ensembles=1, dropout=0, at_mat=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # aggregation\n",
    "        if at_mat != None:\n",
    "            self.attachment_matrix = torch.nn.Parameter(at_mat)\n",
    "            self.attachment_matrix.requires_grad = False\n",
    "        else:\n",
    "            self.attachment_matrix = torch.nn.Parameter(torch.randn(network_size,communities))\n",
    "            self.attachment_matrix.requires_grad = True\n",
    "        \n",
    "        lstm_input = communities + feat_size\n",
    "        \n",
    "        self.ensembles = ensembles\n",
    "        self.lstms = nn.ModuleList()\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(ensembles):\n",
    "             self.lstms.append(LSTM(input_size=lstm_input, hidden_size=hidden_layer_size, num_layers=layers))\n",
    "             self.linears.append(nn.Linear(hidden_layer_size, network_size))\n",
    "            \n",
    "\n",
    "    def forward(self, input_seq, feat):\n",
    "        \n",
    "        w = F.softmax(self.attachment_matrix, dim=1)\n",
    "        x = torch.matmul(input_seq, self.attachment_matrix)\n",
    "        x = torch.cat((x,feat),axis=1)\n",
    "        x = x.view(len(input_seq) ,1, -1)\n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(self.ensembles):\n",
    "            if torch.randn(1) < 0.7 or i==0 or not self.training:\n",
    "                lstm_out, self.hidden_cell = self.lstms[i](x)\n",
    "                y = self.linears[i](lstm_out.view(len(input_seq), -1))\n",
    "                predictions.append(y)\n",
    "        \n",
    "        predictions = torch.stack(predictions)\n",
    "#         print(predictions.shape)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    with torch.no_grad():\n",
    "        for feat,seq, labels in test_inout_seq:\n",
    "#             model.hidden = (torch.zeros(layers, 1, model.hidden_layer_size),\n",
    "#                             torch.zeros(layers, 1, model.hidden_layer_size))\n",
    "            y = model(seq,feat).mean(dim=0)[-1]\n",
    "    \n",
    "            prediction.append(y)\n",
    "\n",
    "    y_test_ = torch.stack([labels[-1] for feat,seq, labels in test_inout_seq], axis=0).detach().cpu().numpy()\n",
    "    y_pred_ = torch.stack(prediction).detach().cpu().numpy()\n",
    "\n",
    "    res = y_pred_ - y_test_\n",
    "    r2 = r2_score(y_test_, y_pred_, multioutput='variance_weighted')\n",
    "    rmse = mean_squared_error(y_test_, y_pred_)\n",
    "    mae = mean_absolute_error(y_test_, y_pred_)\n",
    "#     print(\"r2: \",r2)\n",
    "    return (res, r2, rmse, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_at_mat(targetColumns):\n",
    "    comms = pd.read_csv('/home/urwa/Documents/side_projects/urban/UrbanTemporalNetworks/Data/ZonetoComm.csv')  \n",
    "    communities = list(set(comms.start_community))\n",
    "\n",
    "    mapping = dict(zip(comms.start_id, comms.start_community))\n",
    "    comm_to_index = dict(zip(communities,range(len(communities))))\n",
    "    col_to_index = dict(zip(targetColumns,range(len(targetColumns))))\n",
    "\n",
    "    attach = torch.zeros(len(targetColumns), len(communities))\n",
    "\n",
    "    for t_c in targetColumns:\n",
    "        com = mapping[int(t_c)]\n",
    "        x_i = col_to_index[t_c]\n",
    "        y_i = comm_to_index[com]\n",
    "\n",
    "        attach[x_i,y_i] = 1\n",
    "\n",
    "    return attach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = '/home/urwa/Documents/side_projects/urban/urban_traffic_prediciton/ensemble/bayesian_opt/jfk.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  1\n",
      "\n",
      " train test split\n",
      "(8016, 272)\n",
      "(741, 272)\n",
      "\n",
      " \n",
      "torch.Size([8016, 13])\n",
      "torch.Size([8016, 258])\n",
      "torch.Size([741, 13])\n",
      "torch.Size([741, 258])\n",
      "\n",
      " sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 258]) torch.Size([19, 258])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([258, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.7204843593885372\n",
      "epoch:   0 loss: 1.34565318 r2: 0.614 rmse: 2.758 mae: 0.926\n",
      "epoch:   1 loss: 1.34231913 r2: 0.620 rmse: 2.714 mae: 0.919\n",
      "epoch:   2 loss: 1.29094350 r2: 0.622 rmse: 2.704 mae: 0.917\n",
      "epoch:   3 loss: 1.27928150 r2: 0.623 rmse: 2.698 mae: 0.917\n",
      "epoch:   4 loss: 1.26050305 r2: 0.623 rmse: 2.693 mae: 0.915\n",
      "epoch:   5 loss: 1.25294054 r2: 0.623 rmse: 2.693 mae: 0.915\n",
      "epoch:   6 loss: 1.23628235 r2: 0.624 rmse: 2.688 mae: 0.915\n",
      "epoch:   7 loss: 1.22186852 r2: 0.625 rmse: 2.684 mae: 0.913\n",
      "epoch:   8 loss: 1.22072709 r2: 0.625 rmse: 2.682 mae: 0.913\n",
      "epoch:   9 loss: 1.21845472 r2: 0.624 rmse: 2.685 mae: 0.913\n",
      "epoch:  10 loss: 1.20874000 r2: 0.625 rmse: 2.684 mae: 0.913\n",
      "epoch:  11 loss: 1.20241630 r2: 0.628 rmse: 2.657 mae: 0.907\n",
      "epoch:  12 loss: 1.20385456 r2: 0.629 rmse: 2.653 mae: 0.906\n",
      "epoch:  13 loss: 1.19464636 r2: 0.628 rmse: 2.658 mae: 0.906\n",
      "epoch:  14 loss: 1.19504678 r2: 0.629 rmse: 2.650 mae: 0.904\n",
      "epoch:  14 loss: 1.1950467825\n",
      "bet_r2:  0.6292653363941075\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  2\n",
      "\n",
      " train test split\n",
      "(8085, 272)\n",
      "(672, 272)\n",
      "\n",
      " \n",
      "torch.Size([8085, 13])\n",
      "torch.Size([8085, 258])\n",
      "torch.Size([672, 13])\n",
      "torch.Size([672, 258])\n",
      "\n",
      " sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 258]) torch.Size([19, 258])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([258, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.6782887584356649\n",
      "epoch:   0 loss: 1.35138559 r2: 0.589 rmse: 2.626 mae: 0.930\n",
      "epoch:   1 loss: 1.33370721 r2: 0.595 rmse: 2.588 mae: 0.923\n",
      "epoch:   2 loss: 1.29277945 r2: 0.598 rmse: 2.568 mae: 0.920\n",
      "epoch:   3 loss: 1.29133451 r2: 0.599 rmse: 2.557 mae: 0.918\n",
      "epoch:   4 loss: 1.27239323 r2: 0.602 rmse: 2.542 mae: 0.915\n",
      "epoch:   5 loss: 1.25562286 r2: 0.604 rmse: 2.531 mae: 0.913\n",
      "epoch:   6 loss: 1.24205518 r2: 0.604 rmse: 2.527 mae: 0.913\n",
      "epoch:   7 loss: 1.23906183 r2: 0.604 rmse: 2.526 mae: 0.912\n",
      "epoch:   8 loss: 1.22625685 r2: 0.605 rmse: 2.524 mae: 0.912\n",
      "epoch:   9 loss: 1.21920490 r2: 0.607 rmse: 2.511 mae: 0.910\n",
      "epoch:  10 loss: 1.21232462 r2: 0.607 rmse: 2.506 mae: 0.908\n",
      "epoch:  11 loss: 1.21619487 r2: 0.616 rmse: 2.450 mae: 0.899\n",
      "epoch:  12 loss: 1.21004796 r2: 0.619 rmse: 2.430 mae: 0.895\n",
      "epoch:  13 loss: 1.20525038 r2: 0.621 rmse: 2.420 mae: 0.893\n",
      "epoch:  14 loss: 1.19930780 r2: 0.622 rmse: 2.413 mae: 0.892\n",
      "epoch:  14 loss: 1.1993077993\n",
      "bet_r2:  0.6220370443486188\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  3\n",
      "\n",
      " train test split\n",
      "(8013, 272)\n",
      "(744, 272)\n",
      "\n",
      " \n",
      "torch.Size([8013, 13])\n",
      "torch.Size([8013, 258])\n",
      "torch.Size([744, 13])\n",
      "torch.Size([744, 258])\n",
      "\n",
      " sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 258]) torch.Size([19, 258])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([258, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.7115879473604467\n",
      "epoch:   0 loss: 1.35815275 r2: 0.637 rmse: 2.739 mae: 0.934\n",
      "epoch:   1 loss: 1.33899450 r2: 0.642 rmse: 2.704 mae: 0.930\n",
      "epoch:   2 loss: 1.29173350 r2: 0.645 rmse: 2.683 mae: 0.927\n",
      "epoch:   3 loss: 1.28001392 r2: 0.646 rmse: 2.676 mae: 0.926\n",
      "epoch:   4 loss: 1.26204836 r2: 0.647 rmse: 2.669 mae: 0.926\n",
      "epoch:   5 loss: 1.25010872 r2: 0.648 rmse: 2.660 mae: 0.924\n",
      "epoch:   6 loss: 1.24378383 r2: 0.649 rmse: 2.650 mae: 0.922\n",
      "epoch:   7 loss: 1.22980130 r2: 0.648 rmse: 2.656 mae: 0.924\n",
      "epoch:   8 loss: 1.22205555 r2: 0.648 rmse: 2.658 mae: 0.924\n",
      "epoch:   9 loss: 1.21794879 r2: 0.649 rmse: 2.650 mae: 0.922\n",
      "epoch:  10 loss: 1.21064723 r2: 0.649 rmse: 2.649 mae: 0.922\n",
      "epoch:  11 loss: 1.20860493 r2: 0.656 rmse: 2.602 mae: 0.914\n",
      "epoch:  12 loss: 1.20096350 r2: 0.656 rmse: 2.598 mae: 0.913\n",
      "epoch:  13 loss: 1.19431937 r2: 0.657 rmse: 2.593 mae: 0.912\n",
      "epoch:  14 loss: 1.19616997 r2: 0.658 rmse: 2.586 mae: 0.911\n",
      "epoch:  14 loss: 1.1961699724\n",
      "bet_r2:  0.6576641046354088\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  4\n",
      "\n",
      " train test split\n",
      "(8037, 272)\n",
      "(720, 272)\n",
      "\n",
      " \n",
      "torch.Size([8037, 13])\n",
      "torch.Size([8037, 258])\n",
      "torch.Size([720, 13])\n",
      "torch.Size([720, 258])\n",
      "\n",
      " sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 258]) torch.Size([19, 258])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([258, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.7114909992153997\n",
      "epoch:   0 loss: 1.35986960 r2: 0.636 rmse: 2.751 mae: 0.956\n",
      "epoch:   1 loss: 1.33312774 r2: 0.638 rmse: 2.742 mae: 0.955\n",
      "epoch:   2 loss: 1.29951334 r2: 0.641 rmse: 2.720 mae: 0.952\n",
      "epoch:   3 loss: 1.27909458 r2: 0.642 rmse: 2.713 mae: 0.951\n",
      "epoch:   4 loss: 1.26019990 r2: 0.643 rmse: 2.703 mae: 0.950\n",
      "epoch:   5 loss: 1.25175691 r2: 0.643 rmse: 2.698 mae: 0.949\n",
      "epoch:   6 loss: 1.24434114 r2: 0.644 rmse: 2.697 mae: 0.949\n",
      "epoch:   7 loss: 1.22953951 r2: 0.643 rmse: 2.698 mae: 0.949\n",
      "epoch:   8 loss: 1.22568393 r2: 0.644 rmse: 2.694 mae: 0.949\n",
      "epoch:   9 loss: 1.21558607 r2: 0.644 rmse: 2.691 mae: 0.948\n",
      "epoch:  10 loss: 1.20640755 r2: 0.645 rmse: 2.687 mae: 0.948\n",
      "epoch:  11 loss: 1.20900095 r2: 0.651 rmse: 2.642 mae: 0.940\n",
      "epoch:  12 loss: 1.20261264 r2: 0.651 rmse: 2.638 mae: 0.939\n",
      "epoch:  13 loss: 1.19988227 r2: 0.652 rmse: 2.631 mae: 0.938\n",
      "epoch:  14 loss: 1.19606650 r2: 0.652 rmse: 2.632 mae: 0.938\n",
      "epoch:  14 loss: 1.1960664988\n",
      "bet_r2:  0.652311024409751\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  5\n",
      "\n",
      " train test split\n",
      "(8013, 272)\n",
      "(744, 272)\n",
      "\n",
      " \n",
      "torch.Size([8013, 13])\n",
      "torch.Size([8013, 258])\n",
      "torch.Size([744, 13])\n",
      "torch.Size([744, 258])\n",
      "\n",
      " sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 258]) torch.Size([19, 258])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([258, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.7261187434484714\n",
      "epoch:   0 loss: 1.36835122 r2: 0.647 rmse: 2.814 mae: 0.957\n",
      "epoch:   1 loss: 1.32723641 r2: 0.650 rmse: 2.793 mae: 0.953\n",
      "epoch:   2 loss: 1.30021524 r2: 0.650 rmse: 2.786 mae: 0.953\n",
      "epoch:   3 loss: 1.27937281 r2: 0.652 rmse: 2.772 mae: 0.951\n",
      "epoch:   4 loss: 1.27795541 r2: 0.654 rmse: 2.761 mae: 0.950\n",
      "epoch:   5 loss: 1.25194323 r2: 0.655 rmse: 2.751 mae: 0.949\n",
      "epoch:   6 loss: 1.24270844 r2: 0.655 rmse: 2.746 mae: 0.948\n",
      "epoch:   7 loss: 1.23275995 r2: 0.657 rmse: 2.732 mae: 0.947\n",
      "epoch:   8 loss: 1.22402084 r2: 0.657 rmse: 2.737 mae: 0.947\n",
      "epoch:   9 loss: 1.21518958 r2: 0.657 rmse: 2.733 mae: 0.947\n",
      "epoch:  10 loss: 1.20853913 r2: 0.658 rmse: 2.726 mae: 0.946\n",
      "epoch:  11 loss: 1.20783162 r2: 0.661 rmse: 2.699 mae: 0.941\n",
      "epoch:  12 loss: 1.20558679 r2: 0.663 rmse: 2.689 mae: 0.940\n",
      "epoch:  13 loss: 1.19663513 r2: 0.663 rmse: 2.688 mae: 0.939\n",
      "epoch:  14 loss: 1.19218278 r2: 0.664 rmse: 2.682 mae: 0.938\n",
      "epoch:  14 loss: 1.1921827793\n",
      "bet_r2:  0.6635955012709063\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  6\n",
      "\n",
      " train test split\n",
      "(8037, 272)\n",
      "(720, 272)\n",
      "\n",
      " \n",
      "torch.Size([8037, 13])\n",
      "torch.Size([8037, 258])\n",
      "torch.Size([720, 13])\n",
      "torch.Size([720, 258])\n",
      "\n",
      " sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 258]) torch.Size([19, 258])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([258, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.6987237399072597\n",
      "epoch:   0 loss: 1.34830260 r2: 0.625 rmse: 2.750 mae: 0.950\n",
      "epoch:   1 loss: 1.32375002 r2: 0.627 rmse: 2.732 mae: 0.947\n",
      "epoch:   2 loss: 1.29168606 r2: 0.627 rmse: 2.732 mae: 0.947\n",
      "epoch:   3 loss: 1.28717184 r2: 0.628 rmse: 2.726 mae: 0.947\n",
      "epoch:   4 loss: 1.27947402 r2: 0.630 rmse: 2.712 mae: 0.946\n",
      "epoch:   5 loss: 1.25521493 r2: 0.630 rmse: 2.714 mae: 0.946\n",
      "epoch:   6 loss: 1.24931264 r2: 0.631 rmse: 2.707 mae: 0.945\n",
      "epoch:   7 loss: 1.22203684 r2: 0.631 rmse: 2.706 mae: 0.945\n",
      "epoch:   8 loss: 1.22854257 r2: 0.631 rmse: 2.705 mae: 0.945\n",
      "epoch:   9 loss: 1.21979451 r2: 0.630 rmse: 2.713 mae: 0.946\n",
      "epoch:  10 loss: 1.21452725 r2: 0.630 rmse: 2.713 mae: 0.946\n",
      "epoch:  11 loss: 1.20619893 r2: 0.634 rmse: 2.684 mae: 0.941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  12 loss: 1.20413482 r2: 0.634 rmse: 2.682 mae: 0.941\n",
      "epoch:  13 loss: 1.19397664 r2: 0.635 rmse: 2.676 mae: 0.940\n",
      "epoch:  14 loss: 1.19616759 r2: 0.635 rmse: 2.676 mae: 0.940\n",
      "epoch:  14 loss: 1.1961675882\n",
      "bet_r2:  0.6350797965169155\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  7\n",
      "\n",
      " train test split\n",
      "(8013, 272)\n",
      "(744, 272)\n",
      "\n",
      " \n",
      "torch.Size([8013, 13])\n",
      "torch.Size([8013, 258])\n",
      "torch.Size([744, 13])\n",
      "torch.Size([744, 258])\n",
      "\n",
      " sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 258]) torch.Size([19, 258])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([258, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.6892882980441339\n",
      "epoch:   0 loss: 1.34333026 r2: 0.609 rmse: 2.751 mae: 0.958\n",
      "epoch:   1 loss: 1.31705678 r2: 0.610 rmse: 2.747 mae: 0.959\n",
      "epoch:   2 loss: 1.29852366 r2: 0.611 rmse: 2.737 mae: 0.958\n",
      "epoch:   3 loss: 1.27320206 r2: 0.611 rmse: 2.740 mae: 0.959\n",
      "epoch:   4 loss: 1.26234078 r2: 0.611 rmse: 2.740 mae: 0.959\n",
      "epoch:   5 loss: 1.25531852 r2: 0.610 rmse: 2.743 mae: 0.959\n",
      "epoch:   6 loss: 1.23092675 r2: 0.610 rmse: 2.742 mae: 0.960\n",
      "epoch:   7 loss: 1.23372114 r2: 0.610 rmse: 2.746 mae: 0.961\n",
      "epoch:   8 loss: 1.22037196 r2: 0.609 rmse: 2.748 mae: 0.961\n",
      "epoch:   9 loss: 1.21401799 r2: 0.610 rmse: 2.747 mae: 0.961\n",
      "epoch:  10 loss: 1.20343995 r2: 0.609 rmse: 2.750 mae: 0.961\n",
      "epoch:  11 loss: 1.20606959 r2: 0.613 rmse: 2.724 mae: 0.957\n",
      "epoch:  12 loss: 1.20229864 r2: 0.613 rmse: 2.720 mae: 0.956\n",
      "epoch:  13 loss: 1.19622231 r2: 0.613 rmse: 2.719 mae: 0.956\n",
      "epoch:  14 loss: 1.19124627 r2: 0.613 rmse: 2.720 mae: 0.957\n",
      "epoch:  14 loss: 1.1912462711\n",
      "bet_r2:  0.6134558738917163\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  8\n",
      "\n",
      " train test split\n",
      "(8013, 272)\n",
      "(744, 272)\n",
      "\n",
      " \n",
      "torch.Size([8013, 13])\n",
      "torch.Size([8013, 258])\n",
      "torch.Size([744, 13])\n",
      "torch.Size([744, 258])\n",
      "\n",
      " sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 258]) torch.Size([19, 258])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([258, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.6676648958127406\n",
      "epoch:   0 loss: 1.36317134 r2: 0.571 rmse: 2.895 mae: 1.006\n",
      "epoch:   1 loss: 1.33557224 r2: 0.572 rmse: 2.889 mae: 1.005\n",
      "epoch:   2 loss: 1.30947351 r2: 0.575 rmse: 2.870 mae: 1.003\n",
      "epoch:   3 loss: 1.28376615 r2: 0.576 rmse: 2.861 mae: 1.002\n",
      "epoch:   4 loss: 1.26240158 r2: 0.577 rmse: 2.856 mae: 1.002\n",
      "epoch:   5 loss: 1.24751389 r2: 0.576 rmse: 2.861 mae: 1.003\n",
      "epoch:   6 loss: 1.25192046 r2: 0.576 rmse: 2.864 mae: 1.003\n",
      "epoch:   7 loss: 1.23290014 r2: 0.576 rmse: 2.859 mae: 1.003\n",
      "epoch:   8 loss: 1.22713470 r2: 0.576 rmse: 2.857 mae: 1.003\n",
      "epoch:   9 loss: 1.22006500 r2: 0.577 rmse: 2.857 mae: 1.003\n",
      "epoch:  10 loss: 1.20715630 r2: 0.576 rmse: 2.859 mae: 1.004\n",
      "epoch:  11 loss: 1.20482087 r2: 0.577 rmse: 2.853 mae: 1.001\n",
      "epoch:  12 loss: 1.20071471 r2: 0.577 rmse: 2.852 mae: 1.001\n",
      "epoch:  13 loss: 1.19616783 r2: 0.577 rmse: 2.853 mae: 1.001\n",
      "epoch:  14 loss: 1.18443060 r2: 0.577 rmse: 2.856 mae: 1.002\n",
      "epoch:  14 loss: 1.1844305992\n",
      "bet_r2:  0.5773014550689083\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  9\n",
      "\n",
      " train test split\n",
      "(8037, 272)\n",
      "(720, 272)\n",
      "\n",
      " \n",
      "torch.Size([8037, 13])\n",
      "torch.Size([8037, 258])\n",
      "torch.Size([720, 13])\n",
      "torch.Size([720, 258])\n",
      "\n",
      " sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 258]) torch.Size([19, 258])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([258, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.7452034906828554\n",
      "epoch:   0 loss: 1.32559454 r2: 0.651 rmse: 3.005 mae: 0.983\n",
      "epoch:   1 loss: 1.32442939 r2: 0.656 rmse: 2.960 mae: 0.978\n",
      "epoch:   2 loss: 1.31231713 r2: 0.657 rmse: 2.948 mae: 0.976\n",
      "epoch:   3 loss: 1.28288889 r2: 0.659 rmse: 2.938 mae: 0.975\n",
      "epoch:   4 loss: 1.26199687 r2: 0.660 rmse: 2.927 mae: 0.974\n",
      "epoch:   5 loss: 1.26320112 r2: 0.660 rmse: 2.929 mae: 0.974\n",
      "epoch:   6 loss: 1.24362206 r2: 0.661 rmse: 2.922 mae: 0.974\n",
      "epoch:   7 loss: 1.24248827 r2: 0.662 rmse: 2.911 mae: 0.973\n",
      "epoch:   8 loss: 1.22935820 r2: 0.663 rmse: 2.897 mae: 0.971\n",
      "epoch:   9 loss: 1.21865308 r2: 0.663 rmse: 2.901 mae: 0.972\n",
      "epoch:  10 loss: 1.21044886 r2: 0.664 rmse: 2.895 mae: 0.971\n",
      "epoch:  11 loss: 1.21165895 r2: 0.665 rmse: 2.884 mae: 0.969\n",
      "epoch:  12 loss: 1.20911300 r2: 0.666 rmse: 2.874 mae: 0.967\n",
      "epoch:  13 loss: 1.19386804 r2: 0.665 rmse: 2.879 mae: 0.968\n",
      "epoch:  14 loss: 1.19789290 r2: 0.666 rmse: 2.878 mae: 0.968\n",
      "epoch:  14 loss: 1.1978929043\n",
      "bet_r2:  0.6660435244138342\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  10\n",
      "\n",
      " train test split\n",
      "(8013, 272)\n",
      "(744, 272)\n",
      "\n",
      " \n",
      "torch.Size([8013, 13])\n",
      "torch.Size([8013, 258])\n",
      "torch.Size([744, 13])\n",
      "torch.Size([744, 258])\n",
      "\n",
      " sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 258]) torch.Size([19, 258])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([258, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.6145591373827785\n",
      "epoch:   0 loss: 1.36251056 r2: 0.589 rmse: 3.722 mae: 1.057\n",
      "epoch:   1 loss: 1.33257771 r2: 0.589 rmse: 3.721 mae: 1.057\n",
      "epoch:   2 loss: 1.29153097 r2: 0.592 rmse: 3.695 mae: 1.055\n",
      "epoch:   3 loss: 1.28915322 r2: 0.593 rmse: 3.686 mae: 1.054\n",
      "epoch:   4 loss: 1.26521719 r2: 0.595 rmse: 3.670 mae: 1.053\n",
      "epoch:   5 loss: 1.25679731 r2: 0.594 rmse: 3.676 mae: 1.054\n",
      "epoch:   6 loss: 1.24335778 r2: 0.595 rmse: 3.671 mae: 1.054\n",
      "epoch:   7 loss: 1.23244560 r2: 0.596 rmse: 3.659 mae: 1.053\n",
      "epoch:   8 loss: 1.22864282 r2: 0.596 rmse: 3.656 mae: 1.052\n",
      "epoch:   9 loss: 1.21667552 r2: 0.596 rmse: 3.662 mae: 1.052\n",
      "epoch:  10 loss: 1.21853936 r2: 0.596 rmse: 3.659 mae: 1.052\n",
      "epoch:  11 loss: 1.21276820 r2: 0.598 rmse: 3.639 mae: 1.049\n",
      "epoch:  12 loss: 1.20960128 r2: 0.599 rmse: 3.631 mae: 1.048\n",
      "epoch:  13 loss: 1.20229030 r2: 0.599 rmse: 3.628 mae: 1.047\n",
      "epoch:  14 loss: 1.19775772 r2: 0.600 rmse: 3.620 mae: 1.047\n",
      "epoch:  14 loss: 1.1977577209\n",
      "bet_r2:  0.6003052940239731\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  11\n",
      "\n",
      " train test split\n",
      "(8037, 272)\n",
      "(720, 272)\n",
      "\n",
      " \n",
      "torch.Size([8037, 13])\n",
      "torch.Size([8037, 258])\n",
      "torch.Size([720, 13])\n",
      "torch.Size([720, 258])\n",
      "\n",
      " sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 258]) torch.Size([19, 258])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([258, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.5569346012950084\n",
      "epoch:   0 loss: 1.34346914 r2: 0.554 rmse: 4.026 mae: 1.093\n",
      "epoch:   1 loss: 1.33240187 r2: 0.557 rmse: 4.001 mae: 1.090\n",
      "epoch:   2 loss: 1.29424214 r2: 0.559 rmse: 3.984 mae: 1.088\n",
      "epoch:   3 loss: 1.28886473 r2: 0.560 rmse: 3.974 mae: 1.087\n",
      "epoch:   4 loss: 1.27060294 r2: 0.561 rmse: 3.969 mae: 1.086\n",
      "epoch:   5 loss: 1.26649868 r2: 0.562 rmse: 3.960 mae: 1.086\n",
      "epoch:   6 loss: 1.24803436 r2: 0.562 rmse: 3.960 mae: 1.085\n",
      "epoch:   7 loss: 1.24017084 r2: 0.561 rmse: 3.964 mae: 1.086\n",
      "epoch:   8 loss: 1.23216867 r2: 0.562 rmse: 3.959 mae: 1.085\n",
      "epoch:   9 loss: 1.21212780 r2: 0.562 rmse: 3.958 mae: 1.085\n",
      "epoch:  10 loss: 1.21462262 r2: 0.563 rmse: 3.950 mae: 1.083\n",
      "epoch:  11 loss: 1.20724666 r2: 0.564 rmse: 3.940 mae: 1.079\n",
      "epoch:  12 loss: 1.20112920 r2: 0.563 rmse: 3.948 mae: 1.080\n",
      "epoch:  13 loss: 1.20598888 r2: 0.564 rmse: 3.941 mae: 1.079\n",
      "epoch:  14 loss: 1.18878174 r2: 0.564 rmse: 3.937 mae: 1.078\n",
      "epoch:  14 loss: 1.1887817383\n",
      "bet_r2:  0.5640616047920537\n",
      "-------------------------------------------------\n",
      "-------------------------------------------------\n",
      "Month:  12\n",
      "\n",
      " train test split\n",
      "(8013, 272)\n",
      "(744, 272)\n",
      "\n",
      " \n",
      "torch.Size([8013, 13])\n",
      "torch.Size([8013, 258])\n",
      "torch.Size([744, 13])\n",
      "torch.Size([744, 258])\n",
      "\n",
      " sequences\n",
      "torch.Size([19, 13]) torch.Size([19, 258]) torch.Size([19, 258])\n",
      "\n",
      "attachment matrix\n",
      "torch.Size([258, 24])\n",
      "\n",
      " model inititalized\n",
      "\n",
      " model loaded\n",
      "Pretraining R2:  0.5161425904306087\n",
      "epoch:   0 loss: 1.20783257 r2: 0.538 rmse: 3.383 mae: 1.014\n",
      "epoch:   1 loss: 1.20149922 r2: 0.539 rmse: 3.369 mae: 1.013\n",
      "epoch:   2 loss: 1.18787336 r2: 0.541 rmse: 3.354 mae: 1.011\n",
      "epoch:   3 loss: 1.18501270 r2: 0.541 rmse: 3.359 mae: 1.010\n",
      "epoch:   4 loss: 1.18431866 r2: 0.540 rmse: 3.362 mae: 1.011\n",
      "epoch:   5 loss: 1.17629373 r2: 0.540 rmse: 3.365 mae: 1.012\n",
      "epoch:   6 loss: 1.17100430 r2: 0.541 rmse: 3.360 mae: 1.011\n",
      "epoch:   7 loss: 1.16756248 r2: 0.540 rmse: 3.367 mae: 1.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   8 loss: 1.16690660 r2: 0.539 rmse: 3.374 mae: 1.013\n",
      "epoch:   9 loss: 1.15782464 r2: 0.539 rmse: 3.376 mae: 1.014\n",
      "epoch:  10 loss: 1.15421462 r2: 0.539 rmse: 3.375 mae: 1.014\n",
      "epoch:  11 loss: 1.15184188 r2: 0.538 rmse: 3.383 mae: 1.013\n",
      "epoch:  12 loss: 1.14866006 r2: 0.537 rmse: 3.389 mae: 1.014\n",
      "epoch:  13 loss: 1.14592636 r2: 0.537 rmse: 3.388 mae: 1.014\n",
      "epoch:  14 loss: 1.14623535 r2: 0.537 rmse: 3.387 mae: 1.014\n",
      "epoch:  14 loss: 1.1462353468\n",
      "bet_r2:  0.5414843036210735\n"
     ]
    }
   ],
   "source": [
    "bptt = config['bptt']\n",
    "\n",
    "R2List = []\n",
    "residual_list = []\n",
    "\n",
    "for m in range(1,13):\n",
    "    month_index  = pd.to_datetime(dataset.Date).dt.month == m\n",
    "    \n",
    "    print('-------------------------------------------------')\n",
    "    print('-------------------------------------------------')\n",
    "    print(\"Month: \", m)\n",
    "\n",
    "\n",
    "    trainData = dataset[~month_index]\n",
    "    testData = dataset[month_index]\n",
    "\n",
    "    print(\"\\n train test split\")\n",
    "    print(trainData.shape)\n",
    "    print(testData.shape)\n",
    "\n",
    "\n",
    "    print(\"\\n \")\n",
    "    X_train = trainData[features_cols].values\n",
    "    X_train = torch.tensor(X_train).float().to(device)\n",
    "    print(X_train.shape)\n",
    "\n",
    "    y_train = trainData[targetColumns].values\n",
    "    y_train = torch.tensor(y_train).float().to(device)\n",
    "    print(y_train.shape)\n",
    "\n",
    "    X_test = testData[features_cols].values\n",
    "    X_test = torch.tensor(X_test).float().to(device)\n",
    "    print(X_test.shape)\n",
    "\n",
    "    y_test = testData[targetColumns].values\n",
    "    y_test = torch.tensor(y_test).float().to(device)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    \n",
    "    train_inout_seq = create_inout_sequences(X_train,y_train, bptt)\n",
    "    \n",
    "    test_inout_seq = create_inout_sequences(X_test,y_test, bptt)\n",
    "    print(\"\\n sequences\")\n",
    "    print(train_inout_seq[0][0].shape,train_inout_seq[0][1].shape, train_inout_seq[0][2].shape)\n",
    "    \n",
    "    at_mat = get_at_mat(targetColumns)\n",
    "    print(\"\\nattachment matrix\")\n",
    "    print(at_mat.shape)\n",
    "    \n",
    "    \n",
    "    layers = config['layers']\n",
    "    communities = 24\n",
    "    network_size = len(targetColumns)\n",
    "    feat_size = len(features_cols)\n",
    "    ensembles=10\n",
    "    dropout = config['dropout']\n",
    "\n",
    "    model = GraphPrediction(feat_size = feat_size, hidden_layer_size=100,\n",
    "                 network_size=network_size, layers=layers,\n",
    "                communities=communities, ensembles=ensembles, dropout=dropout, at_mat=at_mat).to(device)\n",
    "\n",
    "    loss_function = nn.L1Loss()   \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=config['step_size'], gamma=config['gamma'])\n",
    "    print(\"\\n model inititalized\")\n",
    "    \n",
    "    model.load_state_dict(torch.load(pretrained_weights))\n",
    "    print(\"\\n model loaded\")\n",
    "    \n",
    "    residual, r2, rmse, mae = evaluate(model)\n",
    "    print(\"Pretraining R2: \",r2)\n",
    "    \n",
    "    \n",
    "    best_r2 = 0\n",
    "    best_residual = residual\n",
    "#     torch.save(model.state_dict(), 'data/'+'jfk_'+str(m)+'.pt')\n",
    "#     np.save('data/'+'jfk_'+str(m)+'.npy', best_residual)\n",
    "    \n",
    "    \n",
    "    epochs = 15\n",
    "\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        for feat,seq, labels in train_inout_seq:\n",
    "            optimizer.zero_grad()\n",
    "    #         model.hidden_cell = (torch.zeros(layers, 1, model.hidden_layer_size).to(device),\n",
    "    #                         torch.zeros(layers, 1, model.hidden_layer_size).to(device))\n",
    "\n",
    "            y_pred = model(seq, feat)\n",
    "            labels = labels.repeat(y_pred.shape[0],1,1)\n",
    "\n",
    "            single_loss = loss_function(y_pred, labels)\n",
    "            single_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        residual, r2, rmse, mae = evaluate(model)\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f} r2: {r2:5.3f} rmse: {rmse:5.3f} mae: {mae:5.3f}')\n",
    "        \n",
    "        if r2 > best_r2:\n",
    "            best_r2 = r2\n",
    "            best_residual = residual\n",
    "            torch.save(model.state_dict(), 'data/'+'jfk_'+str(m)+'.pt')\n",
    "            np.save('data/'+'jfk_'+str(m)+'.npy', best_residual)\n",
    "\n",
    "\n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "    print(\"bet_r2: \", best_r2)\n",
    "\n",
    "    R2List.append(best_r2)\n",
    "    residual_list.append(best_residual)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6292653363941075,\n",
       " 0.6220370443486188,\n",
       " 0.6576641046354088,\n",
       " 0.652311024409751,\n",
       " 0.6635955012709063,\n",
       " 0.6350797965169155,\n",
       " 0.6134558738917163,\n",
       " 0.5773014550689083,\n",
       " 0.6660435244138342,\n",
       " 0.6003052940239731,\n",
       " 0.5640616047920537,\n",
       " 0.5414843036210735]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R2List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.6292653363941075\n",
    "0.6220370443486188\n",
    "0.6576641046354088\n",
    "0.652311024409751\n",
    "0.6635955012709063\n",
    "0.6350797965169155\n",
    "0.6134558738917163\n",
    "0.5773014550689083\n",
    "0.6660435244138342"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attachment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b2581fdf675b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattachment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'attachment' is not defined"
     ]
    }
   ],
   "source": [
    "len(set(attachment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 linear\n",
    "# 0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 linear\n",
    "# 0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 linear + RELU\n",
    "# 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 linear bptt = 24\n",
    "# 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble\n",
    "#0.53228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO\n",
    "# other hubs\n",
    "# ensemble model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
