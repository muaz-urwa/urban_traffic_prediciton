{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.00034439316653688684,\n",
       " 'layers': 3,\n",
       " 'step_size': 11,\n",
       " 'gamma': 0.761795969995615,\n",
       " 'bptt': 19,\n",
       " 'dropout': 0.1227497445640586}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'lr': 0.00034439316653688684,\n",
    " 'layers': 3,\n",
    " 'step_size': 11,\n",
    " 'gamma': 0.761795969995615,\n",
    " 'bptt': 19,\n",
    " 'dropout': 0.1227497445640586}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/home/urwa/Documents/side_projects/urban/data/featureData/jfk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 1049)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>...</th>\n",
       "      <th>91_lag_3</th>\n",
       "      <th>92_lag_3</th>\n",
       "      <th>93_lag_3</th>\n",
       "      <th>94_lag_3</th>\n",
       "      <th>95_lag_3</th>\n",
       "      <th>96_lag_3</th>\n",
       "      <th>97_lag_3</th>\n",
       "      <th>98_lag_3</th>\n",
       "      <th>99_lag_3</th>\n",
       "      <th>arrival_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour  1  10  100  101  102  106  107  108  ...  91_lag_3  \\\n",
       "0  2018-01-01     3  0   0    0    0    0    0    0    0  ...       1.0   \n",
       "1  2018-01-01     4  0   3    0    0    1    0    0    1  ...       4.0   \n",
       "2  2018-01-01     5  0   4    0    0    1    2    3    1  ...       0.0   \n",
       "\n",
       "   92_lag_3  93_lag_3  94_lag_3  95_lag_3  96_lag_3  97_lag_3  98_lag_3  \\\n",
       "0       1.0       0.0       1.0       6.0       0.0       1.0       0.0   \n",
       "1       1.0       0.0       0.0       2.0       0.0       0.0       0.0   \n",
       "2       0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "\n",
       "   99_lag_3  arrival_lag_3  \n",
       "0       0.0            6.0  \n",
       "1       0.0            6.0  \n",
       "2       0.0            2.0  \n",
       "\n",
       "[3 rows x 1049 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "777"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_columns = [c for c in dataset.columns if 'lag' in c]\n",
    "len(lag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 272)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[[c for c in dataset.columns if c not in lag_columns]]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DateColumns = ['Date']\n",
    "\n",
    "ext_columns = ['Dow', 'arrival','maxtemp', 'mintemp', 'avgtemp', 'departure', 'hdd',\n",
    "       'cdd', 'participation', 'newsnow', 'snowdepth', 'ifSnow']\n",
    "\n",
    "targetColumns = [c for c in dataset.columns if c not in ext_columns and \\\n",
    "                c not in DateColumns and c not in lag_columns and c != 'Hour']\n",
    "len(targetColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cols = [c for c in dataset.columns if c not in targetColumns and c not in DateColumns]\n",
    "len(features_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6567\n",
      "(6567, 272)\n",
      "(2190, 272)\n"
     ]
    }
   ],
   "source": [
    "sep = int(0.75*len(dataset))\n",
    "print(sep)\n",
    "\n",
    "\n",
    "trainData = dataset[:sep]\n",
    "testData = dataset[sep:]\n",
    "\n",
    "print(trainData.shape)\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6567, 13])\n",
      "torch.Size([6567, 258])\n",
      "torch.Size([2190, 13])\n",
      "torch.Size([2190, 258])\n"
     ]
    }
   ],
   "source": [
    "X_train = trainData[features_cols].values\n",
    "X_train = torch.tensor(X_train).float().to(device)\n",
    "print(X_train.shape)\n",
    "\n",
    "y_train = trainData[targetColumns].values\n",
    "y_train = torch.tensor(y_train).float().to(device)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test = testData[features_cols].values\n",
    "X_test = torch.tensor(X_test).float().to(device)\n",
    "print(X_test.shape)\n",
    "\n",
    "y_test = testData[targetColumns].values\n",
    "y_test = torch.tensor(y_test).float().to(device)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(x,y, tw):\n",
    "    inout_seq = []\n",
    "    L = len(x)\n",
    "    for i in range(L-tw):\n",
    "        train_seq_x = x[i:i+tw]\n",
    "        train_seq_y = y[i:i+tw]\n",
    "#         train_seq = torch.cat((train_seq_x,train_seq_y),axis=1)\n",
    "        \n",
    "#         train_label = y[i+tw:i+tw+1]\n",
    "        train_label = y[i+1:i+tw+1]\n",
    "        inout_seq.append((train_seq_x, train_seq_y ,train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inout_seq = create_inout_sequences(X_train,y_train, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([19, 13]), torch.Size([19, 258]), torch.Size([19, 258]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inout_seq[0][0].shape,train_inout_seq[0][1].shape, train_inout_seq[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inout_seq = create_inout_sequences(X_test,y_test, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=100, num_layers=1, dropout=0):\n",
    "        super().__init__()\n",
    "                \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.hidden_cell = (torch.zeros(num_layers,1,self.hidden_size).to(device),\n",
    "                    torch.zeros(num_layers,1,self.hidden_size).to(device))\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, dropout=dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.hidden_cell = (torch.zeros(self.num_layers,1,self.hidden_size).to(device),\n",
    "                    torch.zeros(self.num_layers,1,self.hidden_size).to(device))\n",
    "           \n",
    "        lstm_out, self.hidden_cell = self.lstm(x.view(len(x) ,1, -1), self.hidden_cell)\n",
    "        \n",
    "        return lstm_out, self.hidden_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphPrediction(nn.Module):\n",
    "    def __init__(self, feat_size=1, hidden_layer_size=100, network_size=1, layers=1, communities=10, ensembles=1, dropout=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        # aggregation\n",
    "        self.attachment_matrix = torch.nn.Parameter(torch.randn(network_size,communities))\n",
    "        self.attachment_matrix.requires_grad = True\n",
    "        \n",
    "        lstm_input = communities + feat_size\n",
    "        \n",
    "        self.ensembles = ensembles\n",
    "        self.lstms = nn.ModuleList()\n",
    "        self.linears = nn.ModuleList()\n",
    "        for i in range(ensembles):\n",
    "             self.lstms.append(LSTM(input_size=lstm_input, hidden_size=hidden_layer_size, num_layers=layers))\n",
    "             self.linears.append(nn.Linear(hidden_layer_size, network_size))\n",
    "            \n",
    "\n",
    "    def forward(self, input_seq, feat):\n",
    "        \n",
    "        w = F.softmax(self.attachment_matrix, dim=1)\n",
    "        x = torch.matmul(input_seq, self.attachment_matrix)\n",
    "        x = torch.cat((x,feat),axis=1)\n",
    "        x = x.view(len(input_seq) ,1, -1)\n",
    "        \n",
    "        predictions = []\n",
    "        for i in range(self.ensembles):\n",
    "            if torch.randn(1) < 0.7 or i==0 or not self.training:\n",
    "                lstm_out, self.hidden_cell = self.lstms[i](x)\n",
    "                y = self.linears[i](lstm_out.view(len(input_seq), -1))\n",
    "                predictions.append(y)\n",
    "        \n",
    "        predictions = torch.stack(predictions)\n",
    "#         print(predictions.shape)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    with torch.no_grad():\n",
    "        for feat,seq, labels in test_inout_seq:\n",
    "#             model.hidden = (torch.zeros(layers, 1, model.hidden_layer_size),\n",
    "#                             torch.zeros(layers, 1, model.hidden_layer_size))\n",
    "            y = model(seq,feat).mean(dim=0)[-1]\n",
    "    \n",
    "            prediction.append(y)\n",
    "\n",
    "    y_test_ = torch.stack([labels[-1] for feat,seq, labels in test_inout_seq], axis=0).detach().cpu().numpy()\n",
    "    y_pred_ = torch.stack(prediction).detach().cpu().numpy()\n",
    "\n",
    "    r2 = r2_score(y_test_, y_pred_, multioutput='variance_weighted')\n",
    "    rmse = mean_squared_error(y_test_, y_pred_)\n",
    "    mae = mean_absolute_error(y_test_, y_pred_)\n",
    "#     print(\"r2: \",r2)\n",
    "    return (r2, rmse, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 3\n",
    "communities = 24\n",
    "network_size = len(targetColumns)\n",
    "feat_size = len(features_cols)\n",
    "ensembles=10\n",
    "dropout= 0.1227497445640586\n",
    "\n",
    "model = GraphPrediction(feat_size = feat_size, hidden_layer_size=100,\n",
    "             network_size=network_size, layers=layers,\n",
    "            communities=communities, ensembles=ensembles, dropout=dropout).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.L1Loss()   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00034439316653688684)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=11, gamma=0.762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 1.09996319 r2: 0.424 rmse: 4.914 mae: 1.211\n",
      "epoch:   1 loss: 1.08950555 r2: 0.502 rmse: 4.255 mae: 1.128\n",
      "epoch:   2 loss: 1.06901085 r2: 0.502 rmse: 4.252 mae: 1.129\n",
      "epoch:   3 loss: 1.06093681 r2: 0.518 rmse: 4.113 mae: 1.111\n",
      "epoch:   4 loss: 1.03974140 r2: 0.543 rmse: 3.898 mae: 1.086\n",
      "epoch:   5 loss: 1.03118396 r2: 0.556 rmse: 3.791 mae: 1.070\n",
      "epoch:   6 loss: 1.03019822 r2: 0.560 rmse: 3.753 mae: 1.068\n",
      "epoch:   7 loss: 1.02515256 r2: 0.561 rmse: 3.750 mae: 1.069\n",
      "epoch:   8 loss: 1.01914835 r2: 0.566 rmse: 3.702 mae: 1.063\n",
      "epoch:   9 loss: 1.02117848 r2: 0.567 rmse: 3.698 mae: 1.064\n",
      "epoch:  10 loss: 1.01926136 r2: 0.567 rmse: 3.694 mae: 1.063\n",
      "epoch:  11 loss: 1.01369584 r2: 0.571 rmse: 3.666 mae: 1.059\n",
      "epoch:  12 loss: 1.01095557 r2: 0.569 rmse: 3.675 mae: 1.062\n",
      "epoch:  13 loss: 1.01351810 r2: 0.571 rmse: 3.662 mae: 1.060\n",
      "epoch:  14 loss: 1.00872242 r2: 0.571 rmse: 3.665 mae: 1.061\n",
      "epoch:  15 loss: 1.00321805 r2: 0.573 rmse: 3.649 mae: 1.061\n",
      "epoch:  16 loss: 1.01278746 r2: 0.572 rmse: 3.652 mae: 1.060\n",
      "epoch:  17 loss: 1.00977647 r2: 0.568 rmse: 3.687 mae: 1.065\n",
      "epoch:  18 loss: 1.00780320 r2: 0.574 rmse: 3.636 mae: 1.060\n",
      "epoch:  19 loss: 1.00215781 r2: 0.574 rmse: 3.640 mae: 1.061\n",
      "epoch:  20 loss: 0.99973106 r2: 0.572 rmse: 3.654 mae: 1.062\n",
      "epoch:  21 loss: 0.99944216 r2: 0.575 rmse: 3.631 mae: 1.058\n",
      "epoch:  22 loss: 0.99738365 r2: 0.573 rmse: 3.646 mae: 1.060\n",
      "epoch:  23 loss: 0.99718773 r2: 0.575 rmse: 3.628 mae: 1.057\n",
      "epoch:  24 loss: 0.98833656 r2: 0.574 rmse: 3.639 mae: 1.059\n",
      "epoch:  25 loss: 0.99055976 r2: 0.573 rmse: 3.643 mae: 1.060\n",
      "epoch:  26 loss: 0.99095565 r2: 0.574 rmse: 3.633 mae: 1.058\n",
      "epoch:  27 loss: 0.98393124 r2: 0.575 rmse: 3.629 mae: 1.058\n",
      "epoch:  28 loss: 0.98614424 r2: 0.575 rmse: 3.629 mae: 1.059\n",
      "epoch:  29 loss: 0.98623818 r2: 0.576 rmse: 3.618 mae: 1.057\n",
      "epoch:  30 loss: 0.98428577 r2: 0.576 rmse: 3.621 mae: 1.058\n",
      "epoch:  31 loss: 0.98102963 r2: 0.576 rmse: 3.624 mae: 1.058\n",
      "epoch:  32 loss: 0.97922325 r2: 0.577 rmse: 3.610 mae: 1.056\n",
      "epoch:  33 loss: 0.97804618 r2: 0.576 rmse: 3.621 mae: 1.056\n",
      "epoch:  34 loss: 0.97830766 r2: 0.576 rmse: 3.621 mae: 1.056\n",
      "epoch:  35 loss: 0.97689271 r2: 0.576 rmse: 3.618 mae: 1.056\n",
      "epoch:  36 loss: 0.97911257 r2: 0.577 rmse: 3.608 mae: 1.055\n",
      "epoch:  37 loss: 0.97388083 r2: 0.577 rmse: 3.608 mae: 1.055\n",
      "epoch:  38 loss: 0.97331899 r2: 0.577 rmse: 3.608 mae: 1.055\n",
      "epoch:  39 loss: 0.97107559 r2: 0.577 rmse: 3.609 mae: 1.055\n",
      "epoch:  40 loss: 0.97153318 r2: 0.577 rmse: 3.608 mae: 1.054\n",
      "epoch:  41 loss: 0.96959186 r2: 0.577 rmse: 3.615 mae: 1.056\n",
      "epoch:  42 loss: 0.97106642 r2: 0.576 rmse: 3.616 mae: 1.056\n",
      "epoch:  43 loss: 0.97065979 r2: 0.575 rmse: 3.627 mae: 1.057\n",
      "epoch:  44 loss: 0.96822029 r2: 0.576 rmse: 3.621 mae: 1.056\n",
      "epoch:  45 loss: 0.96877193 r2: 0.576 rmse: 3.616 mae: 1.055\n",
      "epoch:  46 loss: 0.96768087 r2: 0.576 rmse: 3.620 mae: 1.055\n",
      "epoch:  47 loss: 0.96839452 r2: 0.575 rmse: 3.625 mae: 1.057\n",
      "epoch:  48 loss: 0.96723056 r2: 0.575 rmse: 3.629 mae: 1.057\n",
      "epoch:  49 loss: 0.96615368 r2: 0.575 rmse: 3.629 mae: 1.057\n",
      "epoch:  50 loss: 0.96639764 r2: 0.575 rmse: 3.627 mae: 1.057\n",
      "epoch:  51 loss: 0.96642601 r2: 0.575 rmse: 3.630 mae: 1.057\n",
      "epoch:  52 loss: 0.96712565 r2: 0.574 rmse: 3.638 mae: 1.058\n",
      "epoch:  53 loss: 0.96482325 r2: 0.574 rmse: 3.635 mae: 1.058\n",
      "epoch:  54 loss: 0.96412468 r2: 0.574 rmse: 3.639 mae: 1.058\n",
      "epoch:  55 loss: 0.96254170 r2: 0.574 rmse: 3.635 mae: 1.058\n",
      "epoch:  56 loss: 0.96255046 r2: 0.574 rmse: 3.639 mae: 1.058\n",
      "epoch:  57 loss: 0.96405095 r2: 0.574 rmse: 3.636 mae: 1.058\n",
      "epoch:  58 loss: 0.96159369 r2: 0.574 rmse: 3.640 mae: 1.058\n",
      "epoch:  59 loss: 0.96548605 r2: 0.575 rmse: 3.632 mae: 1.056\n",
      "epoch:  60 loss: 0.96185809 r2: 0.574 rmse: 3.634 mae: 1.057\n",
      "epoch:  61 loss: 0.96392393 r2: 0.574 rmse: 3.639 mae: 1.057\n",
      "epoch:  62 loss: 0.96260810 r2: 0.574 rmse: 3.638 mae: 1.058\n",
      "epoch:  63 loss: 0.96041322 r2: 0.574 rmse: 3.640 mae: 1.058\n",
      "epoch:  64 loss: 0.96240377 r2: 0.574 rmse: 3.638 mae: 1.058\n",
      "epoch:  65 loss: 0.96135831 r2: 0.573 rmse: 3.644 mae: 1.058\n",
      "epoch:  66 loss: 0.95783877 r2: 0.574 rmse: 3.639 mae: 1.058\n",
      "epoch:  67 loss: 0.96160287 r2: 0.574 rmse: 3.641 mae: 1.058\n",
      "epoch:  68 loss: 0.95962644 r2: 0.574 rmse: 3.639 mae: 1.057\n",
      "epoch:  69 loss: 0.96091962 r2: 0.574 rmse: 3.639 mae: 1.057\n",
      "epoch:  70 loss: 0.96033221 r2: 0.574 rmse: 3.641 mae: 1.057\n",
      "epoch:  71 loss: 0.96221650 r2: 0.574 rmse: 3.639 mae: 1.057\n",
      "epoch:  72 loss: 0.95936430 r2: 0.574 rmse: 3.640 mae: 1.057\n",
      "epoch:  73 loss: 0.95611793 r2: 0.574 rmse: 3.640 mae: 1.057\n",
      "epoch:  74 loss: 0.95747143 r2: 0.573 rmse: 3.643 mae: 1.057\n",
      "epoch:  75 loss: 0.95636684 r2: 0.573 rmse: 3.644 mae: 1.058\n",
      "epoch:  76 loss: 0.95732641 r2: 0.573 rmse: 3.645 mae: 1.058\n",
      "epoch:  77 loss: 0.95810837 r2: 0.573 rmse: 3.643 mae: 1.057\n",
      "epoch:  78 loss: 0.95753109 r2: 0.573 rmse: 3.644 mae: 1.057\n",
      "epoch:  79 loss: 0.95382953 r2: 0.573 rmse: 3.644 mae: 1.058\n",
      "epoch:  80 loss: 0.95327091 r2: 0.573 rmse: 3.643 mae: 1.057\n",
      "epoch:  81 loss: 0.95486027 r2: 0.573 rmse: 3.643 mae: 1.057\n",
      "epoch:  82 loss: 0.95620418 r2: 0.573 rmse: 3.644 mae: 1.057\n",
      "epoch:  83 loss: 0.95215094 r2: 0.573 rmse: 3.644 mae: 1.057\n",
      "epoch:  84 loss: 0.95670813 r2: 0.573 rmse: 3.642 mae: 1.057\n",
      "epoch:  85 loss: 0.95360494 r2: 0.573 rmse: 3.644 mae: 1.057\n",
      "epoch:  86 loss: 0.95481783 r2: 0.573 rmse: 3.646 mae: 1.058\n",
      "epoch:  87 loss: 0.94957972 r2: 0.573 rmse: 3.645 mae: 1.057\n",
      "epoch:  88 loss: 0.95427686 r2: 0.573 rmse: 3.645 mae: 1.057\n",
      "epoch:  89 loss: 0.95403719 r2: 0.573 rmse: 3.645 mae: 1.057\n",
      "epoch:  90 loss: 0.95336854 r2: 0.573 rmse: 3.644 mae: 1.057\n",
      "epoch:  91 loss: 0.95244789 r2: 0.573 rmse: 3.645 mae: 1.058\n",
      "epoch:  92 loss: 0.95111966 r2: 0.573 rmse: 3.646 mae: 1.057\n",
      "epoch:  93 loss: 0.95463449 r2: 0.573 rmse: 3.645 mae: 1.057\n",
      "epoch:  94 loss: 0.95295274 r2: 0.573 rmse: 3.646 mae: 1.058\n",
      "epoch:  95 loss: 0.95454341 r2: 0.573 rmse: 3.645 mae: 1.057\n",
      "epoch:  96 loss: 0.94977194 r2: 0.573 rmse: 3.646 mae: 1.058\n",
      "epoch:  97 loss: 0.95179534 r2: 0.573 rmse: 3.646 mae: 1.057\n",
      "epoch:  98 loss: 0.95183647 r2: 0.573 rmse: 3.646 mae: 1.058\n",
      "epoch:  99 loss: 0.95082587 r2: 0.573 rmse: 3.647 mae: 1.058\n",
      "epoch: 100 loss: 0.95137984 r2: 0.573 rmse: 3.648 mae: 1.058\n",
      "epoch: 101 loss: 0.95000285 r2: 0.573 rmse: 3.646 mae: 1.058\n",
      "epoch: 102 loss: 0.95226485 r2: 0.573 rmse: 3.648 mae: 1.058\n",
      "epoch: 103 loss: 0.95080495 r2: 0.573 rmse: 3.646 mae: 1.058\n",
      "epoch: 104 loss: 0.94703335 r2: 0.573 rmse: 3.648 mae: 1.058\n",
      "epoch: 105 loss: 0.95288473 r2: 0.573 rmse: 3.648 mae: 1.058\n",
      "epoch: 106 loss: 0.95063537 r2: 0.573 rmse: 3.648 mae: 1.058\n",
      "epoch: 107 loss: 0.94922572 r2: 0.573 rmse: 3.647 mae: 1.058\n",
      "epoch: 108 loss: 0.95032871 r2: 0.573 rmse: 3.648 mae: 1.058\n",
      "epoch: 109 loss: 0.95203388 r2: 0.573 rmse: 3.647 mae: 1.058\n",
      "epoch: 110 loss: 0.95204318 r2: 0.572 rmse: 3.650 mae: 1.058\n",
      "epoch: 111 loss: 0.94935226 r2: 0.572 rmse: 3.651 mae: 1.058\n",
      "epoch: 112 loss: 0.94921041 r2: 0.572 rmse: 3.651 mae: 1.058\n",
      "epoch: 113 loss: 0.94682139 r2: 0.572 rmse: 3.651 mae: 1.058\n",
      "epoch: 114 loss: 0.94955093 r2: 0.572 rmse: 3.650 mae: 1.058\n",
      "epoch: 115 loss: 0.94737905 r2: 0.572 rmse: 3.651 mae: 1.058\n",
      "epoch: 116 loss: 0.94812334 r2: 0.572 rmse: 3.652 mae: 1.058\n",
      "epoch: 117 loss: 0.94753474 r2: 0.572 rmse: 3.651 mae: 1.058\n",
      "epoch: 118 loss: 0.94526190 r2: 0.572 rmse: 3.652 mae: 1.058\n",
      "epoch: 119 loss: 0.95122230 r2: 0.572 rmse: 3.651 mae: 1.058\n",
      "epoch: 120 loss: 0.95184910 r2: 0.572 rmse: 3.652 mae: 1.058\n",
      "epoch: 121 loss: 0.94916052 r2: 0.572 rmse: 3.654 mae: 1.059\n",
      "epoch: 122 loss: 0.94982606 r2: 0.572 rmse: 3.654 mae: 1.059\n",
      "epoch: 123 loss: 0.94759154 r2: 0.572 rmse: 3.655 mae: 1.059\n",
      "epoch: 124 loss: 0.95176852 r2: 0.572 rmse: 3.655 mae: 1.059\n",
      "epoch: 125 loss: 0.95174640 r2: 0.572 rmse: 3.655 mae: 1.058\n",
      "epoch: 126 loss: 0.94940388 r2: 0.572 rmse: 3.656 mae: 1.059\n",
      "epoch: 127 loss: 0.94946557 r2: 0.572 rmse: 3.655 mae: 1.058\n",
      "epoch: 128 loss: 0.95432943 r2: 0.572 rmse: 3.655 mae: 1.058\n",
      "epoch: 129 loss: 0.95042890 r2: 0.572 rmse: 3.656 mae: 1.058\n",
      "epoch: 130 loss: 0.94584161 r2: 0.572 rmse: 3.656 mae: 1.058\n",
      "epoch: 131 loss: 0.94995946 r2: 0.572 rmse: 3.656 mae: 1.058\n",
      "epoch: 132 loss: 0.95086086 r2: 0.571 rmse: 3.660 mae: 1.059\n",
      "epoch: 133 loss: 0.95446014 r2: 0.571 rmse: 3.660 mae: 1.059\n",
      "epoch: 134 loss: 0.94778496 r2: 0.571 rmse: 3.660 mae: 1.059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 135 loss: 0.95557272 r2: 0.571 rmse: 3.661 mae: 1.059\n",
      "epoch: 136 loss: 0.94719929 r2: 0.571 rmse: 3.661 mae: 1.059\n",
      "epoch: 137 loss: 0.94951469 r2: 0.571 rmse: 3.661 mae: 1.059\n",
      "epoch: 138 loss: 0.95181382 r2: 0.571 rmse: 3.661 mae: 1.058\n",
      "epoch: 139 loss: 0.95426887 r2: 0.571 rmse: 3.661 mae: 1.059\n",
      "epoch: 140 loss: 0.95426911 r2: 0.571 rmse: 3.662 mae: 1.058\n",
      "epoch: 141 loss: 0.95195401 r2: 0.571 rmse: 3.662 mae: 1.058\n",
      "epoch: 142 loss: 0.95168722 r2: 0.571 rmse: 3.662 mae: 1.058\n",
      "epoch: 143 loss: 0.95169663 r2: 0.571 rmse: 3.666 mae: 1.059\n",
      "epoch: 144 loss: 0.95087862 r2: 0.570 rmse: 3.667 mae: 1.059\n",
      "epoch: 145 loss: 0.95364934 r2: 0.570 rmse: 3.668 mae: 1.059\n",
      "epoch: 146 loss: 0.95414239 r2: 0.570 rmse: 3.668 mae: 1.059\n",
      "epoch: 147 loss: 0.95155489 r2: 0.570 rmse: 3.668 mae: 1.059\n",
      "epoch: 148 loss: 0.95277727 r2: 0.570 rmse: 3.669 mae: 1.059\n",
      "epoch: 149 loss: 0.94753027 r2: 0.570 rmse: 3.669 mae: 1.059\n",
      "epoch: 149 loss: 0.9475302696\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    for feat,seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "#         model.hidden_cell = (torch.zeros(layers, 1, model.hidden_layer_size).to(device),\n",
    "#                         torch.zeros(layers, 1, model.hidden_layer_size).to(device))\n",
    "\n",
    "        y_pred = model(seq, feat)\n",
    "        labels = labels.repeat(y_pred.shape[0],1,1)\n",
    "        \n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()\n",
    "#     if i%10 == 1:\n",
    "    r2, rmse, mae = evaluate(model)\n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.8f} r2: {r2:5.3f} rmse: {rmse:5.3f} mae: {mae:5.3f}')\n",
    "    torch.save(model.state_dict(), 'jfk.pt')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bezt value 0.577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5702683714827709, 3.6686943, 1.0587766)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': '18',\n",
       " '10': '6',\n",
       " '100': '1',\n",
       " '101': '3',\n",
       " '102': '4',\n",
       " '106': '19',\n",
       " '107': '4',\n",
       " '108': '15',\n",
       " '109': '1',\n",
       " '11': '2',\n",
       " '110': '20',\n",
       " '111': '7',\n",
       " '112': '13',\n",
       " '113': '19',\n",
       " '114': '18',\n",
       " '115': '17',\n",
       " '116': '5',\n",
       " '117': '10',\n",
       " '118': '1',\n",
       " '119': '9',\n",
       " '12': '23',\n",
       " '120': '6',\n",
       " '121': '17',\n",
       " '122': '17',\n",
       " '123': '18',\n",
       " '124': '13',\n",
       " '125': '3',\n",
       " '126': '18',\n",
       " '127': '13',\n",
       " '128': '11',\n",
       " '129': '7',\n",
       " '13': '22',\n",
       " '130': '9',\n",
       " '131': '19',\n",
       " '133': '7',\n",
       " '134': '9',\n",
       " '135': '13',\n",
       " '136': '4',\n",
       " '137': '19',\n",
       " '138': '16',\n",
       " '139': '19',\n",
       " '14': '16',\n",
       " '140': '12',\n",
       " '141': '5',\n",
       " '142': '7',\n",
       " '143': '2',\n",
       " '144': '7',\n",
       " '145': '15',\n",
       " '146': '6',\n",
       " '147': '17',\n",
       " '148': '14',\n",
       " '149': '13',\n",
       " '15': '15',\n",
       " '150': '11',\n",
       " '151': '12',\n",
       " '152': '2',\n",
       " '153': '7',\n",
       " '154': '17',\n",
       " '155': '17',\n",
       " '156': '19',\n",
       " '157': '1',\n",
       " '158': '4',\n",
       " '159': '16',\n",
       " '16': '10',\n",
       " '160': '6',\n",
       " '161': '6',\n",
       " '162': '0',\n",
       " '163': '22',\n",
       " '164': '9',\n",
       " '165': '22',\n",
       " '166': '18',\n",
       " '167': '4',\n",
       " '168': '18',\n",
       " '169': '13',\n",
       " '17': '15',\n",
       " '170': '20',\n",
       " '171': '23',\n",
       " '172': '23',\n",
       " '173': '8',\n",
       " '174': '9',\n",
       " '175': '10',\n",
       " '176': '7',\n",
       " '177': '4',\n",
       " '178': '3',\n",
       " '179': '8',\n",
       " '18': '9',\n",
       " '180': '4',\n",
       " '181': '20',\n",
       " '182': '14',\n",
       " '183': '23',\n",
       " '184': '12',\n",
       " '185': '1',\n",
       " '186': '20',\n",
       " '187': '13',\n",
       " '188': '1',\n",
       " '189': '8',\n",
       " '19': '17',\n",
       " '190': '17',\n",
       " '191': '4',\n",
       " '192': '3',\n",
       " '193': '19',\n",
       " '194': '13',\n",
       " '195': '14',\n",
       " '196': '2',\n",
       " '197': '19',\n",
       " '198': '10',\n",
       " '199': '6',\n",
       " '2': '8',\n",
       " '20': '6',\n",
       " '200': '15',\n",
       " '201': '13',\n",
       " '202': '10',\n",
       " '203': '7',\n",
       " '204': '1',\n",
       " '205': '16',\n",
       " '206': '13',\n",
       " '207': '15',\n",
       " '208': '4',\n",
       " '209': '0',\n",
       " '21': '18',\n",
       " '210': '8',\n",
       " '211': '19',\n",
       " '212': '19',\n",
       " '213': '4',\n",
       " '214': '1',\n",
       " '215': '6',\n",
       " '216': '18',\n",
       " '217': '13',\n",
       " '218': '11',\n",
       " '219': '13',\n",
       " '22': '17',\n",
       " '220': '18',\n",
       " '221': '3',\n",
       " '222': '9',\n",
       " '223': '6',\n",
       " '224': '8',\n",
       " '225': '8',\n",
       " '226': '11',\n",
       " '227': '5',\n",
       " '228': '23',\n",
       " '229': '5',\n",
       " '23': '5',\n",
       " '230': '11',\n",
       " '231': '19',\n",
       " '232': '7',\n",
       " '233': '7',\n",
       " '234': '6',\n",
       " '235': '13',\n",
       " '236': '3',\n",
       " '237': '14',\n",
       " '238': '16',\n",
       " '239': '3',\n",
       " '24': '10',\n",
       " '240': '12',\n",
       " '241': '14',\n",
       " '242': '10',\n",
       " '243': '15',\n",
       " '244': '10',\n",
       " '245': '5',\n",
       " '246': '12',\n",
       " '247': '8',\n",
       " '248': '11',\n",
       " '249': '7',\n",
       " '25': '0',\n",
       " '250': '8',\n",
       " '251': '9',\n",
       " '252': '1',\n",
       " '253': '15',\n",
       " '254': '7',\n",
       " '255': '10',\n",
       " '256': '11',\n",
       " '257': '11',\n",
       " '258': '2',\n",
       " '259': '18',\n",
       " '26': '19',\n",
       " '260': '23',\n",
       " '261': '22',\n",
       " '262': '3',\n",
       " '263': '4',\n",
       " '27': '9',\n",
       " '28': '10',\n",
       " '29': '10',\n",
       " '3': '1',\n",
       " '30': '21',\n",
       " '31': '18',\n",
       " '32': '15',\n",
       " '33': '13',\n",
       " '34': '8',\n",
       " '35': '17',\n",
       " '36': '9',\n",
       " '37': '2',\n",
       " '38': '17',\n",
       " '39': '11',\n",
       " '4': '10',\n",
       " '40': '14',\n",
       " '41': '3',\n",
       " '42': '14',\n",
       " '43': '1',\n",
       " '44': '17',\n",
       " '45': '7',\n",
       " '46': '21',\n",
       " '47': '23',\n",
       " '48': '1',\n",
       " '49': '21',\n",
       " '5': '23',\n",
       " '50': '9',\n",
       " '51': '4',\n",
       " '52': '23',\n",
       " '53': '20',\n",
       " '54': '12',\n",
       " '55': '10',\n",
       " '56': '4',\n",
       " '58': '15',\n",
       " '59': '12',\n",
       " '6': '21',\n",
       " '60': '6',\n",
       " '61': '12',\n",
       " '62': '5',\n",
       " '63': '5',\n",
       " '64': '16',\n",
       " '65': '5',\n",
       " '66': '5',\n",
       " '67': '21',\n",
       " '68': '21',\n",
       " '69': '2',\n",
       " '7': '2',\n",
       " '70': '6',\n",
       " '71': '13',\n",
       " '72': '0',\n",
       " '73': '8',\n",
       " '74': '19',\n",
       " '75': '2',\n",
       " '76': '18',\n",
       " '77': '1',\n",
       " '78': '14',\n",
       " '79': '11',\n",
       " '8': '2',\n",
       " '80': '1',\n",
       " '81': '23',\n",
       " '82': '2',\n",
       " '83': '10',\n",
       " '84': '15',\n",
       " '85': '15',\n",
       " '86': '12',\n",
       " '87': '19',\n",
       " '88': '4',\n",
       " '89': '16',\n",
       " '9': '7',\n",
       " '90': '19',\n",
       " '91': '4',\n",
       " '92': '7',\n",
       " '93': '14',\n",
       " '94': '6',\n",
       " '95': '2',\n",
       " '96': '15',\n",
       " '97': '7',\n",
       " '98': '3',\n",
       " '99': '17'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attachment = torch.argmax(F.softmax(model.attachment_matrix, dim=1), dim=1).detach().cpu().numpy().astype(str)\n",
    "community_assignment = dict(zip(targetColumns, attachment))\n",
    "community_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('jfk_attachment.json', 'w') as fp:\n",
    "    json.dump(community_assignment, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(attachment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 linear\n",
    "# 0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 linear\n",
    "# 0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 linear + RELU\n",
    "# 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 linear bptt = 24\n",
    "# 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble\n",
    "#0.53228"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO\n",
    "# other hubs\n",
    "# ensemble model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
