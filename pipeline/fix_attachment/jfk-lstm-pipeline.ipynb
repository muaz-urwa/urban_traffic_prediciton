{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2020)\n",
    "np.random.seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.00034439316653688684,\n",
       " 'layers': 3,\n",
       " 'step_size': 11,\n",
       " 'gamma': 0.761795969995615,\n",
       " 'bptt': 19,\n",
       " 'dropout': 0.1227497445640586}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'lr': 0.00034439316653688684,\n",
    " 'layers': 3,\n",
    " 'step_size': 11,\n",
    " 'gamma': 0.761795969995615,\n",
    " 'bptt': 19,\n",
    " 'dropout': 0.1227497445640586}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/home/urwa/Documents/side_projects/urban/data/featureData/jfk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 1049)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>...</th>\n",
       "      <th>91_lag_3</th>\n",
       "      <th>92_lag_3</th>\n",
       "      <th>93_lag_3</th>\n",
       "      <th>94_lag_3</th>\n",
       "      <th>95_lag_3</th>\n",
       "      <th>96_lag_3</th>\n",
       "      <th>97_lag_3</th>\n",
       "      <th>98_lag_3</th>\n",
       "      <th>99_lag_3</th>\n",
       "      <th>arrival_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour  1  10  100  101  102  106  107  108  ...  91_lag_3  \\\n",
       "0  2018-01-01     3  0   0    0    0    0    0    0    0  ...       1.0   \n",
       "1  2018-01-01     4  0   3    0    0    1    0    0    1  ...       4.0   \n",
       "2  2018-01-01     5  0   4    0    0    1    2    3    1  ...       0.0   \n",
       "\n",
       "   92_lag_3  93_lag_3  94_lag_3  95_lag_3  96_lag_3  97_lag_3  98_lag_3  \\\n",
       "0       1.0       0.0       1.0       6.0       0.0       1.0       0.0   \n",
       "1       1.0       0.0       0.0       2.0       0.0       0.0       0.0   \n",
       "2       0.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "\n",
       "   99_lag_3  arrival_lag_3  \n",
       "0       0.0            6.0  \n",
       "1       0.0            6.0  \n",
       "2       0.0            2.0  \n",
       "\n",
       "[3 rows x 1049 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "777"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_columns = [c for c in dataset.columns if 'lag' in c]\n",
    "len(lag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 272)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[[c for c in dataset.columns if c not in lag_columns]]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "258"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DateColumns = ['Date']\n",
    "\n",
    "ext_columns = ['Dow', 'arrival','maxtemp', 'mintemp', 'avgtemp', 'departure', 'hdd',\n",
    "       'cdd', 'participation', 'newsnow', 'snowdepth', 'ifSnow']\n",
    "\n",
    "targetColumns = [c for c in dataset.columns if c not in ext_columns and \\\n",
    "                c not in DateColumns and c not in lag_columns and c != 'Hour']\n",
    "len(targetColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cols = [c for c in dataset.columns if c not in targetColumns and c not in DateColumns]\n",
    "len(features_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6567\n",
      "(6567, 272)\n",
      "(2190, 272)\n"
     ]
    }
   ],
   "source": [
    "sep = int(0.75*len(dataset))\n",
    "print(sep)\n",
    "\n",
    "\n",
    "trainData = dataset[:sep]\n",
    "testData = dataset[sep:]\n",
    "\n",
    "print(trainData.shape)\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6567, 13])\n",
      "torch.Size([6567, 258])\n",
      "torch.Size([2190, 13])\n",
      "torch.Size([2190, 258])\n"
     ]
    }
   ],
   "source": [
    "X_train = trainData[features_cols].values\n",
    "X_train = torch.tensor(X_train).float().to(device)\n",
    "print(X_train.shape)\n",
    "\n",
    "y_train = trainData[targetColumns].values\n",
    "y_train = torch.tensor(y_train).float().to(device)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test = testData[features_cols].values\n",
    "X_test = torch.tensor(X_test).float().to(device)\n",
    "print(X_test.shape)\n",
    "\n",
    "y_test = testData[targetColumns].values\n",
    "y_test = torch.tensor(y_test).float().to(device)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(x,y, tw):\n",
    "    inout_seq = []\n",
    "    L = len(x)\n",
    "    for i in range(L-tw):\n",
    "        train_seq_x = x[i:i+tw]\n",
    "        train_seq_y = y[i:i+tw]\n",
    "#         train_seq = torch.cat((train_seq_x,train_seq_y),axis=1)\n",
    "        \n",
    "#         train_label = y[i+tw:i+tw+1]\n",
    "        train_label = y[i+1:i+tw+1]\n",
    "        inout_seq.append((train_seq_x, train_seq_y ,train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inout_seq = create_inout_sequences(X_train,y_train, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([19, 13]), torch.Size([19, 258]), torch.Size([19, 258]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inout_seq[0][0].shape,train_inout_seq[0][1].shape, train_inout_seq[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inout_seq = create_inout_sequences(X_test,y_test, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, feat_size=1, hidden_layer_size=100, network_size=1, layers=1, communities=10, dropout=0, at_mat=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        # aggregation\n",
    "        if at_mat != None:\n",
    "            self.attachment_matrix = torch.nn.Parameter(at_mat)\n",
    "            self.attachment_matrix.requires_grad = False\n",
    "        else:\n",
    "            self.attachment_matrix = torch.nn.Parameter(torch.randn(network_size,communities))\n",
    "            self.attachment_matrix.requires_grad = True\n",
    "        \n",
    "        \n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        self.hidden_cell = (torch.zeros(layers,1,self.hidden_layer_size),\n",
    "                    torch.zeros(layers,1,self.hidden_layer_size))\n",
    "        \n",
    "        lstm_input = communities + feat_size\n",
    "        self.lstm = nn.LSTM(input_size=lstm_input, hidden_size=hidden_layer_size, num_layers=layers, dropout=dropout)\n",
    "\n",
    "        #disaggregation\n",
    "#         self.linear_1 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.linear_2 = nn.Linear(hidden_layer_size, network_size)\n",
    "\n",
    "\n",
    "    def forward(self, input_seq, feat):\n",
    "        \n",
    "        w = F.softmax(self.attachment_matrix, dim=1)\n",
    "        x = torch.matmul(input_seq, self.attachment_matrix)\n",
    "        x = torch.cat((x,feat),axis=1)\n",
    "\n",
    "        \n",
    "        lstm_out, self.hidden_cell = self.lstm(x.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        \n",
    "        predictions = self.linear_2(lstm_out.view(len(input_seq), -1))\n",
    "#         predictions = F.relu(predictions)\n",
    "#         predictions = self.linear_2(predictions)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    with torch.no_grad():\n",
    "        for feat,seq, labels in test_inout_seq:\n",
    "            model.hidden = (torch.zeros(layers, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(layers, 1, model.hidden_layer_size))\n",
    "            prediction.append(model(seq,feat)[-1])\n",
    "\n",
    "    y_test_ = torch.stack([labels[-1] for feat,seq, labels in test_inout_seq], axis=0).detach().cpu().numpy()\n",
    "    y_pred_ = torch.stack(prediction).detach().cpu().numpy()\n",
    "\n",
    "    r2 = r2_score(y_test_, y_pred_, multioutput='variance_weighted')\n",
    "    rmse = mean_squared_error(y_test_, y_pred_)\n",
    "    mae = mean_absolute_error(y_test_, y_pred_)\n",
    "#     print(\"r2: \",r2)\n",
    "    return (r2, rmse, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_at_mat(targetColumns):\n",
    "    comms = pd.read_csv('/home/urwa/Documents/side_projects/urban/UrbanTemporalNetworks/Data/ZonetoComm.csv')  \n",
    "    communities = list(set(comms.start_community))\n",
    "\n",
    "    mapping = dict(zip(comms.start_id, comms.start_community))\n",
    "    comm_to_index = dict(zip(communities,range(len(communities))))\n",
    "    col_to_index = dict(zip(targetColumns,range(len(targetColumns))))\n",
    "\n",
    "    attach = torch.zeros(len(targetColumns), len(communities))\n",
    "\n",
    "    for t_c in targetColumns:\n",
    "        com = mapping[int(t_c)]\n",
    "        x_i = col_to_index[t_c]\n",
    "        y_i = comm_to_index[com]\n",
    "\n",
    "        attach[x_i,y_i] = 1\n",
    "\n",
    "    return attach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([258, 24])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_mat = get_at_mat(targetColumns)\n",
    "at_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 3\n",
    "communities = 24\n",
    "network_size = len(targetColumns)\n",
    "feat_size = len(features_cols)\n",
    "dropout = 0.1227497445640586\n",
    "\n",
    "model = LSTM(feat_size = feat_size, hidden_layer_size=communities,\n",
    "             network_size=network_size, layers=layers,\n",
    "            communities=communities, dropout=dropout, at_mat=at_mat).to(device)\n",
    "\n",
    "loss_function = nn.L1Loss()   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00034439316653688684)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=11, gamma=0.762)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   0 loss: 1.23288834 r2: 0.399 rmse: 5.134 mae: 1.204\n",
      "epoch:   1 loss: 1.17525387 r2: 0.448 rmse: 4.716 mae: 1.176\n",
      "epoch:   2 loss: 1.15672064 r2: 0.475 rmse: 4.479 mae: 1.142\n",
      "epoch:   3 loss: 1.13136899 r2: 0.517 rmse: 4.120 mae: 1.103\n",
      "epoch:   4 loss: 1.13129175 r2: 0.518 rmse: 4.119 mae: 1.106\n",
      "epoch:   5 loss: 1.11847699 r2: 0.528 rmse: 4.026 mae: 1.092\n",
      "epoch:   6 loss: 1.11798167 r2: 0.533 rmse: 3.985 mae: 1.084\n",
      "epoch:   7 loss: 1.08268738 r2: 0.535 rmse: 3.968 mae: 1.088\n",
      "epoch:   8 loss: 1.10238826 r2: 0.536 rmse: 3.961 mae: 1.083\n",
      "epoch:   9 loss: 1.06926703 r2: 0.541 rmse: 3.922 mae: 1.083\n",
      "epoch:  10 loss: 1.08010077 r2: 0.541 rmse: 3.919 mae: 1.080\n",
      "epoch:  11 loss: 1.07420146 r2: 0.555 rmse: 3.795 mae: 1.069\n",
      "epoch:  12 loss: 1.05235386 r2: 0.560 rmse: 3.757 mae: 1.062\n",
      "epoch:  13 loss: 1.06245053 r2: 0.556 rmse: 3.795 mae: 1.069\n",
      "epoch:  14 loss: 1.05597305 r2: 0.556 rmse: 3.793 mae: 1.067\n",
      "epoch:  15 loss: 1.04932058 r2: 0.561 rmse: 3.749 mae: 1.063\n",
      "epoch:  16 loss: 1.05724406 r2: 0.558 rmse: 3.775 mae: 1.069\n",
      "epoch:  17 loss: 1.05237615 r2: 0.560 rmse: 3.758 mae: 1.067\n",
      "epoch:  18 loss: 1.05388153 r2: 0.565 rmse: 3.715 mae: 1.059\n",
      "epoch:  19 loss: 1.11091328 r2: 0.565 rmse: 3.712 mae: 1.058\n",
      "epoch:  20 loss: 1.04093587 r2: 0.565 rmse: 3.711 mae: 1.061\n",
      "epoch:  21 loss: 1.06057763 r2: 0.563 rmse: 3.729 mae: 1.062\n",
      "epoch:  22 loss: 1.07473254 r2: 0.566 rmse: 3.706 mae: 1.056\n",
      "epoch:  23 loss: 1.03139758 r2: 0.571 rmse: 3.664 mae: 1.049\n",
      "epoch:  24 loss: 1.06150651 r2: 0.570 rmse: 3.667 mae: 1.051\n",
      "epoch:  25 loss: 1.05850220 r2: 0.569 rmse: 3.679 mae: 1.054\n",
      "epoch:  26 loss: 1.04299736 r2: 0.569 rmse: 3.679 mae: 1.054\n",
      "epoch:  27 loss: 1.03878880 r2: 0.571 rmse: 3.658 mae: 1.048\n",
      "epoch:  28 loss: 1.06083703 r2: 0.570 rmse: 3.674 mae: 1.050\n",
      "epoch:  29 loss: 1.04562914 r2: 0.571 rmse: 3.659 mae: 1.052\n",
      "epoch:  30 loss: 1.02366841 r2: 0.571 rmse: 3.663 mae: 1.050\n",
      "epoch:  31 loss: 1.03615797 r2: 0.571 rmse: 3.661 mae: 1.048\n",
      "epoch:  32 loss: 1.02074850 r2: 0.577 rmse: 3.611 mae: 1.044\n",
      "epoch:  33 loss: 1.01906323 r2: 0.578 rmse: 3.606 mae: 1.043\n",
      "epoch:  34 loss: 1.05794549 r2: 0.577 rmse: 3.613 mae: 1.044\n",
      "epoch:  35 loss: 1.02644503 r2: 0.574 rmse: 3.633 mae: 1.048\n",
      "epoch:  36 loss: 1.02876532 r2: 0.579 rmse: 3.595 mae: 1.042\n",
      "epoch:  37 loss: 1.04483378 r2: 0.581 rmse: 3.580 mae: 1.041\n",
      "epoch:  38 loss: 1.04446721 r2: 0.582 rmse: 3.565 mae: 1.039\n",
      "epoch:  39 loss: 1.04092050 r2: 0.581 rmse: 3.580 mae: 1.040\n",
      "epoch:  40 loss: 1.03869784 r2: 0.580 rmse: 3.582 mae: 1.040\n",
      "epoch:  41 loss: 1.02369630 r2: 0.583 rmse: 3.562 mae: 1.038\n",
      "epoch:  42 loss: 1.02109444 r2: 0.582 rmse: 3.565 mae: 1.037\n",
      "epoch:  43 loss: 1.02361345 r2: 0.581 rmse: 3.580 mae: 1.039\n",
      "epoch:  44 loss: 1.02206922 r2: 0.581 rmse: 3.578 mae: 1.039\n",
      "epoch:  45 loss: 1.05206084 r2: 0.582 rmse: 3.566 mae: 1.039\n",
      "epoch:  46 loss: 1.04236448 r2: 0.580 rmse: 3.583 mae: 1.038\n",
      "epoch:  47 loss: 1.02567351 r2: 0.580 rmse: 3.583 mae: 1.037\n",
      "epoch:  48 loss: 1.02305794 r2: 0.583 rmse: 3.560 mae: 1.037\n",
      "epoch:  49 loss: 1.03538573 r2: 0.581 rmse: 3.573 mae: 1.037\n",
      "epoch:  50 loss: 1.02528465 r2: 0.584 rmse: 3.550 mae: 1.036\n",
      "epoch:  51 loss: 1.03507411 r2: 0.585 rmse: 3.546 mae: 1.036\n",
      "epoch:  52 loss: 1.03222191 r2: 0.583 rmse: 3.561 mae: 1.036\n",
      "epoch:  53 loss: 1.03018057 r2: 0.583 rmse: 3.558 mae: 1.035\n",
      "epoch:  54 loss: 1.03218317 r2: 0.583 rmse: 3.558 mae: 1.033\n",
      "epoch:  55 loss: 1.04450667 r2: 0.585 rmse: 3.540 mae: 1.033\n",
      "epoch:  56 loss: 1.02748096 r2: 0.586 rmse: 3.535 mae: 1.032\n",
      "epoch:  57 loss: 1.03207171 r2: 0.585 rmse: 3.540 mae: 1.032\n",
      "epoch:  58 loss: 1.04759240 r2: 0.586 rmse: 3.531 mae: 1.030\n",
      "epoch:  59 loss: 1.05787480 r2: 0.586 rmse: 3.535 mae: 1.031\n",
      "epoch:  60 loss: 1.02591097 r2: 0.587 rmse: 3.527 mae: 1.029\n",
      "epoch:  61 loss: 1.02546692 r2: 0.584 rmse: 3.547 mae: 1.032\n",
      "epoch:  62 loss: 1.03846169 r2: 0.586 rmse: 3.533 mae: 1.030\n",
      "epoch:  63 loss: 1.02367735 r2: 0.585 rmse: 3.541 mae: 1.032\n",
      "epoch:  64 loss: 1.03093445 r2: 0.584 rmse: 3.548 mae: 1.032\n",
      "epoch:  65 loss: 1.04198360 r2: 0.587 rmse: 3.529 mae: 1.031\n",
      "epoch:  66 loss: 1.02108097 r2: 0.587 rmse: 3.530 mae: 1.030\n",
      "epoch:  67 loss: 1.03477371 r2: 0.587 rmse: 3.527 mae: 1.029\n",
      "epoch:  68 loss: 1.03689623 r2: 0.588 rmse: 3.518 mae: 1.029\n",
      "epoch:  69 loss: 1.01807928 r2: 0.587 rmse: 3.526 mae: 1.029\n",
      "epoch:  70 loss: 1.04460430 r2: 0.588 rmse: 3.517 mae: 1.028\n",
      "epoch:  71 loss: 1.03939056 r2: 0.587 rmse: 3.526 mae: 1.029\n",
      "epoch:  72 loss: 1.02070165 r2: 0.586 rmse: 3.531 mae: 1.031\n",
      "epoch:  73 loss: 1.03377450 r2: 0.588 rmse: 3.516 mae: 1.028\n",
      "epoch:  74 loss: 1.04244804 r2: 0.587 rmse: 3.526 mae: 1.030\n",
      "epoch:  75 loss: 1.01412833 r2: 0.587 rmse: 3.523 mae: 1.028\n",
      "epoch:  76 loss: 1.03348541 r2: 0.587 rmse: 3.529 mae: 1.028\n",
      "epoch:  77 loss: 1.03867233 r2: 0.589 rmse: 3.513 mae: 1.027\n",
      "epoch:  78 loss: 1.02809072 r2: 0.589 rmse: 3.513 mae: 1.029\n",
      "epoch:  79 loss: 1.04230618 r2: 0.588 rmse: 3.520 mae: 1.029\n",
      "epoch:  80 loss: 1.01419127 r2: 0.588 rmse: 3.516 mae: 1.028\n",
      "epoch:  81 loss: 1.02780664 r2: 0.589 rmse: 3.511 mae: 1.027\n",
      "epoch:  82 loss: 1.03059936 r2: 0.589 rmse: 3.510 mae: 1.027\n",
      "epoch:  83 loss: 1.03525424 r2: 0.587 rmse: 3.523 mae: 1.027\n",
      "epoch:  84 loss: 1.04316354 r2: 0.589 rmse: 3.508 mae: 1.027\n",
      "epoch:  85 loss: 1.04454541 r2: 0.588 rmse: 3.515 mae: 1.027\n",
      "epoch:  86 loss: 1.02329171 r2: 0.588 rmse: 3.520 mae: 1.028\n",
      "epoch:  87 loss: 1.01912510 r2: 0.589 rmse: 3.511 mae: 1.027\n",
      "epoch:  88 loss: 1.03978240 r2: 0.587 rmse: 3.529 mae: 1.028\n",
      "epoch:  89 loss: 1.03506243 r2: 0.589 rmse: 3.511 mae: 1.027\n",
      "epoch:  90 loss: 1.02289796 r2: 0.588 rmse: 3.516 mae: 1.027\n",
      "epoch:  91 loss: 1.02625442 r2: 0.588 rmse: 3.518 mae: 1.027\n",
      "epoch:  92 loss: 1.02721798 r2: 0.588 rmse: 3.516 mae: 1.026\n",
      "epoch:  93 loss: 1.03364265 r2: 0.589 rmse: 3.512 mae: 1.026\n",
      "epoch:  94 loss: 1.03148162 r2: 0.588 rmse: 3.516 mae: 1.026\n",
      "epoch:  95 loss: 1.03739309 r2: 0.588 rmse: 3.516 mae: 1.027\n",
      "epoch:  96 loss: 1.03407848 r2: 0.588 rmse: 3.513 mae: 1.027\n",
      "epoch:  97 loss: 1.01958585 r2: 0.587 rmse: 3.524 mae: 1.026\n",
      "epoch:  98 loss: 1.04496360 r2: 0.588 rmse: 3.519 mae: 1.027\n",
      "epoch:  99 loss: 1.04310656 r2: 0.587 rmse: 3.523 mae: 1.026\n",
      "epoch:  99 loss: 1.0431065559\n",
      "bet_r2:  0.5890488836091444\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "best_r2 = 0\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    for feat,seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(layers, 1, model.hidden_layer_size).to(device),\n",
    "                        torch.zeros(layers, 1, model.hidden_layer_size).to(device))\n",
    "\n",
    "        y_pred = model(seq, feat)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()\n",
    "#     if i%1 == 1:\n",
    "    r2, rmse, mae = evaluate(model)\n",
    "    print(f'epoch: {i:3} loss: {single_loss.item():10.8f} r2: {r2:5.3f} rmse: {rmse:5.3f} mae: {mae:5.3f}')\n",
    "    \n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        torch.save(model.state_dict(), 'jfk.pt')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')\n",
    "print(\"bet_r2: \", best_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5873123634613898, 3.5231857, 1.0262967)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 0,\n",
       " '10': 4,\n",
       " '100': 0,\n",
       " '101': 4,\n",
       " '102': 23,\n",
       " '106': 19,\n",
       " '107': 1,\n",
       " '108': 3,\n",
       " '109': 5,\n",
       " '11': 3,\n",
       " '110': 5,\n",
       " '111': 19,\n",
       " '112': 9,\n",
       " '113': 1,\n",
       " '114': 1,\n",
       " '115': 18,\n",
       " '116': 22,\n",
       " '117': 16,\n",
       " '118': 5,\n",
       " '119': 14,\n",
       " '12': 1,\n",
       " '120': 22,\n",
       " '121': 8,\n",
       " '122': 4,\n",
       " '123': 3,\n",
       " '124': 4,\n",
       " '125': 1,\n",
       " '126': 14,\n",
       " '127': 22,\n",
       " '128': 22,\n",
       " '129': 23,\n",
       " '13': 1,\n",
       " '130': 4,\n",
       " '131': 4,\n",
       " '133': 3,\n",
       " '134': 4,\n",
       " '135': 8,\n",
       " '136': 10,\n",
       " '137': 0,\n",
       " '138': 0,\n",
       " '139': 4,\n",
       " '14': 3,\n",
       " '140': 15,\n",
       " '141': 15,\n",
       " '142': 12,\n",
       " '143': 12,\n",
       " '144': 1,\n",
       " '145': 7,\n",
       " '146': 7,\n",
       " '147': 14,\n",
       " '148': 1,\n",
       " '149': 3,\n",
       " '15': 8,\n",
       " '150': 3,\n",
       " '151': 12,\n",
       " '152': 22,\n",
       " '153': 10,\n",
       " '154': 3,\n",
       " '155': 3,\n",
       " '156': 11,\n",
       " '157': 23,\n",
       " '158': 1,\n",
       " '159': 14,\n",
       " '16': 8,\n",
       " '160': 23,\n",
       " '161': 0,\n",
       " '162': 0,\n",
       " '163': 0,\n",
       " '164': 0,\n",
       " '165': 3,\n",
       " '166': 12,\n",
       " '167': 14,\n",
       " '168': 14,\n",
       " '169': 14,\n",
       " '17': 9,\n",
       " '170': 0,\n",
       " '171': 8,\n",
       " '172': 6,\n",
       " '173': 23,\n",
       " '174': 10,\n",
       " '175': 8,\n",
       " '176': 5,\n",
       " '177': 13,\n",
       " '178': 3,\n",
       " '179': 7,\n",
       " '18': 10,\n",
       " '180': 4,\n",
       " '181': 19,\n",
       " '182': 2,\n",
       " '183': 2,\n",
       " '184': 2,\n",
       " '185': 2,\n",
       " '186': 0,\n",
       " '187': 11,\n",
       " '188': 13,\n",
       " '189': 19,\n",
       " '19': 4,\n",
       " '190': 19,\n",
       " '191': 4,\n",
       " '192': 8,\n",
       " '193': 7,\n",
       " '194': 20,\n",
       " '195': 19,\n",
       " '196': 23,\n",
       " '197': 4,\n",
       " '198': 9,\n",
       " '199': 8,\n",
       " '2': 4,\n",
       " '20': 10,\n",
       " '200': 10,\n",
       " '201': 16,\n",
       " '202': 7,\n",
       " '203': 4,\n",
       " '204': 5,\n",
       " '205': 4,\n",
       " '206': 18,\n",
       " '207': 17,\n",
       " '208': 2,\n",
       " '209': 1,\n",
       " '21': 3,\n",
       " '210': 3,\n",
       " '211': 1,\n",
       " '212': 2,\n",
       " '213': 2,\n",
       " '214': 6,\n",
       " '215': 4,\n",
       " '216': 4,\n",
       " '217': 9,\n",
       " '218': 4,\n",
       " '219': 4,\n",
       " '22': 3,\n",
       " '220': 10,\n",
       " '221': 18,\n",
       " '222': 13,\n",
       " '223': 7,\n",
       " '224': 1,\n",
       " '225': 9,\n",
       " '226': 7,\n",
       " '227': 3,\n",
       " '228': 3,\n",
       " '229': 0,\n",
       " '23': 11,\n",
       " '230': 0,\n",
       " '231': 1,\n",
       " '232': 1,\n",
       " '233': 0,\n",
       " '234': 21,\n",
       " '235': 14,\n",
       " '236': 15,\n",
       " '237': 15,\n",
       " '238': 12,\n",
       " '239': 12,\n",
       " '24': 12,\n",
       " '240': 10,\n",
       " '241': 10,\n",
       " '242': 2,\n",
       " '243': 22,\n",
       " '244': 22,\n",
       " '245': 18,\n",
       " '246': 21,\n",
       " '247': 14,\n",
       " '248': 2,\n",
       " '249': 1,\n",
       " '25': 19,\n",
       " '250': 2,\n",
       " '251': 11,\n",
       " '252': 8,\n",
       " '253': 8,\n",
       " '254': 2,\n",
       " '255': 9,\n",
       " '256': 9,\n",
       " '257': 19,\n",
       " '258': 4,\n",
       " '259': 2,\n",
       " '26': 3,\n",
       " '260': 23,\n",
       " '261': 1,\n",
       " '262': 15,\n",
       " '263': 15,\n",
       " '27': 16,\n",
       " '28': 4,\n",
       " '29': 3,\n",
       " '3': 2,\n",
       " '30': 16,\n",
       " '31': 2,\n",
       " '32': 2,\n",
       " '33': 19,\n",
       " '34': 19,\n",
       " '35': 13,\n",
       " '36': 9,\n",
       " '37': 9,\n",
       " '38': 4,\n",
       " '39': 13,\n",
       " '4': 1,\n",
       " '40': 19,\n",
       " '41': 20,\n",
       " '42': 22,\n",
       " '43': 12,\n",
       " '44': 5,\n",
       " '45': 1,\n",
       " '46': 2,\n",
       " '47': 14,\n",
       " '48': 0,\n",
       " '49': 19,\n",
       " '5': 5,\n",
       " '50': 0,\n",
       " '51': 2,\n",
       " '52': 19,\n",
       " '53': 8,\n",
       " '54': 19,\n",
       " '55': 3,\n",
       " '56': 23,\n",
       " '58': 2,\n",
       " '59': 14,\n",
       " '6': 6,\n",
       " '60': 14,\n",
       " '61': 13,\n",
       " '62': 13,\n",
       " '63': 13,\n",
       " '64': 8,\n",
       " '65': 19,\n",
       " '66': 19,\n",
       " '67': 3,\n",
       " '68': 21,\n",
       " '69': 14,\n",
       " '7': 7,\n",
       " '70': 23,\n",
       " '71': 13,\n",
       " '72': 13,\n",
       " '73': 8,\n",
       " '74': 20,\n",
       " '75': 20,\n",
       " '76': 13,\n",
       " '77': 13,\n",
       " '78': 14,\n",
       " '79': 1,\n",
       " '8': 7,\n",
       " '80': 9,\n",
       " '81': 2,\n",
       " '82': 23,\n",
       " '83': 23,\n",
       " '84': 5,\n",
       " '85': 13,\n",
       " '86': 16,\n",
       " '87': 1,\n",
       " '88': 1,\n",
       " '89': 13,\n",
       " '9': 8,\n",
       " '90': 21,\n",
       " '91': 13,\n",
       " '92': 8,\n",
       " '93': 8,\n",
       " '94': 10,\n",
       " '95': 8,\n",
       " '96': 23,\n",
       " '97': 19,\n",
       " '98': 8,\n",
       " '99': 5}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attachment = torch.argmax(F.softmax(model.attachment_matrix, dim=1), dim=1).detach().cpu().numpy()\n",
    "community_assignment = dict(zip(targetColumns, attachment))\n",
    "community_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 comm\n",
    "# 0.505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 comm\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
