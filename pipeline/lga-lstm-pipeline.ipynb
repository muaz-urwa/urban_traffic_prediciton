{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/home/urwa/Documents/side_projects/urban/data/featureData/lga.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 1045)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>1</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>106</th>\n",
       "      <th>107</th>\n",
       "      <th>108</th>\n",
       "      <th>...</th>\n",
       "      <th>91_lag_3</th>\n",
       "      <th>92_lag_3</th>\n",
       "      <th>93_lag_3</th>\n",
       "      <th>94_lag_3</th>\n",
       "      <th>95_lag_3</th>\n",
       "      <th>96_lag_3</th>\n",
       "      <th>97_lag_3</th>\n",
       "      <th>98_lag_3</th>\n",
       "      <th>99_lag_3</th>\n",
       "      <th>arrival_lag_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 1045 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Hour  1  10  100  101  102  106  107  108  ...  91_lag_3  \\\n",
       "0  2018-01-01     3  0   0    0    0    0    0    0    0  ...       0.0   \n",
       "1  2018-01-01     4  1   0    0    0    0    0    0    0  ...       0.0   \n",
       "2  2018-01-01     5  1   0    0    0    0    0    0    0  ...       0.0   \n",
       "\n",
       "   92_lag_3  93_lag_3  94_lag_3  95_lag_3  96_lag_3  97_lag_3  98_lag_3  \\\n",
       "0       1.0       0.0       1.0       0.0       0.0       1.0       0.0   \n",
       "1       1.0       0.0       0.0       0.0       0.0       0.0       1.0   \n",
       "2       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   99_lag_3  arrival_lag_3  \n",
       "0       0.0            3.0  \n",
       "1       0.0            0.0  \n",
       "2       0.0            1.0  \n",
       "\n",
       "[3 rows x 1045 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_columns = [c for c in dataset.columns if 'lag' in c]\n",
    "len(lag_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8757, 271)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[[c for c in dataset.columns if c not in lag_columns]]\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DateColumns = ['Date']\n",
    "\n",
    "ext_columns = ['Dow', 'arrival','maxtemp', 'mintemp', 'avgtemp', 'departure', 'hdd',\n",
    "       'cdd', 'participation', 'newsnow', 'snowdepth', 'ifSnow']\n",
    "\n",
    "targetColumns = [c for c in dataset.columns if c not in ext_columns and \\\n",
    "                c not in DateColumns and c not in lag_columns and c != 'Hour']\n",
    "len(targetColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cols = [c for c in dataset.columns if c not in targetColumns and c not in DateColumns]\n",
    "len(features_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6567\n",
      "(6567, 271)\n",
      "(2190, 271)\n"
     ]
    }
   ],
   "source": [
    "sep = int(0.75*len(dataset))\n",
    "print(sep)\n",
    "\n",
    "\n",
    "trainData = dataset[:sep]\n",
    "testData = dataset[sep:]\n",
    "\n",
    "print(trainData.shape)\n",
    "print(testData.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6567, 13])\n",
      "torch.Size([6567, 257])\n",
      "torch.Size([2190, 13])\n",
      "torch.Size([2190, 257])\n"
     ]
    }
   ],
   "source": [
    "X_train = trainData[features_cols].values\n",
    "X_train = torch.tensor(X_train).float().to(device)\n",
    "print(X_train.shape)\n",
    "\n",
    "y_train = trainData[targetColumns].values\n",
    "y_train = torch.tensor(y_train).float().to(device)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test = testData[features_cols].values\n",
    "X_test = torch.tensor(X_test).float().to(device)\n",
    "print(X_test.shape)\n",
    "\n",
    "y_test = testData[targetColumns].values\n",
    "y_test = torch.tensor(y_test).float().to(device)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(x,y, tw):\n",
    "    inout_seq = []\n",
    "    L = len(x)\n",
    "    for i in range(L-tw):\n",
    "        train_seq_x = x[i:i+tw]\n",
    "        train_seq_y = y[i:i+tw]\n",
    "#         train_seq = torch.cat((train_seq_x,train_seq_y),axis=1)\n",
    "        \n",
    "#         train_label = y[i+tw:i+tw+1]\n",
    "        train_label = y[i+1:i+tw+1]\n",
    "        inout_seq.append((train_seq_x, train_seq_y ,train_label))\n",
    "    return inout_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inout_seq = create_inout_sequences(X_train,y_train, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 13]), torch.Size([6, 257]), torch.Size([6, 257]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inout_seq[0][0].shape,train_inout_seq[0][1].shape, train_inout_seq[0][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inout_seq = create_inout_sequences(X_test,y_test, bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, feat_size=1, hidden_layer_size=100, network_size=1, layers=1, communities=10):\n",
    "        super().__init__()\n",
    "        \n",
    "        # aggregation\n",
    "        self.attachment_matrix = torch.nn.Parameter(torch.randn(network_size,communities))\n",
    "        self.attachment_matrix.requires_grad = True\n",
    "        \n",
    "        \n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        self.hidden_cell = (torch.zeros(layers,1,self.hidden_layer_size),\n",
    "                    torch.zeros(layers,1,self.hidden_layer_size))\n",
    "        \n",
    "        lstm_input = communities + feat_size\n",
    "        self.lstm = nn.LSTM(input_size=lstm_input, hidden_size=hidden_layer_size, num_layers=layers)\n",
    "\n",
    "        #disaggregation\n",
    "#         self.linear_1 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.linear_2 = nn.Linear(hidden_layer_size, network_size)\n",
    "\n",
    "\n",
    "    def forward(self, input_seq, feat):\n",
    "        \n",
    "        w = F.softmax(self.attachment_matrix, dim=1)\n",
    "        x = torch.matmul(input_seq, self.attachment_matrix)\n",
    "        x = torch.cat((x,feat),axis=1)\n",
    "\n",
    "        \n",
    "        lstm_out, self.hidden_cell = self.lstm(x.view(len(input_seq) ,1, -1), self.hidden_cell)\n",
    "        \n",
    "        predictions = self.linear_2(lstm_out.view(len(input_seq), -1))\n",
    "#         predictions = F.relu(predictions)\n",
    "#         predictions = self.linear_2(predictions)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    prediction = []\n",
    "    with torch.no_grad():\n",
    "        for feat,seq, labels in test_inout_seq:\n",
    "            model.hidden = (torch.zeros(layers, 1, model.hidden_layer_size),\n",
    "                            torch.zeros(layers, 1, model.hidden_layer_size))\n",
    "            prediction.append(model(seq,feat)[-1])\n",
    "\n",
    "    y_test_ = torch.stack([labels[-1] for feat,seq, labels in test_inout_seq], axis=0).detach().cpu().numpy()\n",
    "    y_pred_ = torch.stack(prediction).detach().cpu().numpy()\n",
    "\n",
    "    r2 = r2_score(y_test_, y_pred_, multioutput='variance_weighted')\n",
    "    rmse = mean_squared_error(y_test_, y_pred_)\n",
    "    mae = mean_absolute_error(y_test_, y_pred_)\n",
    "#     print(\"r2: \",r2)\n",
    "    return (r2, rmse, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = 1\n",
    "communities = 24\n",
    "network_size = len(targetColumns)\n",
    "feat_size = len(features_cols)\n",
    "\n",
    "model = LSTM(feat_size = feat_size, hidden_layer_size=communities,\n",
    "             network_size=network_size, layers=layers,\n",
    "            communities=communities).to(device)\n",
    "\n",
    "loss_function = nn.L1Loss()   \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0201af2b1ff0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msingle_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msingle_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/general/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/general/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/general/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    for feat,seq, labels in train_inout_seq:\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(layers, 1, model.hidden_layer_size).to(device),\n",
    "                        torch.zeros(layers, 1, model.hidden_layer_size).to(device))\n",
    "\n",
    "        y_pred = model(seq, feat)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()\n",
    "    if i%10 == 1:\n",
    "        r2, rmse, mae = evaluate(model)\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f} r2: {r2:5.3f} rmse: {rmse:5.3f} mae: {mae:5.3f}')\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7046127387300352, 6.887028, 1.0707647)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attachment = torch.argmax(F.softmax(model.attachment_matrix, dim=1), dim=1).detach().cpu().numpy()\n",
    "# community_assignment = dict(zip(targetColumns, attachment))\n",
    "# community_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# community_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "attachment = model.attachment_matrix.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257, 24)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attachment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targetColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== 2 ============\n",
      "2.8963139551937362\n",
      "========== 3 ============\n",
      "3.2892934667507987\n",
      "========== 4 ============\n",
      "3.129459677258672\n",
      "========== 5 ============\n",
      "3.0258845288014555\n",
      "========== 6 ============\n",
      "3.076842440938373\n",
      "========== 7 ============\n",
      "2.9947178511630725\n",
      "========== 8 ============\n",
      "2.877054105184271\n",
      "========== 9 ============\n",
      "2.8290008475947457\n",
      "========== 10 ============\n",
      "2.8404560378365904\n",
      "========== 11 ============\n",
      "2.774318371378216\n",
      "========== 12 ============\n",
      "2.719678940570788\n",
      "========== 13 ============\n",
      "2.547455966446989\n",
      "========== 14 ============\n",
      "2.5443252809522585\n",
      "========== 15 ============\n",
      "2.5685699026103843\n",
      "========== 16 ============\n",
      "2.577130689691856\n",
      "========== 17 ============\n",
      "2.4756219256433702\n",
      "========== 18 ============\n",
      "2.404953712633187\n",
      "========== 19 ============\n",
      "2.555520310984024\n",
      "========== 20 ============\n",
      "2.417650742023066\n",
      "========== 21 ============\n",
      "2.4885713148860455\n",
      "========== 22 ============\n",
      "2.427904609154537\n",
      "========== 23 ============\n",
      "2.442913565151824\n"
     ]
    }
   ],
   "source": [
    "for i in range(2,24):\n",
    "    print('========== '+str(i)+' ============')\n",
    "    kmeans = KMeans(n_clusters=i, random_state=1).fit(attachment)\n",
    "    labels = kmeans.labels_\n",
    "    print(davies_bouldin_score(attachment, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  8, 22,  6,  7,  2,  6,  4,  6, 10,  0, 22,  3,  8,  8,  2,  4,\n",
       "        2, 19, 12,  2, 19,  1, 16, 18, 13, 18, 14, 19, 19, 17,  6,  8,  6,\n",
       "       10,  5, 14,  7,  3,  5,  4, 10,  2, 10, 10,  7,  4, 18, 16, 13, 17,\n",
       "        6,  4,  2,  5, 11, 12, 12, 11,  7, 20, 21, 21, 10, 13,  3, 20,  7,\n",
       "       22,  7, 19,  8,  4,  5, 10,  0, 20, 22,  2,  2, 19,  8, 19, 10,  8,\n",
       "        7, 22, 20,  5, 12, 13,  7, 12, 14, 10,  8, 12, 21,  1,  7, 13,  5,\n",
       "        2, 10,  7, 19,  6, 17, 10, 13, 22, 12, 15, 12, 22,  4,  7, 22, 22,\n",
       "       13, 22,  7, 17, 17, 18,  3,  2,  8, 22,  3, 10,  0, 19,  7,  3, 21,\n",
       "       19, 16,  1, 18, 18,  1, 18, 13, 13, 13, 19, 10, 22, 22, 10, 21, 13,\n",
       "        5, 17,  3,  5,  1, 12, 14,  5, 10, 22,  8, 15,  1,  5, 18,  3,  4,\n",
       "       12,  9,  3, 16, 22,  1, 10,  3,  5,  7, 21, 19,  3,  9, 13,  6, 13,\n",
       "        5,  7,  7,  6, 18, 19, 10,  7,  1, 13, 11, 13,  1, 18,  8, 20,  6,\n",
       "       12, 14, 10,  2,  6,  7,  2,  2,  5, 20, 18, 20, 19,  4, 22, 12, 13,\n",
       "       20, 22, 13,  2,  2,  8,  8,  8,  8, 13, 15, 14,  5,  3,  3,  3, 20,\n",
       "       19, 13, 11,  1,  3, 18, 13, 14,  5, 10, 18, 22, 12,  4,  2,  6, 13,\n",
       "        7, 18], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "community_assignment = dict(zip(targetColumns, labels.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('lga_single.json', 'w') as fp:\n",
    "    json.dump(community_assignment, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20 comm\n",
    "# 0.505"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 comm\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
